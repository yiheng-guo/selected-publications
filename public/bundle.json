[{"title":"Workflow Refactoring for Maximizing Concurrency and Block-Structuredness","date":"2021","authors":["Wei Song","Hans-Arno Jacobsen","Shing-Chi Cheung","Hongyu Liu","Xiaoxing Ma"],"venue":"IEEE Trans. Serv. Comput.","venueShort":"TSC","tags":["Workflow refactoring","activity dependence","concurrency maximization","block-structuredness","synchronization links"],"abstract":"\nIn the era of Internet and big data, contemporary workflows become increasingly large in scale and complex in structure, introducing greater challenges for workflow modeling. Workflows are not with maximized concurrency and block-structuredness in terms of control flow, though languages supporting block-structuredness (e.g., BPEL) are employed. Existing workflow refactoring approaches mostly focus on maximizing concurrency according to dependences between activities, but do not consider the block-structuredness of the refactored workflow. It is easier to comprehend and analyze a workflow that is block-structured and to transform it into BPEL-like processes. In this paper, we aim at maximizing both concurrency and block-structuredness. Nevertheless, not all workflows can be refactored with a block-structured representation, and it is intractable to make sure that the refactored workflows are as block-structured as possible. We first define a well-formed dependence pattern of activities. The control flow among the activities in this pattern can be represented in block-structured forms with maximized concurrency. Then, we propose a greedy heuristics-based graph reduction approach to recursively find such patterns. In this way, the resulting workflow is with maximized concurrency and its block-structuredness approximates optimality. We show the effectiveness and efficiency of our approach with real-world scientific workflows.\n        ","projectUrl":null,"paperUrl":null,"slidesUrl":null,"bibtex":"@article{DBLP:journals/tsc/SongJCLM21,\n  author    = {Wei Song and\n               Hans{-}Arno Jacobsen and\n               Shing{-}Chi Cheung and\n               Hongyu Liu and\n               Xiaoxing Ma},\n  title     = {Workflow Refactoring for Maximizing Concurrency and Block-Structuredness},\n  journal   = {{IEEE} Trans. Serv. Comput.},\n  volume    = {14},\n  number    = {4},\n  pages     = {1224--1237},\n  year      = {2021},\n  url       = {https://doi.org/10.1109/TSC.2018.2867593},\n  doi       = {10.1109/TSC.2018.2867593},\n  timestamp = {Thu, 12 Aug 2021 17:51:00 +0200},\n  biburl    = {https://dblp.org/rec/journals/tsc/SongJCLM21.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"awards":[]},{"title":"Sifter: A Service Isolation Strategy for Internet Applications","date":"2021","authors":["Chunyang Ye","Shing-Chi Cheung","Wing Kwong Chan"],"venue":"IEEE Trans. Serv. Comput.","venueShort":"TSC","tags":["Atomicity sphere","behavior constraint","exception handling","implicit interaction","isolation","web service"],"abstract":"\nService oriented architecture (SOA) provides a flexible platform to build collaborative Internet applications by composing existing self-contained and autonomous services. However, the implicit interactions among the concurrently provisioned services may introduce interference to Internet applications and cause them behave abnormally. It is thus desirable to isolate services to safeguard their application consistency. Existing approaches mostly address this problem by restricting concurrent execution of services to avoid all the implicit interactions. These approaches, however, compromise the performance and flexibility of Internet applications due to the long running nature of services. This paper presents Sifter, a new service isolation strategy for Internet applications. We devise in this strategy a novel static approach to analyze the potential implicit interactions among the services and their impacts on the consistency of the associated Internet applications. By locating only those afflicted implicit interactions that may violate the application consistency, a novel approach based on exception handling and behavior constraints is customized to involved services to eliminate their impacts. We show that this approach exempts the consistency property of Internet applications from being interfered at runtime. The experimental results show that our approach has a better performance than existing solutions.\n        ","projectUrl":null,"paperUrl":null,"slidesUrl":null,"bibtex":"@article{DBLP:journals/tsc/YeCC21,\n  author    = {Chunyang Ye and\n               Shing{-}Chi Cheung and\n               Wing Kwong Chan},\n  title     = {Sifter: {A} Service Isolation Strategy for Internet Applications},\n  journal   = {{IEEE} Trans. Serv. Comput.},\n  volume    = {14},\n  number    = {5},\n  pages     = {1545--1557},\n  year      = {2021},\n  url       = {https://doi.org/10.1109/TSC.2018.2876254},\n  doi       = {10.1109/TSC.2018.2876254},\n  timestamp = {Wed, 03 Nov 2021 08:27:31 +0100},\n  biburl    = {https://dblp.org/rec/journals/tsc/YeCC21.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"awards":[]},{"title":"ContractGuard: Defend Ethereum Smart Contracts with Embedded Intrusion Detection","date":"2020","authors":["Xinming Wang","Jiahao He","Zhijian Xie","Gansen Zhao","Shing-Chi Cheung"],"venue":"IEEE Trans. Serv. Comput.","venueShort":"TSC","tags":["Blockchain","Smart Contracts","Program Analysis","Security"],"abstract":"\nEthereum smart contracts are programs that can be collectively executed by a network of mutually untrusted nodes. Smart contracts handle and transfer assets of values, offering strong incentives for malicious attacks. Intrusion attacks are a popular type of malicious attacks. In this article, we propose ContractGuard, the first intrusion detection system (IDS) to defend Ethereum smart contracts against such attacks. Like IDSs for conventional programs, ContractGuard detects intrusion attempts as abnormal control flow. However, existing IDS techniques/tools are inapplicable to Ethereum smart contracts due to Ethereum's decentralized nature and its highly restrictive execution environment. To address these issues, we design ContractGuard by embedding it in the contracts to profile context-tagged acyclic paths, and optimizing it under the Ethereum gas-oriented performance model. The main goal is to minimize the overheads, to which the users will be extremely sensitive since the cost needs to be paid upfront in digital concurrency. Empirical investigation using real-life contracts deployed in the Ethereum mainnet shows that on average, ContractGuard only adds to 36.14 percent of the deployment overhead and 28.27 percent of the runtime overhead. Furthermore, we conducted controlled experiments and show that ContractGuard successfully guard against attacks on all real-world vulnerabilities and 83 percent of the seeded vulnerabilities.\n        ","projectUrl":null,"paperUrl":null,"slidesUrl":null,"bibtex":"@article{DBLP:journals/tsc/WangHXZC20,\n  author    = {Xinming Wang and\n               Jiahao He and\n               Zhijian Xie and\n               Gansen Zhao and\n               Shing{-}Chi Cheung},\n  title     = {ContractGuard: Defend Ethereum Smart Contracts with Embedded Intrusion\n               Detection},\n  journal   = {{IEEE} Trans. Serv. Comput.},\n  volume    = {13},\n  number    = {2},\n  pages     = {314--328},\n  year      = {2020},\n  url       = {https://doi.org/10.1109/TSC.2019.2949561},\n  doi       = {10.1109/TSC.2019.2949561},\n  timestamp = {Fri, 22 May 2020 21:56:08 +0200},\n  biburl    = {https://dblp.org/rec/journals/tsc/WangHXZC20.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"awards":[]},{"title":"Detecting numerical bugs in neural network architectures","date":"2020","authors":["Yuhao Zhang","Luyao Ren","Liqian Chen","Yingfei Xiong","Shing-Chi Cheung","Tao Xie"],"venue":"Proceedings of the 28th ACM Joint European SoftwareEngineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE ’20)","venueShort":"ESEC/FSE","tags":["Neural Networks","Formal Software Verification","Program Analysis"],"awards":["Distinguished Paper"],"abstract":"\nDetecting bugs in deep learning software at the architecture level provides additional benefits that detecting bugs at the model level does not provide. This paper makes the first attempt to conduct static analysis for detecting numerical bugs at the architecture level. We propose a static analysis approach for detecting numerical bugs in neural architectures based on abstract interpretation. Our approach mainly comprises two kinds of abstraction techniques, i.e., one for tensors and one for numerical values. Moreover, to scale up while maintaining adequate detection precision, we propose two abstraction techniques: tensor partitioning and (elementwise) affine relation analysis to abstract tensors and numerical values, respectively. We realize the combination scheme of tensor partitioning and affine relation analysis (together with interval analysis) as DEBAR, and evaluate it on two datasets: neural architectures with known bugs (collected from existing studies) and real-world neural architectures. The evaluation results show that DEBAR outperforms other tensor and numerical abstraction techniques on accuracy without losing scalability. DEBAR successfully detects all known numerical bugs with no false positives within 1.7–2.3 seconds per architecture. On the real-world architectures, DEBAR reports 529 warnings within 2.6–135.4 seconds per architecture, where 299 warnings are true positives.\n        ","projectUrl":null,"paperUrl":null,"slidesUrl":null,"bibtex":"@inproceedings{DBLP:conf/sigsoft/ZhangRC0C020,\n  author    = {Yuhao Zhang and\n               Luyao Ren and\n               Liqian Chen and\n               Yingfei Xiong and\n               Shing{-}Chi Cheung and\n               Tao Xie},\n  editor    = {Prem Devanbu and\n               Myra B. Cohen and\n               Thomas Zimmermann},\n  title     = {Detecting numerical bugs in neural network architectures},\n  booktitle = {{ESEC/FSE} '20: 28th {ACM} Joint European Software Engineering Conference\n               and Symposium on the Foundations of Software Engineering, Virtual\n               Event, USA, November 8-13, 2020},\n  pages     = {826--837},\n  publisher = {{ACM}},\n  year      = {2020},\n  url       = {https://doi.org/10.1145/3368089.3409720},\n  doi       = {10.1145/3368089.3409720},\n  timestamp = {Tue, 10 Nov 2020 10:58:23 +0100},\n  biburl    = {https://dblp.org/rec/conf/sigsoft/ZhangRC0C020.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null},{"title":"Boosting automated program repair with bug-inducing commits","date":"2020","authors":["Ming Wen","Yepang Liu","Shing-Chi Cheung"],"venue":"42nd International Conference on Software Engineering (NIER Track)","venueShort":"ICSE NIER","tags":["Program Repair"],"abstract":"\nThe search space explosion problem is a long-standing challenge for search-based automated program repair (APR). The operation space, which defines how to select appropriate mutation operators, and the ingredient space, which defines how to select appropriate code elements as fixing ingredients, are two major factors that determine the search space. Conventional approaches mainly devise fixing strategies via learning from frequent fixing patterns based on substantial patches collected from open-source projects. In this paper, we propose a new direction for search-based APR, that is to repair a bug via learning from how the bug was introduced instead of learning from how other bugs are frequently fixed. Our empirical study reveals that substantial mutation operators and fixing ingredients required to fix a bug can be inferred from the commit that introduced the bug. Based on the findings of our empirical study, we devised a preliminary fixing strategy based on bug-inducing commits, which is able to repair 8 new bugs that cannot be repaired by the state-of-the-art techniques. Such results demonstrate that our proposed new idea for searched-based APR is promising.\n        ","projectUrl":null,"paperUrl":null,"slidesUrl":null,"bibtex":"@inproceedings{DBLP:conf/icse/Wen0C20,\n  author    = {Ming Wen and\n               Yepang Liu and\n               Shing{-}Chi Cheung},\n  editor    = {Gregg Rothermel and\n               Doo{-}Hwan Bae},\n  title     = {Boosting automated program repair with bug-inducing commits},\n  booktitle = {{ICSE-NIER} 2020: 42nd International Conference on Software Engineering,\n               New Ideas and Emerging Results, Seoul, South Korea, 27 June - 19 July,\n               2020},\n  pages     = {77--80},\n  publisher = {{ACM}},\n  year      = {2020},\n  url       = {https://doi.org/10.1145/3377816.3381743},\n  doi       = {10.1145/3377816.3381743},\n  timestamp = {Mon, 03 May 2021 16:42:27 +0200},\n  biburl    = {https://dblp.org/rec/conf/icse/Wen0C20.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"awards":[]},{"title":"MR-Scout: Automated Synthesis of Metamorphic Relations from Existing Test Cases","date":"2024-06-29","authors":["Congying Xu","Valerio Terragni","Hengcheng Zhu","Jiarong Wu","Shing-Chi Cheung"],"venue":"ACM Transactions on Software Engineering and Methodology","venueShort":"TOSEM","tags":["Meramorphic Testing"],"projectUrl":"https://mr-scout.github.io/","paperUrl":"https://dl.acm.org/doi/abs/10.1145/3656340","arxivUrl":null,"abstract":null,"bibtex":null,"slidesUrl":null,"awards":[]},{"title":"MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing","date":"2024-09-01","authors":["Congying Xu","Songqiang Chen","Jiarong Wu","Shing-Chi Cheung","Valerio Terragni","Hengcheng Zhu","Jialun Cao"],"venue":"IEEE/ACM International Conference on Automated Software Engineering","venueShort":"ASE","tags":["LLM","Meramorphic Testing"],"projectUrl":"https://mr-adopt.github.io/","paperUrl":"https://arxiv.org/abs/2408.15815","arxivUrl":null,"abstract":null,"bibtex":null,"slidesUrl":null,"awards":[]},{"title":"Automatic build repair for test cases using incompatible Java versions","date":"2024","authors":["Ching Hang Mak","Shing-Chi Cheung"],"venue":"Information and Software Technology","venueShort":"INFSOF","tags":["Java","Program Analysis","Program Repair","Third-Party Libraries"],"abstract":"\n        Context:\n        Bug bisection is a common technique used to identify a revision that introduces a bug or indirectly fixes a bug, and often involves executing multiple revisions of a project to determine whether the bug is present within the revision. However, many legacy revisions often cannot be successfully compiled due to changes in the programming language or tools used in the compilation process, adding complexity and preventing automation in the bisection process.\n        \n        Objective:\n        In this paper, we introduce an approach to repair test cases of Java projects by performing dependency minimization. Our approach aims to remove classes and methods that are not required for the execution of one or more test cases. Unlike existing state-of-the-art techniques, our approach performs minimization at source-level, which allows compile-time errors to be fixed.\n        \n        Method:\n        A standalone Java tool implementing our technique was developed, and we evaluated our technique using subjects from Defects4J retargeted against Java 8 and 17.\n        \n        Results:\n        Our evaluation showed that a majority of subjects can be repaired solely by performing minimization, including replicating the test results of the original version. Furthermore, our technique is also shown to achieve accurate minimized results, while only adding a small overhead to the bisection process.\n        \n        Conclusion:\n        Our proposed technique is shown to be effective for repairing build failures with minimal overhead, making it suitable for use in automated bug bisection. Our tool can also be adapted for use cases such as bug corpus creation and refactoring. \n        ","projectUrl":"https://github.com/Derppening/test-dependency-minimization/","arxivUrl":"https://arxiv.org/abs/2404.17818","bibtex":"@article{mak2024automatic,\n        title={Automatic build repair for test cases using incompatible java versions},\n        author={Mak, Ching Hang and Cheung, Shing-Chi},\n        journal={Information and Software Technology},\n        pages={107473},\n        year={2024},\n        publisher={Elsevier}\n        }","paperUrl":null,"slidesUrl":null,"awards":[]},{"title":"CINA: Suppressing the Detection of Unstable Context Inconsistency","date":"2015","authors":["Chang Xu","Wang Xi","Shing-Chi Cheung","Xiaoxing Ma","Chun Cao","Jian Lu"],"venue":"IEEE Transactions of Software Engineering 41(9), September 2015","venueShort":"TSE","tags":[],"abstract":"\n    Context-aware applications adapt their behavior based on contexts. Contexts can, however, be incorrect. A popular means to build dependable applications is to augment them with a set of constraints to govern the consistency of context values. These constraints are evaluated upon context changes to detect inconsistencies so that they can be timely handled. However, we observe that many context inconsistencies are unstable. They vanish by themselves and do not require handling. Such inconsistencies are detected due to misaligned sensor sampling or improper inconsistency detection scheduling. We call them unstable context inconsistencies (or STINs). STINs should be avoided to prevent unnecessary inconsistency handling and unstable behavioral adaptation to applications. In this article, we study STINs systematically, from examples to theoretical analysis, and present algorithms to suppress their detection. Our key insight is that only certain patterns of context changes can make a consistency constraint subject to the detection of STINs. We derive such patterns and proactively use them to suppress the detection of STINs. We implemented our idea and applied it to real-world applications. Experimental results confirmed its effectiveness in suppressing the detection of numerous STINs with negligible overhead, while preserving the detection of stable context inconsistencies that require inconsistency handling.\n    ","paperUrl":"https://www.computer.org/csdl/trans/ts/2015/09/07078871-abs.html","bibtex":"@article{DBLP:journals/tse/XuXCMCL15,\n  author    = {Chang Xu and\n               Wang Xi and\n               Shing{-}Chi Cheung and\n               Xiaoxing Ma and\n               Chun Cao and\n               Jian Lu},\n  title     = {Cina: Suppressing the Detection of Unstable Context Inconsistency},\n  journal   = {{IEEE} Trans. Software Eng.},\n  volume    = {41},\n  number    = {9},\n  pages     = {842--865},\n  year      = {2015},\n  url       = {http://dx.doi.org/10.1109/TSE.2015.2418760},\n  doi       = {10.1109/TSE.2015.2418760},\n  timestamp = {Thu, 10 Dec 2015 11:33:07 +0100},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/tse/XuXCMCL15},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Sifter: A Service Isolation Strategy for Internet Applications","date":"2019","authors":["Chunyang Ye","Shing-Chi Cheung","W.K. Chan"],"venue":"IEEE Transactions on Services Computing 2019","venueShort":"TSC","tags":[],"abstract":"\n    Service oriented architecture (SOA) provides a flexible platform to build collaborative Internet applications by composing existing self-contained and autonomous services. However, the implicit interactions among the concurrently provisioned services may introduce interference to Internet applications and cause them behave abnormally. It is thus desirable to isolate services to safeguard their application consistency. Existing approaches mostly address this problem by restricting concurrent execution of services to avoid all the implicit interactions. These approaches, however, compromise the performance and flexibility of Internet applications due to the long running nature of services. This paper presents Sifter, a new service isolation strategy for Internet applications. We devise in this strategy a novel static approach to analyze the potential implicit interactions among the services and their impacts on the consistency of the associated Internet applications. By locating only those afflicted implicit interactions that may violate the application consistency, a novel approach based on exception handling and behavior constraints is customized to involved services to eliminate their impacts. We show that this approach exempts the consistency property of Internet applications from being interfered at runtime. The experimental results show that our approach has a better performance than existing solutions.\n    ","paperUrl":"materials/TSC-cyye.pdf","bibtex":"@ARTICLE{8493286,\nauthor={C. Ye and Shing-Chi Cheung and W. K. Chan},\njournal={IEEE Transactions on Services Computing},\ntitle={Sifter: A Service Isolation Strategy for Internet Applications},\nyear={2019},\nvolume={},\nnumber={},\npages={1-1},\nmonth={},}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Testing Multithreaded Programs via Thread Speed Control","date":"2018","authors":["Dongjie Chen","Yanyan Jiang","Chang Xu","Xiaoxing Ma","Jian Lu"],"venue":"26th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2018), Lake Buena Vista, Florida, USA, Nov 2018","venueShort":"ESEC/FSE","tags":[],"abstract":"\n    Intensive dependencies of a Java project on third-party libraries can easily lead to the presence of multiple library or class versions on its classpath. When this happens, JVM will load one version and shadows the others. Dependency conflict (DC) issues occur when the loaded version fails to cover a required feature (e.g., method) referenced by the project, thus causing runtime exceptions. However, the warnings of duplicate classes or libraries detected by existing build tools such as Maven can be benign since not all instances of duplication will induce runtime exceptions, and hence are often ignored by developers. In this paper, we conducted an empirical study on real-world DC issues collected from large open source projects. We studied the manifestation and fixing patterns of DC issues. Based on our findings, we designed Decca, an automated detection tool that assesses DC issues' severity and filters out the benign ones. Our evaluation results on 30 projects show that Decca achieves a precision of 0.923 and recall of 0.766 in detecting high-severity DC issues. Decca also detected new DC issues in these projects. Subsequently, 20 DC bug reports were filed, and 11 of them were confirmed by developers. Issues in 6 reports were fixed with our suggested patches.\n    ","paperUrl":"https://cs.nju.edu.cn/changxu/1_publications/ESECFSE18.pdf","projectUrl":"https://midwinter1993.github.io/Schnauzer/","bibtex":"@inproceedings{chen_testing_2018,\n  author    = {Dongjie Chen and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Jian Lu},\n  title     = {Testing multithreaded programs via thread speed control},\n  pages     = {to appear},\n  year      = {2018},\n  booktitle = {Proceedings of the 26th Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE)},\n  pdf       = {/spar/publication/chen_testing_2018.pdf},\n  code      = {https://midwinter1993.github.io/Schnauzer/},\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Understanding and Detecting Callback Compatibility Issues for Android Applications","date":"2018","authors":["Huaxun Huang","Lili Wei","Yepang Liu","Shing-Chi Cheung"],"venue":"2018 33rd ACM/IEEE International Conference on Automated Software Engineering (ASE '18), September 2018, Montpellier, France","venueShort":"ASE","tags":[],"abstract":"\n    The control flows of Android apps are largely driven by the protocols that govern how callback APIs are invoked in response to various event.\nWhen these callback APIs evolve along with the Android framework, the changes in their invocation protocols can induce unexpected control flows to existing Android apps, causing various compatibility issues. We refer to these issues as callback compatibility issues.\nWhile Android framework updates have received due attention, little is known about their impacts on app control flows and the callback compatibility issues thus induced.\nTo bridge the gap, we examined Android documentations\nand conducted an empirical study on 100 real-world callback compatibility issues\nto investigate how these issues were induced by callback API evolutions. \nBased on our empirical findings, we propose a graph-based model to capture the control flow inconsistencies caused by API evolutions and devise a static analysis technique, CIDER, to detect callback compatibility issues.\nOur evaluation of CIDER on 20 popular open-source Android apps shows that CIDER is effective. It detected 13 new callback compatibility issues in these apps, among which 12 issues were confirmed and 9 issues were fixed.\n    ","paperUrl":"materials/callback.pdf","projectUrl":"https://cideranalyzer.github.io/","bibtex":"@inproceedings {ASE18,\n  title = {{Understanding and Detecting Callback Compatibility Issues for Android Applications}},\n  author = {Huaxun Huang, Lili Wei, Yepang Liu, Shing-Chi Cheung},\n  booktitle = {Proceedings of the 2018 33rd ACM/IEEE International Conference on Automated Software Engineering, {ASE} 2018},\n  year = {2018},\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"A Tale of Two Cities: How WebView Induces Bugs to Android Applications","date":"2018","authors":["Jiajun Hu","Lili Wei","Yepang Liu","Shing-Chi Cheung","Huaxun Huang"],"venue":"Proceedings of 2018 33rd ACM/IEEE International Conference on Automated Software Engineering (ASE'18), September 3-7, 2018, Montpellier, France","venueShort":"ASE","tags":[],"abstract":"\n    WebView is a widely used Android component that augments a native app with web browser capabilities. It eases the interactions between an app’s native code and web code. However, the interaction mechanism of WebView induces new types of bugs in Android apps. Understanding the characteristics and manifestation of these WebView-induced bugs (ωBugs for short) facilitates the correct usages of WebViews in Android apps. This motivates us to conduct the first empirical study on ωBugs based on those found in popular open-source Android apps. Our study identified the major root causes and consequences of ωBugs and made interesting observations that can be leveraged for detecting and diagnosing ωBugs. Based on the empirical study, we further propose an automated testing technique ωDroid to effectively expose ωBugs in Android apps. In our experiments, ωDroid successfully discovered 30 unique and previously-unknown ωBugs when applied to 146 open-source Android apps. We reported the 30 ωBugs to the corresponding app developers. Out of these 30 ωBugs, 14 were confirmed and 7 of them were fixed. This shows that ωDroid can effectively detect ωBugs that are of the developers’ concern.\n    ","paperUrl":"materials/wDroid.pdf","projectUrl":"http://home.cse.ust.hk/~jhuao/wDroid.html","bibtex":"@inproceedings {ASE18Hu,\n  title = {{A Tale of Two Cities: How WebView Induces Bugs to Android Applications}},\n  author = {Jiajun Hu, Lili Wei, Yepang Liu, Shing-Chi Cheung, Huaxun Huang},\n  booktitle = {{Proceedings of the 2018 33rd ACM/IEEE International Conference on Automated Software Engineering (ASE’18)}},\n  year = {2018},\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Synthesizing Relation-Aware Entity Transformation by Examples","date":"2018","authors":["Jiarong Wu","Yanyan Jiang","Chang Xu","Shing-Chi Cheung","Xiaoxing Ma","Jian Lu"],"venue":"40th International Conference on Software Engineering (ICSE 2018 Poster)","venueShort":"ICSE Poster","tags":[],"abstract":"\n    Recently, programming by examples (PBE) technique achieves a great success in processing and transforming data entities, yet existing approaches generally fall short on the tasks concerning entity relations. This paper presents ENTER, a domain-agnostic language for relation-aware entity transformation synthesis. It leverages the combination of two basic relations, the equivalence relation and the total order relation, to succinctly express complex entity relations. ENTER can be instantiated with domain-specific elements to solve a wide range of entity transformation tasks.\n    ","paperUrl":"https://cs.nju.edu.cn/changxu/1_publications/ICSE18.pdf","bibtex":"@inproceedings{wu_synthesizing_2018,\n  author    = {Jiarong Wu and Yanyan Jiang and Chang Xu and S. C. Cheung and Xiaoxing Ma and Jian Lu},\n  title     = {Synthesizing relation-aware entity transformation by examples},\n  booktitle = {Proceedings of the 40th International Conference on Software Engineering (ICSE Poster Track)},\n  pages     = {to appear},\n  year      = {2018},\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"AATT+: Effectively Manifesting Concurrency Bugs in Android Apps","date":"2018","authors":["Jue Wang","Yanyan Jiang","Chang Xu","Qiwei Li","Tianxiao Gu","Jun Ma","Xiaoxing Ma","Jian Lu"],"venue":"Science of Computer Programming (SCP)","venueShort":"SCP","tags":[],"abstract":"\n    Smartphones are indispensable in people’s daily activities, and smartphone apps tend to be increasingly concurrent due to the wide use of multi-core devices and technologies. Due to this tendency, developers are increasingly unable to tackle the complexity of concurrent apps and to avoid subtle concurrency bugs. To better address this issue, we propose a novel approach to detecting concurrency bugs in Android apps based on the fact that one can generate simultaneous input events and their schedules for an app, which would easily trigger concurrency bugs in an app. We conduct systematic state space exploration to find potentially conflicting resource accesses in an Android app. The app is then automatically pressure-tested by guided event and schedule generation. We implemented our prototype tool named AATT+ and evaluated it with two sets of real-world Android apps. Benchmarking using 15 Android apps with previously known concurrency bugs, AATT+ and existing concurrency-unaware techniques detected 10 and 1 bugs, respectively. Evaluated with another set of 17 popu- lar Android apps, AATT+ detected 11 concurrency bugs and 7 of them were previously unknown, achieving an over 80% higher detection rate than existing concurrency-unaware techniques.\n    ","paperUrl":"https://cs.nju.edu.cn/changxu/1_publications/SCP18.pdf","projectUrl":"https://github.com/skull591/AATT","bibtex":"@inproceedings{wang_aatt_2018,\n  author  = {Jue Wang and Yanyan Jiang and Chang Xu and Qiwei Li and Tianxiao Gu and Jun Ma and Xiaoxing Ma and Jian Lu},\n  title   = {AATT+: Effectively manifesting concurrency bugs in Android apps},\n  journal = {Science of Computer Programming (SCP)},\n  year    = {2018},\n  volume  = {163},\n  pages   = {1--18},\n  url     = {https://doi.org/10.1016/j.scico.2018.03.008},\n  code    = {https://github.com/skull591/AATT},\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Hybrid CPU-GPU Constraint Checking: Towards Efficient Context Consistency","date":"2016","authors":["Jun Sui","Chang Xu","Shing-Chi Cheung","Wang Xi","Yanyan Jiang","Chun Cao","Xiaoxing Ma","Jian Lu"],"venue":"Information and Software Technology (IST) 2016","venueShort":"IST","tags":[],"abstract":"\n    Context: modern software increasingly relies on contexts about computing environments to provide adaptive and smart services. Such contexts, captured and derived from environments of uncontrollable noises, can be inaccurate, incomplete or even in conflict with each other. This is known as the context inconsistency problem, and should be addressed by checking contexts in time to prevent abnormal behavior to applications. One popular way is to check application contexts against consistency constraints before their uses, but this can bring heavy computation due to tremendous amount of contexts in changing environments. Existing efforts improve the checking performance by incremental or concurrent computation, but they rely on CPU computing only and can consume valuable CPU capabilities that should otherwise be used by applications themselves.\n\nObjective: in this article, we propose GAIN, a GPU-supported technique to checking consistency constraints systematically and efficiently.\n\nMethod: GAIN can automatically recognize a constraint’s parallel units and associate these units and their runtime instances with matched contexts under checking. GAIN coordinates CPU and GPU and utilizes their capabilities for task preparation and context checking, respectively.\n\nResult: we evaluate GAIN experimentally with millions of real-life context data. The evaluation results show that GAIN can work at least 2–7 × faster and requires much less CPU usage than CPU-based techniques. Besides, GAIN can also work stably for different and varying workloads.\n\nConclusion: our experience with GAIN suggests its high efficiency in constraint checking for context consistency as well as its wide applicability to different application workloads.\n    ","paperUrl":"http://www.sciencedirect.com/science/article/pii/S095058491500169X","bibtex":"@article{Sui_IST2016,\n  author    = {Jun Sui and\n               Chang Xu and\n               Shing{-}Chi Cheung and\n               Wang Xi and\n               Yanyan Jiang and\n               Chun Cao and\n               Xiaoxing Ma and\n               Jian Lu},\n  title     = {Hybrid {CPU-GPU} constraint checking: Towards efficient context consistency},\n  journal   = {Information {&} Software Technology},\n  volume    = {74},\n  pages     = {230--242},\n  year      = {2016},\n  url       = {http://dx.doi.org/10.1016/j.infsof.2015.10.003},\n  doi       = {10.1016/j.infsof.2015.10.003},\n  timestamp = {Mon, 25 Apr 2016 19:47:34 +0200},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/infsof/SuiXCX0CML16},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Taming Android Fragmentation: Characterizing and Detecting Compatibility Issues for Android Apps","date":"2016","authors":["Lili Wei","Yepang Liu","Shing-Chi Cheung"],"venue":"31st IEEE/ACM International Conference on Automated Software Engineering (ASE 2016), Singapore, Sept 2016","venueShort":"ASE","tags":["Android","Empirical Study","Fault Detection"],"awards":["Distinguished Paper"],"abstract":"\n    Android ecosystem is heavily fragmented. The numerous combinations of different device models and operating system versions make it impossible for Android app developers to exhaustively test their apps. As a result, various compatibility issues arise, causing poor user experience. However, little is known on the characteristics of such fragmentation-induced compatibility issues and no mature tools exist to help developers quickly diagnose and fix these issues. To bridge the gap, we conducted an empirical study on 191 real-world compatibility issues collected from popular open-source Android apps. Our study characterized the symptoms and root causes of compatibility issues, and disclosed that the patches of these issues exhibit common patterns. With these findings, we propose a technique named FicFinder to automatically detect compatibility issues in Android apps. FicFinder performs static code analysis based on a model that captures Android APIs as well as their associated context by which compatibility issues are triggered. FicFinder reports actionable debugging information to developers when it detects potential issues. We evaluated FicFinder with 27 large-scale open-source Android apps. The results show that FicFinder can precisely detect compatibility issues in these apps and uncover previously-unknown issues.\n    ","paperUrl":"http://sccpu2.cse.ust.hk/ficfinder/ASE_FicFinder.pdf","projectUrl":"http://sccpu2.cse.ust.hk/ficfinder/index.html","bibtex":"@inproceedings{Wei_ASE16,\n\tauthor    = {Lili Wei and Yepang Liu and\n\t\t    \t Shing{-}Chi Cheung},\n\ttitle     = {Taming Android Fragmentation: Characterizing and Detecting Compatibility Issues for Android Apps},\n\tbooktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, {ASE} 2016},\n\tyear      = {2016}\n}","arxivUrl":null,"slidesUrl":null},{"title":"OASIS: Prioritizing Static Analysis Warnings for Android Apps Based on App User Reviews","date":"2017","authors":["Lili Wei","Yepang Liu","Shing-Chi Cheung"],"venue":"11th joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE 2017), Paderborn, Germany, Sept 2017","venueShort":"ESEC/FSE","tags":[],"abstract":"\n    Lint is a widely-used static analyzer for detecting bugs/issues in Android apps. However, it can generate many false warnings. One existing solution to this problem is to leverage project history data (e.g., bug fixing statistics) for warning prioritization. Unfortunately, such techniques are biased toward a project’s archived warnings and can easily miss newissues. Anotherweakness is that developers cannot readily relate the warnings to the impacts perceivable by users. To overcome these weaknesses, in this paper, we propose a semantics-aware approach, OASIS, to prioritizing Lint warnings by leveraging app user reviews. OASIS combines program analysis and NLP techniques to recover the intrinsic links between the Lint warnings for a given app and the user complaints on the app problems caused by the issues of concern. OASIS leverages the strength of such links to prioritize warnings. We evaluated OASIS on six popular and large-scale open-source Android apps. The results show that OASIS can effectively prioritize Lint warnings and help identify new issues that are previously-unknown to app developers.\n    ","paperUrl":"materials/OASIS_author_copy.pdf","bibtex":"@inproceedings{Wei_FSE17,\n\tauthor    = {Lili Wei and Yepang Liu and\n\t\t    \t Shing{-}Chi Cheung},\n\ttitle     = {OASIS: Prioritizing Static Analysis Warnings for Android Apps Based on App User Reviews},\n\tbooktitle = {joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, {ESEC/FSE} 2017},\n\tyear      = {2017}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Understanding and Detecting Fragmentation-Induced Compatibility Issues for Android Apps","date":"2020","authors":["Lili Wei","Yepang Liu","Shing-Chi Cheung","Huaxun Huang","Xuan Lu","Xuanzhe Liu"],"venue":"IEEE Transactions on Software Engineering 2020","venueShort":"TSE","tags":["Android","Bug Detection"],"abstract":"\n    Android ecosystem is heavily fragmented. The numerous combinations of different device models and operating system versions make it impossible for Android app developers to exhaustively test their apps, and thus various compatibility issues arise. Unfortunately, little is known on the characteristics of such fragmentation-induced compatibility issues. No mature tools exist to help developers quickly diagnose and fix these issues. To bridge the gap, we conducted an empirical study on 220 real-world compatibility issues collected from five popular open-source Android apps. We further interviewed Android practitioners and conducted an online survey to gain insights from real practices. Via the studies, we characterized compatibility issues, investigated common practices to handle compatibility issues, and disclosed that these issues exhibit common patterns. With these findings, we propose a technique, FicFinder, to automatically detect compatibility issues in Android apps. FicFinder performs static code analysis based on a model that captures Android APIs as well as their associated context by which compatibility issues can be triggered. FicFinder reports actionable debugging information to developers when it detects potential issues. We evaluated FicFinder with 53 large-scale open-source Android apps. The results show that FicFinder can precisely detect compatibility issues in these apps and uncover previously-unknown issues.\n    ","paperUrl":"materials/TSE19-lili.pdf","bibtex":"@ARTICLE{DBLP:journals/tse/WeiLCHLL20,\n  author    = {Lili Wei and\n               Yepang Liu and\n               Shing{-}Chi Cheung and\n               Huaxun Huang and\n               Xuan Lu and\n               Xuanzhe Liu},\n  title     = {Understanding and Detecting Fragmentation-Induced Compatibility Issues\n               for Android Apps},\n  journal   = {{IEEE} Trans. Software Eng.},\n  volume    = {46},\n  number    = {11},\n  pages     = {1176--1199},\n  year      = {2020},\n  url       = {https://doi.org/10.1109/TSE.2018.2876439},\n  doi       = {10.1109/TSE.2018.2876439},\n  timestamp = {Thu, 31 Dec 2020 01:35:38 +0100},\n  biburl    = {https://dblp.org/rec/journals/tse/WeiLCHLL20.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"PIVOT: Learning API-Device Correlations to Facilitate Android Compatibility Issue Detection","date":"2019","authors":["Lili Wei","Yepang Liu","Shing-Chi Cheung"],"venue":"International Conference on Software Engineering 2019, Technical Research Paper, Montréal, QC, Canada, 25 May - 31 May","venueShort":"ICSE","tags":[],"awards":["Distinguished Artifact"],"abstract":"\n    The heavily fragmented Android ecosystem has induced various compatibility issues in Android apps. The search space for such fragmentation-induced compatibility issues (FIC issues) is huge, comprising three dimensions: device models, Android OS versions, and Android APIs. FIC issues, especially those arising from device models, evolve quickly with the frequent release of new device models to the market. As a result, an automated technique is desired to maintain timely knowledge of such FIC issues, which are mostly undocumented. In this paper, we propose such a technique, PIVOT, that automatically learns API-device correlations of FIC issues from existing Android apps. PIVOT extracts and prioritizes API-device correlations from a given corpus of Android apps. We evaluated PIVOT with popular Android apps on Google Play. Evaluation results show that PIVOT can effectively prioritize valid API-device correlations for app corpora collected at different time. Leveraging the knowledge in the learned API-device correlations, we further conducted a case study and successfully uncovered ten previously-undetected FIC issues in open-source Android apps.\n    ","paperUrl":"materials/ICSE19-lili.pdf","projectUrl":"https://ficissuepivot.github.io/Pivot/","bibtex":"@inproceedings {ICSE19Wei,\n  title = {{PIVOT: Learning API-Device Correlations to Facilitate Android Compatibility Issue Detection}},\n  author = {Lili Wei and Yepang Liu and Shing-Chi Cheung},\n  booktitle = {{Proceedings of the 41th International Conference on Software Engineering}, {ICSE 2019}},\n  year = {2019},\n  pages = {11}\n}","arxivUrl":null,"slidesUrl":null},{"title":"Which Generated Test Failures Are Fault Revealing? Prioritizing Failures Based on Inferred Precondition Violations using PAF","date":"2018","authors":["Mijung Kim","Shing-Chi Cheung","Sunghun Kim"],"venue":"The ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Technical Research Paper, Lake Buena Vista, Florida, 4 Nov - 9 Nov 2018","venueShort":"ESEC/FSE","tags":[],"abstract":"\n    Automated unit testing tools, such as Randoop, have been developed to produce failing tests as means of finding faults. However, these tools often produce false alarms, so are not widely used in practice. The main reason for a false alarm is that the generated failing test violates an implicit precondition of the method under test, such as a field should not be null at the entry of the method. This condition is not explicitly programmed or documented but implicitly assumed\n\t\t\t\tby developers. To address this limitation, we propose a technique called Paf to cluster generated test failures due to the same cause and reorder them based on their likelihood of violating an implicit precondition of the method under test. From various test executions, Paf observes their dataflows to the variables whose values are used when the program fails. Based on the dataflow similarity and where these values are originated, Paf clusters failures and determines\n\t\t\t\ttheir likelihood of being fault revealing. We integrated Paf into Randoop. Our empirical results on open-source projects show that Paf effectively clusters fault revealing tests arising from the same\n\t\t\t\tfault and successfully prioritizes the fault-revealing ones.\n    ","paperUrl":"materials/fse18-mijung.pdf","bibtex":"@inproceedings{kim2018paf,\n title={Which Generated Test Failures Are Fault Revealing? Prioritizing\nFailures Based on Inferred Precondition Violations using PAF},\n author={Kim, Mijung and Cheung, Shing-Chi and Kim, Sunghun},\n booktitle={Proceedings of the 2018 26th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2018)},\n pages={1--12},\n year={2018},\n organization={ACM}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Locus: Locating Bugs from Software Changes","date":"2016","authors":["Ming Wen","Rongxin Wu","Shing-Chi Cheung"],"venue":"31st IEEE/ACM International Conference on Automated Software Engineering (ASE 2016), Singapore, Sept 2016","venueShort":"ASE","tags":[],"abstract":"\n    Various information retrieval (IR) based techniques have been proposed recently to locate bugs automatically at the file level. However, their usefulness is often compromised by the coarse granularity of files and the lack of contextual information. To address this, we propose to locate bugs using software changes, which offer finer granularity than files and provide important contextual clues for bug-fixing. We observe that bug inducing changes can facilitate the bug fixing process. For example, it helps triage the bug fixing task to the developers who committed the bug inducing changes or enables developers to fix bugs by reverting these changes. Our study further identifies that change logs and the naturally small granularity of changes can help boost the performance of IR-based bug localization. Motivated by these observations, we propose an IR-based approach Locus to locate bugs from software changes, and evaluate it on six large open source projects. The results show that Locus outperforms existing techniques at the source file level localization significantly. MAP and MRR in particular have been improved, on average, by 20.1% and 20.5%, respectively. Locus is also capable of locating the inducing changes within top 5 for 41.0% of the bugs. The results show that Locus can significantly reduce the number of lines needing to be scanned to locate the bug compared with existing techniques.\n    ","paperUrl":"http://home.cse.ust.hk/~mwenaa/paper/ASE16-Locus.pdf","projectUrl":"http://www.cse.ust.hk/~mwenaa/Locus.html","bibtex":"@inproceedings{Wei_ASE16,\n\tauthor    = {Ming Wen and Rongxin Wu and\n\t\t    \t Shing{-}Chi Cheung},\n\ttitle     = {Locus: Locating Bugs from Software Changes},\n\tbooktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, {ASE} 2016},\n\tyear      = {2016}\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Context-Aware Patch Generation for Better Automated Program Repair","date":"2018","authors":["Ming Wen","Junjie Chen","Rongxin Wu","Dan Hao","Shing-Chi Cheung"],"venue":"International Conference on Software Engineering, Technical Research Paper, Gothenburg, Sweden, May 27 - 3 June 2018","venueShort":"ICSE","tags":[],"abstract":"\n    The effectiveness of search-based automated program repair is limited in the number of correct patches that can be successfully generated.\nThere are two causes of such limitation. \nFirst, the search space does not contain the correct patch. \nSecond, the search space is huge and therefore the correct patch cannot be generated (ie correct patches are either generated after incorrect plausible ones or not generated within the time budget).\n\nTo increase the likelihood of including the correct patches in the search space, we propose to work at a fine granularity in terms of AST nodes.\nThis, however, will further enlarge the search space, increasing the challenge to find the correct patches.\nWe address the challenge by devising a strategy to prioritize the candidate patches based on their likelihood of being correct.\nSpecifically, we study the use of AST nodes' context information to estimate the likelihood.\n\nIn this paper, we propose CapGen, a context-aware patch generation technique.\nThe novelty which allows CapGen to produce more correct patches lies in three aspects:\n(1) The fine-granularity design enables it to find more correct fixing ingredients;\n(2) The context-aware prioritization of mutation operators enables it to constrain the search space;\n(3) Three context-aware models enable it to rank correct patches at high positions before incorrect plausible ones.\nWe evaluate CapGen on Defects4J and compare it with the state-of-the-art program repair techniques.\nOur evaluation shows that CapGen outperforms and complements existing techniques.\nCapGen achieves a high precision of 84.00% and can prioritize the correct patches before 98.78% of the incorrect plausible ones.\n    ","paperUrl":"materials/Repair.pdf","bibtex":"@inproceedings {ICSE18,\n  title = {{Context-Aware Patch Generation for Better Automated Program Repair}},\n  author = {Ming, Wen and Junjie, Chen and Rongxin, Wu and Dan, Hao and Shing-Chi, Cheung},\n  booktitle = {{Proceedings of the 40th International Conference on Software Engineering}},\n  series = {ICSE 2016},\n  year = {2018},\n  doi = {10.1145/3180155.3180233},\n  url = {http://home.cse.ust.hk/~mwenaa/paper/Repair.pdf},\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"How Well Do Change Sequences Predict Defects? Sequence Learning from Software Changes","date":"2020","authors":["Ming Wen","Rongxin Wu","Shing-Chi Cheung"],"venue":"IEEE Transactions on Software Engineering 2020","venueShort":"TSE","tags":["Software Analytics","Defect Prediction"],"abstract":"\n    Software defect prediction, which aims to identify defective modules, can assist developers in finding bugs and prioritizing limited quality assurance resources. Various features to build defect prediction models have been proposed and evaluated. Among them, process metrics are one important category. Yet, existing process metrics are mainly encoded manually from change histories and ignore the sequential information arising from the changes during software evolution. Unlike traditional process metrics used for existing defect prediction models, change sequences are mostly vectors of variable length. This makes it difficult to apply such sequences directly in prediction models that are driven by conventional classifiers. To resolve this challenge, we utilize Recurrent Neural Network (RNN), which is a deep learning technique, to encode features from sequence data automatically. In this paper, we propose a novel approach called Fences, which extracts six types of change sequences covering different aspects of software changes via fine-grained change analysis. It approaches defects prediction by mapping it to a sequence labeling problem solvable by RNN. Our evaluations on 10 open source projects show that Fences can predict defects with high performance. Fences also outperforms the state-of-the-art technique which learns semantic features automatically from static code via deep learning.\n    ","paperUrl":"materials/TSE19-ming.pdf","bibtex":"@article{DBLP:journals/tse/WenWC20,\n  author    = {Ming Wen and\n               Rongxin Wu and\n               Shing{-}Chi Cheung},\n  title     = {How Well Do Change Sequences Predict Defects? Sequence Learning from\n               Software Changes},\n  journal   = {{IEEE} Trans. Software Eng.},\n  volume    = {46},\n  number    = {11},\n  pages     = {1155--1175},\n  year      = {2020},\n  url       = {https://doi.org/10.1109/TSE.2018.2876256},\n  doi       = {10.1109/TSE.2018.2876256},\n  timestamp = {Tue, 02 Feb 2021 18:29:15 +0100},\n  biburl    = {https://dblp.org/rec/journals/tse/WenWC20.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Exploring and Exploiting the Correlations between Bug-Inducing and Bug-Fixing Commits","date":"2019","authors":["Ming Wen","Rongxin Wu","Yepang Liu","Yongqiang Tian","Xuan Xie","Shing-Chi Cheung","Zhendong Su"],"venue":"The ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering 2019, Technical Research Paper, Tallinn, Estonia","venueShort":"ESEC/FSE","tags":[],"abstract":"\n    Bug-inducing commits provide important information to understand when and how bugs were introduced.\n\t\t\t\tTherefore, they have been extensively investigated by existing studies and frequently leveraged to facilitate bug fixings in industrial practices.\n\n\t\t\t\tDue to the importance of bug-inducing commits in software debugging,\n\t\t\t\twe are motivated to conduct the first systematic empirical study to explore the correlations between bug-inducing and bug-fixing commits in terms of code elements and modifications.\n\t\t\t\tTo facilitate the study, we collected the inducing and fixing commits for 333 bugs from seven large open-source projects.\n\t\t\t\tThe empirical findings reveal important and significant correlations between a bug's inducing and fixing commits.\n\t\t\t\tWe further exploit the usefulness of such correlation findings from two aspects.\n\t\t\t\tFirst, they explain why the SZZ algorithm, the most widely-adopted approach to collecting bug-inducing commits, is imprecise.\n\t\t\t\tIn view of SZZ's imprecision, we revisited the findings of previous studies based on SZZ,\n\t\t\t\tand found that 8 out of 10 previous findings are significantly affected by SZZ's imprecision.\n\t\t\t\tSecond, they shed lights on the design of automated debugging techniques.\n\t\t\t\tFor demonstration, we designed approaches that exploit the correlations with respect to statements and change actions.\n\t\t\t\tOur experiments on \textsc{Defects4J} show that our approaches can boost the performance of fault localization significantly and also advance existing APR techniques.\n    ","paperUrl":"materials/FSE19-ming.pdf","projectUrl":"https://github.com/justinwm/InduceBenchmark","bibtex":"@inproceedings{wen2019exploring,\n  title={Exploring and Exploiting the Correlations between Bug-Inducing and Bug-Fixing Commits.},\n  author={Wen, Ming and Wu, Rongxin and Liu, Yepang and Tian, Yongqiang and Xie, Xuan and Cheung, Shing-Chi and Su, Zhendong},\n  booktitle={Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},\n  to appear,\n  year={2019},\n  organization={ACM}\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Exposing Library API Misuses via Mutation Analysis","date":"2019","authors":["Ming Wen","Yepang Liu","Rongxin Wu","Xuan Xie","Shing-Chi Cheung","Zhendong Su"],"venue":"International Conference on Software Engineering 2019, Technical Research Paper, Montréal, QC, Canada, 25 May - 31 May","venueShort":"ICSE","tags":[],"abstract":"\n    Misuses of library APIs are pervasive and often lead to software crashes and vulnerability issues. Various static analysis tools have been proposed to detect library API misuses. They often involve mining frequent patterns from a large number of correct API usage examples, which can be hard to obtain in practice. They also suffer from low precision due to an over-simplified assumption that a deviation from frequent usage patterns indicates a misuse.\n\t\t\t\tWe make two observations on the discovery of API misuse patterns. First, API misuses can be represented as mutants of the corresponding correct usages. Second, whether a mutant will introduce a misuse can be validated via executing it against a test suite and analyzing the execution information. Based on these observations, we propose MUTAPI, the first approach to discovering API misuse patterns via mutation analysis. To effectively mimic API misuses based on correct usages, we first design eight effective mutation operators inspired by the common characteristics of API misuses. MUTAPI generates mutants by applying these mutation operators on a set of client projects and collects mutant-killing tests as well as the associated stack traces. Misuse patterns are discovered from the killed mutants that are prioritized according to their likelihood of causing API misuses based on the collected information. We applied MUTAPI on 16 client projects with respect to 73 popular Java APIs. The results show that MUTAPI is able to discover substantial API misuse patterns with a high precision of 0.78. It also achieves a recall of 0.49 on the MUBENCH benchmark, which outperforms the state-of-the-art techniques.\n    ","paperUrl":"materials/ICSE19-ming.pdf","bibtex":"@inproceedings {WEN2019API,\n  title = {{Exposing Library API Misuses via Mutation Analysis}},\n  author = {Ming, Wen and Yepang, Liu and Rongxin, Wu and Xuan, Xie and Shing-Chi, Cheung and Zhendong, Su},\n  booktitle = {{Proceedings of the 41th International Conference on Software Engineering}},\n  series = {ICSE 2019},\n  year = {2019},\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Historical Spectrum based Fault Localization","date":"2021","authors":["Ming Wen","Junjie Chen","Yongqiang Tian","Rongxin Wu","Dan Hao","Shi Han","Shing-Chi Cheung"],"venue":"Transactions of Software Engineering 2021","venueShort":"TSE","tags":[],"abstract":"\n    Spectrum-based fault localization (SBFL) techniques are widely studied and have been evaluated to be effective in locating faults. Recent studies also showed that developers from industry value automated SBFL techniques. However, their effectiveness is still limited by two main reasons. First, the test coverage information leveraged to construct the spectrum does not reflect the root cause directly. Second, SBFL suffers from the tie issue so that the buggy code entities can not be well differentiated from non-buggy ones. To address these challenges, we propose to leverage the information of version histories in fault localization based on the following two intuitions. First, version histories record how bugs are introduced to software projects and this information reflects the root cause of bugs directly. Second, the evolution histories of code can help differentiate those suspicious code entities ranked in tie by SBFL. Our intuitions are also inspired by the observations on debugging practices from large open source projects and industry.\n\t\t\t\tBased on the intuitions, we propose a novel technique HSFL (historical spectrum based fault localization). Specifically, HSFL identifies bug-inducing commits from the version history in the first step. It then constructs historical spectrum (denoted as Histrum) based on bug-inducing commits, which is another dimension of spectrum orthogonal to the coverage based spectrum used in SBFL. HSFL finally ranks the suspicious code elements based on our proposed Histrum and the conventional spectrum. HSFL outperforms the state-of-the-art SBFL techniques significantly on the Defects4J benchmark. Specifically, it locates and ranks the buggy statement at Top-1 for 77.8% more bugs as compared with SBFL, and 33.9% more bugs at Top-5. Besides, for the metrics MAP and MRR, HSFL achieves an average improvement of 28.3% and 40.8% over all bugs, respectively. Moreover, HSFL can also outperform other six families of fault localization techniques, and our proposed Histrum model can be integrated with different families of techniques and boost their performance.\n    ","paperUrl":"materials/TSE20-ming.pdf","projectUrl":"https://github.com/justinwm/HSFL/","bibtex":"@article{WEN_TSE21,\n author    = {Ming, Wen and Junjie, Chen and Yongqiang, Tian and Rongxin, Wu and Dan, Hao and Shi, Han and Shing-Chi, Cheung},\n title     = {Historical Spectrum based Fault Localization},\n  journal   = {{IEEE} Trans. Software Eng.},\n  volume    = {47},\n  number    = {11},\n  pages     = {2348--2368},\n  year      = {2021},\n  url       = {https://doi.org/10.1109/TSE.2019.2948158},\n  doi       = {10.1109/TSE.2019.2948158}\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"CrashLocator: Locating Crashing Faults based on Crash Stacks","date":"2014","authors":["Rongxin Wu","Hongyu Zhang","Shing-Chi Cheung","Sunghun Kim"],"venue":"International Symposium on Software Testing and Analysis (ISSTA 2014), San Jose, California, USA, July 2014","venueShort":"ISSTA","tags":["Fault Localization"],"awards":["Distinguished Paper"],"abstract":"\n    Software crash is common. When a crash occurs, software developers can receive a report upon user permission. A crash report typically includes a call stack at the time of crash. An important step of debugging a crash is to identify faulty functions, which is often a tedious and labor-intensive task. In this paper, we propose CrashLocator, a method to locate faulty functions using the crash stack information in crash reports. It deduces possible crash traces (the failing execution traces that lead to crash) by expanding the crash stack with functions in static call graph. It then calculates the suspiciousness of each function in the approximate crash traces. The functions are then ranked by their suspiciousness scores and are recommended to developers for further investigation. We evaluate our approach using real-world Mozilla crash data. The results show that our approach is effective: we can locate 50.6%, 63.7% and 67.5% of crashing faults by examining top 1, 5 and 10 functions recommended by CrashLocator, respectively. Our approach outperforms the conventional stack-only methods significantly.\n    ","paperUrl":"http://dl.acm.org/citation.cfm?doid=2610384.2610386","bibtex":"@inproceedings{DBLP:conf/issta/WuZCK14,\n  author    = {Rongxin Wu and\n               Hongyu Zhang and\n               Shing{-}Chi Cheung and\n               Sunghun Kim},\n  title     = {CrashLocator: locating crashing faults based on crash stacks},\n  booktitle = {International Symposium on Software Testing and Analysis, {ISSTA}\n               '14, San Jose, CA, {USA} - July 21 - 26, 2014},\n  pages     = {204--214},\n  year      = {2014},\n  crossref  = {DBLP:conf/issta/2014},\n  url       = {http://doi.acm.org/10.1145/2610384.2610386},\n  doi       = {10.1145/2610384.2610386},\n  timestamp = {Sun, 13 Jul 2014 13:49:26 +0200},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/issta/WuZCK14},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null},{"title":"Casper: An Efficient Approach to Call Trace Collection","date":"2016","authors":["Rongxin Wu","Xiao Xiao","Shing-Chi Cheung","Hongyu Zhang","Charles Zhang"],"venue":"43rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL 2016)","venueShort":"POPL","tags":[],"abstract":"\n    Call traces, i.e., sequences of function calls and returns, are fundamental to a wide range of program analyses such as bug reproduction, fault diagnosis, performance analysis, and many others. The conventional approach to collect call traces that instruments each function call and return site incurs large space and time overhead. Our approach aims at reducing the recording overheads by instrumenting only a small amount of call sites while keeping the capability of recovering the full trace. We propose a call trace model and a logged call trace model based on an LL(1) grammar, which enables us to define the criteria of a feasible solution to call trace collection. Based on the two models, we prove that to collect call traces with minimal instrumentation is an NP-hard problem. We then propose an efficient approach to obtaining a suboptimal solution. We implemented our approach as a tool Casper and evaluated it using the DaCapo benchmark suite. The experiment results show that our approach causes significantly lower runtime (and space) overhead than two state-of-the-arts approaches.\n    ","paperUrl":"http://home.cse.ust.hk/~wurongxin/files/wurongxin_popl2016.pdf","bibtex":"@inproceedings{Wu_POPL2016,\n  author    = {Rongxin Wu and\n               Xiao Xiao and\n               Shing{-}Chi Cheung and\n               Hongyu Zhang and\n               Charles Zhang},\n  title     = {Casper: an efficient approach to call trace collection},\n  booktitle = {Proceedings of the 43rd Annual {ACM} {SIGPLAN-SIGACT} Symposium on\n               Principles of Programming Languages, {POPL} 2016, St. Petersburg,\n               FL, USA, January 20 - 22, 2016},\n  pages     = {678--690},\n  year      = {2016},\n  crossref  = {DBLP:conf/popl/2016},\n  url       = {http://doi.acm.org/10.1145/2837614.2837619},\n  doi       = {10.1145/2837614.2837619},\n  timestamp = {Wed, 09 Mar 2016 08:11:59 +0100},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/popl/WuXCZZ16},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"ChangeLocator: Locate Crash-Inducing Changes Based on Crash Reports","date":"2018","authors":["Rongxin Wu","Ming Wen","Shing-Chi Cheung","Hongyu Zhang"],"venue":"Journal of Empirical Software Engineering (EmSE 2018)","venueShort":"EmSE","tags":[],"abstract":"\n    Software crashes are severe manifestations of software bugs. Debugging crashing bugs is tedious and time-consuming. Understanding software changes that induce a crashing bug can provide useful contextual information for bug fixing and is highly demanded by developers. Locating the bug inducing changes is also useful for automatic program repair, since it narrows down the root causes and reduces the search space of bug fix location. However, currently there are no systematic studies on locating the software changes to a source code repository that induce a crashing bug reflected by a bucket of crash reports. To tackle this problem, we first conducted an empirical study on characterizing the bug inducing changes for crashing bugs (denoted as crash-inducing changes). We also propose ChangeLocator, a method to automatically locate crash-inducing changes for a given bucket of crash reports. We base our approach on a learning model that uses features originated from our empirical study and train the model using the data from the historical fixed crashes. We evaluated ChangeLocator with six release versions of Netbeans project. The results show that it can locate the crash-inducing changes for 44.7%, 68.5%, and 74.5% of the bugs by examining only top 1, 5 and 10 changes in the recommended list, respectively. It significantly outperforms the existing state-of-the-art approach.\n    ","paperUrl":"materials/ChangeLocator.pdf","bibtex":"@article{wu2018changelocator,\n  title={ChangeLocator: locate crash-inducing changes based on crash reports},\n  author={Wu, Rongxin and Wen, Ming and Cheung, Shing-Chi and Zhang, Hongyu},\n  journal={Empirical Software Engineering},\n  volume={23},\n  number={5},\n  pages={2866--2900},\n  year={2018},\n  publisher={Springer}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"How Effectively can Spreadsheet Anomalies be Detected: An Empirical Study","date":"2017","authors":["Ruiqing Zhang","Chang Xu","Shing-Chi Cheung","Ping Yu","Xiaoxing Ma","Jian Lu"],"venue":"The Journal of Systems and Software (JSS)","venueShort":"JSS ","tags":[],"abstract":"\n    While spreadsheets are widely used, they have been found to be error-prone. Various techniques have been proposed to detect anomalies in spreadsheets, with varying scopes and effectiveness. Nevertheless, there is no empirical study comparing these techniques' practical usefulness and effectiveness. In this work, we conducted a large-scale empirical study of three state-of-the-art techniques on their effectiveness in detecting spreadsheet anomalies. Our study focused on the precision, recall rate, efficiency and scope. We found that one technique outperforms the other two in precision and recall rate of spreadsheet anomaly detection. Efficiency of the three techniques is acceptable for most spreadsheets, but they may not be scalable to large spreadsheets with complex formulas. Besides, they have different scopes for detecting different spreadsheet anomalies, thus complementing to each other. We also discussed limitations of these three techniques. Based on our findings, we give suggestions for future spreadsheet research.\n    ","paperUrl":"http://cs.nju.edu.cn/_upload/tpl/01/55/341/template341/1_publications/JSS16.pdf","bibtex":"@article{Zhang_JSS17,\n\tauthor    = {Ruiqing Zhang, Chang Xu, Shing-Chi Cheung, Ping Yu, Xiaoxing Ma and Jian Lu},\n\ttitle     = {How Effective can Spreadsheet Anomalies be Detected: An Empirical Study},\n\tjournal = {The Journal of Systems and Software (JSS)},\n\tyear      = {2017}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Automatic Detection and Update Suggestion for Outdated API Names in Documentation","date":"2021","authors":["Seonah Lee","Rongxin Wu","Shing-Chi Cheung","Sungwon Kang"],"venue":"IEEE Transactions on Software Engineering 2021","venueShort":"TSE","tags":["Software Analytics","API Misuse"],"abstract":"\n    Application programming interfaces (APIs) continually evolve to meet ever-changing user needs, and documentation provides an authoritative reference for their usage. However, API documentation is commonly outdated because nearly all of the associated updates are performed manually. Such outdated documentation, especially with regard to API names, causes major software development issues. In this paper, we propose a method for automatically updating outdated API names in API documentation. Our insight is that API updates in documentation can be derived from API implementation changes between code revisions. To evaluate the proposed method, we applied it to four open source projects. Our evaluation results show that our method, FreshDoc, detects outdated API names in API documentation with 48% higher accuracy than the existing state-of-the-art methods do. Moreover, when we checked the updates suggested by FreshDoc against the developers? manual updates in the revised documentation, FreshDoc addressed 82% of the outdated names. When we reported 40 outdated API names found by FreshDoc via issue tracking systems, developers accepted 75% of the suggestions. These evaluation results indicate that FreshDoc can be used as a practical method for the detection and updating of API names in the associated documentation.\n    ","paperUrl":"materials/TSE19-lee.pdf","bibtex":"@article{DBLP:journals/tse/LeeWCK21,\n  author    = {Seonah Lee and\n               Rongxin Wu and\n               Shing{-}Chi Cheung and\n               Sungwon Kang},\n  title     = {Automatic Detection and Update Suggestion for Outdated {API} Names\n               in Documentation},\n  journal   = {{IEEE} Trans. Software Eng.},\n  volume    = {47},\n  number    = {4},\n  pages     = {653--675},\n  year      = {2021},\n  url       = {https://doi.org/10.1109/TSE.2019.2901459},\n  doi       = {10.1109/TSE.2019.2901459},\n  timestamp = {Thu, 29 Apr 2021 15:14:58 +0200},\n  biburl    = {https://dblp.org/rec/journals/tse/LeeWCK21.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Automatic Spreadsheet Cell Clustering and Smell Detection Using Strong and Weak Features","date":"2016","authors":["Shing-Chi Cheung","Wanjun Chen","Yepang Liu","Chang Xu"],"venue":"38th International Conference on Software Engineering (ICSE 2016), Austin, TX, USA, May 2016","venueShort":"ICSE","tags":[],"abstract":"\n    Various techniques have been proposed to detect smells in spreadsheets, which are susceptible to errors. These techniques typically detect spreadsheet smells through a mechanism based on a fixed set of patterns or metric thresholds. Unlike conventional programs, tabulation styles vary greatly across spreadsheets. Smell detection based on fixed patterns or metric thresholds, which are insensitive to the varying tabulation styles, can miss many smells in one spreadsheet while reporting many spurious smells in another. In this paper, we propose CUSTODES to effectively cluster spreadsheet cells and detect smells in these clusters. The clustering mechanism can automatically adapt to the tabulation styles of each spreadsheet using strong and weak features. These strong and weak features capture the invariant and variant parts of tabulation styles, respectively. As smelly cells in a spreadsheet normally occur in minority, they can be mechanically detected as clusters' outliers in feature spaces. We implemented and applied CUSTODES to 70 spreadsheets files randomly sampled from the EUSES corpus. These spreadsheets contain 1,610 formula cell clusters. Experimental results confirmed that CUSTODES is effective. It successfully detected harmful smells that can induce computation anomalies in spreadsheets with an F-measure of 0.72, outperforming state-of-the-art techniques.\n    ","paperUrl":"http://doi.acm.org/10.1145/2884781.2884796","projectUrl":"http://sccpu2.cse.ust.hk/custodes/","slidesUrl":"http://sccpu2.cse.ust.hk/castle/materials/Custodes.4.pdf","bibtex":"@inproceedings{Cheung_ICSE2016,\n  author    = {Shing{-}Chi Cheung and\n               Wanjun Chen and\n               Yepang Liu and\n               Chang Xu},\n  title     = {{CUSTODES:} automatic spreadsheet cell clustering and smell detection\n               using strong and weak features},\n  booktitle = {Proceedings of the 38th International Conference on Software Engineering,\n               {ICSE} 2016, Austin, TX, USA, May 14-22, 2016},\n  pages     = {464--475},\n  year      = {2016},\n  crossref  = {DBLP:conf/icse/2016},\n  url       = {http://doi.acm.org/10.1145/2884781.2884796},\n  doi       = {10.1145/2884781.2884796},\n  timestamp = {Sun, 15 May 2016 11:55:22 +0200},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icse/CheungCLX16},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"awards":[]},{"title":"Automating Object Transformations for Dynamic Software Updating via Online Execution Synthesis","date":"2018","authors":["Tianxiao Gu","Xiaoxing Ma","Chang Xu","Yanyan Jiang","Chun Cao","Jian Lu"],"venue":"32nd European Conference on Object-Oriented Programming (ECOOP 2018), Article 19","venueShort":"ECOOP","tags":[],"abstract":"\n    Dynamic software updating (DSU) is a technique to upgrade a running software system on the fly without stopping the system. During updating, the runtime state of the modified components of the system needs to be properly transformed into a new state, so that the modified components can still correctly interact with the rest of the system. However, the transformation is non-trivial to realize due to the gap between the low-level implementations of two versions of a program. This paper presents AOTES, a novel approach to automating object transformations for dynamic updating of Java programs. AOTES bridges the gap by abstracting the old state of an object to a history of method invocations, and re-invoking the new version of all methods in the history to get the desired new state. AOTES requires no instrumentation to record any data and thus has no overhead during normal execution. We propose and implement a novel technique that can synthesize an equivalent history of method invocations based on the current object state only. We evaluated AOTES on software updates taken from Apache Commons Collections, Tomcat, FTP Server and SSHD Server. Experimental results show that AOTES successfully handled 51 of 61 object transformations of 21 updated classes, while two state-of-the-art approaches only handled 11 and 6 of 61, respectively.\n    ","paperUrl":"https://cs.nju.edu.cn/changxu/1_publications/ECOOP18.pdf","bibtex":"@inproceedings{gu_automating_2018,\n  author    = {Tianxiao Gu and Xiaoxing Ma and Chang Xu and Yanyan Jiang and Chun Cao and Jian Lu},\n  title     = {Automating object transformations for dynamic software updating via online execution synthesis},\n  pages     = {to appear},\n  year      = {2018},\n  booktitle = {Proceedings of the 32nd European Conference on Object-Oriented Programming (ECOOP)},\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"RECONTEST: Effective Regression Testing of Concurrent Programs","date":"2015","authors":["Valerio Terragni","Shing-Chi Cheung","Charles Zhang"],"venue":"37th International Conference on Software Engineering (ICSE 2015), Florence, Italy, May 16-24, 2015","venueShort":"ICSE","tags":[],"abstract":"\n    Concurrent programs proliferate as multi-core technologies advance. As a result, the conventional approach that selects a sub-set of test cases for regression testing without considering interleavings is insufficient. In this paper we present RECONTEST to address the problem by selecting the new interleavings that arise due to code changes. These interleavings must be explored in order to uncover regression bugs. RECONTEST efficiently selects new interleavings by first identifying shared memory accesses that are affected by the changes, and then exploring only those problematic interleavings that contain at least one of these accesses. We have implemented RECONTEST as an automated tool and evaluated it using 13 real-world concurrent program subjects. Our results show that RECONTEST can significantly reduce the regression testing cost without missing any faulty interleavings induced by code changes.\n    ","paperUrl":"http://home.cse.ust.hk/~vterragni/files/Terragni_ICSE2015.pdf","bibtex":"@inproceedings{TERRAGNI_ICSE15,\n  author    = {Valerio Terragni and\n               Shing{-}Chi Cheung and\n               Charles Zhang},\n  title     = {{RECONTEST:} Effective Regression Testing of Concurrent Programs},\n  booktitle = {37th {IEEE/ACM} International Conference on Software Engineering,\n               {ICSE} 2015, Florence, Italy, May 16-24, 2015, Volume 1},\n  pages     = {246--256},\n  year      = {2015},\n  url       = {http://dx.doi.org/10.1109/ICSE.2015.45},\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"CSNIPPEX: Automated Synthesis of Compilable Code Snippets from Q&A Sites","date":"2016","authors":["Valerio Terragni","Yepang Liu","Shing-Chi Cheung"],"venue":"Proceedings of the 25th International Symposium on Software Testing and Analysis (ISSTA 2016), Saarbrücken, Germany, July 2016","venueShort":"ISSTA","tags":[],"abstract":"\n    Popular Q&A sites like StackOverflow have collected numerous code snippets. However, many of them do not have complete type information, making them uncompilable and inapplicable to various software engineering tasks. This paper analyzes this problem, and proposes a technique CSNIPPEX to automatically convert code snippets into compilable Java source code files by resolving external dependencies, generating import declarations, and fixing syntactic errors. We implemented CSNIPPEX as a plug-in for Eclipse and evaluated it with 242,175 StackOverflow posts that contain code snippets. CSNIPPEX successfully synthesized compilable Java files for 40,410 of them. It was also able to effectively recover import declarations for each post with a precision of 91.04% in a couple of seconds.\n    ","paperUrl":"http://www.cse.ust.hk/~vterragni/files/Terragni_ISSTA2016.pdf","bibtex":"@inproceedings{Terragni_ISSTA16,\n  author    = {Valerio Terragni and Yepang Liu and\n               Shing{-}Chi Cheung},\n  title     = {CSNIPPEX: Automated Synthesis of Compilable Code Snippets from Q&A Sites},\n  booktitle = {Proceedings of the 2016 International Symposium on Software Testing\n               and Analysis, {ISSTA} 2016},\n  pages     = {118--129},\n  year      = {2016},\n  url       = {http://dx.doi.org/10.1145/2931037.2931058}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Coverage-Driven Test Code Generation for Concurrent Classes","date":"2016","authors":["Valerio Terragni","Shing-Chi Cheung"],"venue":"38th International Conference on Software Engineering (ICSE 2016), Austin, TX, USA, May 2016","venueShort":"ICSE","tags":[],"abstract":"\n    Previous techniques on concurrency testing have mainly focused on exploring the interleaving space of manually written test code to expose faulty interleavings of shared memory accesses. These techniques assume the availability of failure-inducing tests. In this paper, we present AutoConTest, a coverage-driven approach to generate effective concurrent test code that achieve high interleaving coverage. AutoConTest consists of three components. First, it computes the coverage requirements dynamically and iteratively during sequential test code generation, using a coverage metric that captures the execution context of shared memory accesses. Second, it smartly selects these sequential codes based on the computed result and assembles them for concurrent tests, achieving increased context-sensitive interleaving coverage. Third, it explores the newly covered interleavings. We have implemented AutoConTest as an automated tool and evaluated it using 6 real-world concurrent Java subjects. The results show that AutoConTest is able to generate effective concurrent tests that achieve high interleaving coverage and expose concurrency faults quickly. AutoConTest took less than 65 seconds (including program analysis, test generation and execution) to expose the faults in the program subjects.\n    ","paperUrl":"http://www.cse.ust.hk/~vterragni/files/Terragni_ICSE2016.pdf","bibtex":"@inproceedings{Terragni_ICSE16,\n  author    = {Valerio Terragni and\n               Shing{-}Chi Cheung},\n  title     = {Coverage-driven test code generation for concurrent classes},\n  booktitle = {Proceedings of the 38th International Conference on Software Engineering,\n               {ICSE} 2016, Austin, TX, USA, May 14-22, 2016},\n  pages     = {1121--1132},\n  year      = {2016},\n  url       = {http://doi.acm.org/10.1145/2884781.2884876}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"File-level socio-technical congruence and its relationship with bug proneness in OSS projects","date":"2019","authors":["Weiqiang Zhang","Shing-Chi Cheung","Zhenyu Chen","Yuming Zhou","Bin Luo"],"venue":"Journal of Systems and Software 156: 21-40 (2019)","venueShort":"JSS","tags":[],"abstract":"\n    Coordination is important in software development. Socio-Technical Congruence (STC) is proposed to measure the match between coordination requirements and actual coordination activities. The previous work of Cataldo et al. computes STC in commercial projects and finds it related to software failures. In this paper, we study the relationship between file-level STC and bug proneness in Open Source Software (OSS) projects. We apply the fundamental STC framework to the OSS data setting and present a method of computing file-level STC based on our available data. We also propose a derivative STC metric called Missing Developer Links (MDL), which is to measure the amount of coordination breakdowns. In our empirical analysis on five OSS projects, we find that MDL is more related to bug proneness than STC. Furthermore, STC or MDL can be computed based on different types of file networks and developer networks, and we find out the best file network and the best developer network via an empirical study. We also evaluate the usefulness of STC or MDL metrics in bug prediction. This work is promising to help detect coordination issues in OSS projects.\n    ","paperUrl":"https://www.sciencedirect.com/science/article/pii/S0164121219301177","bibtex":"@article{DBLP:journals/jss/ZhangCCZL19,\n  author    = {Weiqiang Zhang and\n               Shing{-}Chi Cheung and\n               Zhenyu Chen and\n               Yuming Zhou and\n               Bin Luo},\n  title     = {File-level socio-technical congruence and its relationship with bug\n               proneness in {OSS} projects},\n  journal   = {Journal of Systems and Software},\n  volume    = {156},\n  pages     = {21--40},\n  year      = {2019},\n  url       = {https://doi.org/10.1016/j.jss.2019.05.030},\n  doi       = {10.1016/j.jss.2019.05.030},\n  timestamp = {Thu, 05 Sep 2019 19:41:26 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/jss/ZhangCCZL19},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"A Survey on Dependability Improvement Techniques for Pervasive Computing Systems","date":"2015","authors":["Wenhua Yang","Yepang Liu","Chang Xu","Shing-Chi Cheung"],"venue":"SCIENCE CHINA Information Sciences (SCIS) 58(5), May 2015","venueShort":"SCIS","tags":[],"abstract":"\n    The goal of this survey is to summarize the state-of-the-art research results and identify research challenges of developing and deploying dependable pervasive computing systems. We discuss the factors that affect the system dependability and the studies conducted to improve it with respect to these factors. These studies were categorized according to their similarities and differences in hope of shedding some insight into future research. There are three categories: context management, fault detection, and uncertainty handling. These three categories of work address the three most difficult problems of pervasive computing systems. First, pervasive computing systems’ perceived environments, which are also called their contexts, can vary intensively, and thus have a great impact on the systems’ dependability. Second, it is challenging to guarantee the correctness of the systems’ internal computations integrated with interactions with external environments for developers. Fault detection is then an important issue for improving dependability for these systems. Last but not least importantly, pervasive computing systems interact with their environments frequently. These interactions can be affected by many uncertainties, which can jeopardize the systems’ dependability. After a discussion of these pieces of work, we present an outlook for its future research directions.\n    ","paperUrl":"http://link.springer.com/article/10.1007%2Fs11432-015-5300-3","bibtex":"@article{DBLP:journals/chinaf/YangLXC15,\n  author    = {Wenhua Yang and\n               Yepang Liu and\n               Chang Xu and\n               Shing{-}Chi Cheung},\n  title     = {A survey on dependability improvement techniques for pervasive computing\n               systems},\n  journal   = {{SCIENCE} {CHINA} Information Sciences},\n  volume    = {58},\n  number    = {5},\n  pages     = {1--14},\n  year      = {2015},\n  url       = {http://dx.doi.org/10.1007/s11432-015-5300-3},\n  doi       = {10.1007/s11432-015-5300-3},\n  timestamp = {Wed, 29 Apr 2015 12:35:39 +0200},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/chinaf/YangLXC15},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Efficient Validation of Self-adaptive Applications by Counterexample Probability Maximization","date":"2018","authors":["Wenhua Yang","Chang Xu","Minxue Pan","Chun Cao","Xiaoxing Ma","Jian Lu"],"venue":"The Journal of Systems and Software (JSS)","venueShort":"JSS","tags":[],"abstract":"\n    Self-adaptive applications’ executions can be affected by uncertainty factors like unreliable sensing and flawed adaptation and therefore often error-prone. Existing methods can verify the applications suffering uncertainty and report counterexamples. However, such verification results can deviate from reality when the uncertainty specification used in verification is itself imprecise. This thus calls for further validation of reported counterexamples. One outstanding challenge in counterexample validation is that the probabilities of counterex- amples occurring in real environment are usually very low, which makes the validation extremely inefficient. In this paper, we propose a novel approach to systematically deriving path-equivalent counterexamples with respect to origi- nal ones. The derived counterexamples guarantee to have higher probabilities, making them capable of being validated efficiently in field test. We evaluated our approach with real-world self-adaptive applications. The results reported that our approach significantly increased counterexample probabilities, and the derived counterexamples were also consistently and efficiently validated in both real environment and simulation.\n    ","paperUrl":"https://cs.nju.edu.cn/changxu/1_publications/JSS18.pdf","bibtex":"@inproceedings{yang2018jss,\n\tauthor    = {Wenhua Yang, Chang Xu, Minxue Pan, Chun Cao, Xiaoxing Ma, and Jian Lu},\n\ttitle     = {The Journal of Systems and Software (JSS)},\n\tyear      = {2018},\n\tpages     = {82-99}\n\t}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Improving Verification Accuracy of CPS by Modeling and Calibrating Interaction Uncertainty","date":"2018","authors":["Wenhua Yang","Chang Xu","Minxue Pan","Xiaoxing Ma","Jian Lu"],"venue":"ACM Transactions on Internet Technology (TOIT)","venueShort":"TOIT","tags":[],"abstract":"\n    Cyber-Physical Systems (CPS) intrinsically combine hardware and physical systems with software and network, which are together creating complex and correlated interactions. CPS applications often experience uncertainty in interacting with environment through unreliable sensor. They can be faulty and exhibit runtime errors if developers have not considered environmental interaction uncertainty adequately. Existing work in verifying CPS applications ignores interaction uncertainty and thus may overlook uncertainty-related faults. To improve verification accuracy, in this article we propose a novel approach to verifying CPS applications with explicit modeling of uncertainty arisen in the interaction between them and the environment. Our approach builds an Interactive State Machine (ISM) network for a CPS application and models interaction uncertainty by error ranges and distributions. Then it encodes both the application and uncertainty models to SMT formula to leverage SMT solvers searching for counterexamples that represent application failures. The precision of uncertainty model can affect the verification results. However, it may be difficult to model interaction uncertainty precisely enough at the beginning, because of the uncontrollable noise of sensors and insufficient data sample size. To further improve the accuracy of the verification results, we propose an approach to identifying and calibrating imprecise uncertainty models. We exploit the inconsistency between the counterexamples’ estimate and actual occurrence probabilities to identify possible imprecision in uncertainty models, and the calibration of imprecise models is to minimize the inconsistency, which is reduced to a Search- Based Software Engineering (SBSE) problem. We experimentally evaluated our verification and calibration approaches with real-world CPS applications, and the experimental results confirmed their effectiveness and efficiency.\n    ","paperUrl":"https://cs.nju.edu.cn/changxu/1_publications/TOIT18.pdf","bibtex":"@inproceedings{yang2018toit,\n\tauthor    = {Wenhua Yang, Chang Xu, Minxue Pan, Xiaoxing Ma, and Jian Lu},\n\ttitle     = {Improving Verification Accuracy of CPS by Modeling and Calibrating Interaction Uncertainty},\n\tjournal = {ACM Transactions on Internet Technology (TOIT)},\n\tyear      = {2018},\n\tpages     = {1-37}\n\t}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Is Spreadsheet Ambiguity Harmful? Detecting and Repairing Spreadsheet Smells due to Ambiguous Computation","date":"2014","authors":["Wensheng Dou","Shing-Chi Cheung","Jun Wei"],"venue":"36th International Conference on Software Engineering (ICSE 2014), Hyderabad, India, May-Jun 2014","venueShort":"ICSE","tags":[],"abstract":"\n    Spreadsheets are widely used by end users for numerical computation in their business. Spreadsheet cells whose computation is subject to the same semantics are often clustered in a row or column. When a spreadsheet evolves, these cell clusters can degenerate due to ad hoc modifications or undisciplined copy-and-pastes. Such degenerated clusters no longer keep cells prescribing the same computational semantics, and are said to exhibit ambiguous computation smells. Our empirical study finds that such smells are common and likely harmful. We propose AmCheck, a novel technique that automatically detects and repairs ambiguous computation smells by recovering their intended computational semantics. A case study using AmCheck suggests that it is useful for discovering and repairing real spreadsheet problems.\n    ","paperUrl":"http://dl.acm.org/citation.cfm?doid=2568225.2568316","bibtex":"@inproceedings{DBLP:conf/icse/DouCW14,\n  author    = {Wensheng Dou and\n               Shing{-}Chi Cheung and\n               Jun Wei},\n  title     = {Is spreadsheet ambiguity harmful? detecting and repairing spreadsheet\n               smells due to ambiguous computation},\n  booktitle = {36th International Conference on Software Engineering, {ICSE} '14,\n               Hyderabad, India - May 31 - June 07, 2014},\n  pages     = {848--858},\n  year      = {2014},\n  crossref  = {DBLP:conf/icse/2014},\n  url       = {http://doi.acm.org/10.1145/2568225.2568316},\n  doi       = {10.1145/2568225.2568316},\n  timestamp = {Mon, 14 Sep 2015 15:13:50 +0200},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icse/DouCW14},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Detecting Table Clones and Smells in                  Spreadsheets","date":"2016","authors":["Wensheng Dou","Shing-Chi Cheung","Chushu Gao","Chang Xu","Liang Xu","Jun Wei"],"venue":"24th ACM SIGSOFT International Symposium on the Foundations of Software Engineering (FSE 2016), Seattle, WA, USA, Nov 2016","venueShort":"FSE ","tags":[],"abstract":"\n    Spreadsheets  are  widely  used  by  end  users  for  various  business tasks, such as data analysis and financial reporting. End users may perform similar tasks by cloning a block of cells (table) in their spreadsheets.  The  corresponding  cells  in  these  cloned  tables  are supposed  to  keep  the  same  or  similar  computational  semantics. However,  when  spreadsheets  evolve,  thus  cloned  tables  can  become  inconsistent  due  to  ad-hoc  modifications,  and  as  a  result suffer from smells. In this paper, we propose TableCheck to detect table clones and related smells due to inconsistency among them. We observe that two tables with the same header information at their corresponding cells are likely to be table clones. Inspired by existing finger-print-based code clone detection techniques, we developed a detection  algorithm  to  detect  this kind  of  table  clones.  We further detected outliers among corresponding cells as smells in the detected  table  clones.  We  implemented  our  idea  into  TableCheck, and applied it to real-world spreadsheets from the EUSES corpus. Experimental  results  show  that  table  clones  commonly  exist (21.8%), and 25.6% of the spreadsheets with table clones suffer from smells due to inconsistency among these clones. TableCheck detected table clones and their smells with a precision of 92.2% and  85.5%,  respectively,  while  existing  techniques  detected  no more than 35.6% true smells that TableCheck could detect.\n    ","paperUrl":"http://sccpu2.cse.ust.hk/castle/materials/fse16main-mainid258-p-e95dd6b-29549-preprint.pdf","slidesUrl":"http://sccpu2.cse.ust.hk/castle/materials/TableCheck_2016_11-17-1.pdf","bibtex":"@inproceedings{Dou_FSE16,\n\tauthor    = {Wensheng Dou and Shing{-}Chi Cheung and Chushu Gao and Chang Xu and Liang Xu and Jun Wei},\n\ttitle     = {Detecting Table Clones and Smells in Spreadsheets},\n\tbooktitle = {Proceedings of the 2016 International Symposium on the Foundations of Software Engineering, {FSE} 2016},\n\tyear      = {2016}\n}","arxivUrl":null,"projectUrl":null,"awards":[]},{"title":"VEnron: A Versioned Spreadsheet Corpus and Related Evolution Analysis","date":"2016","authors":["Wensheng Dou","Liang Xu","Shing-Chi Cheung","Chushu Gao","Jun Wei","Tao Huang"],"venue":"38th International Conference on Software Engineering (ICSE 2016 - SEIP), Companion Volume, Austin, TX, USA, May 2016","venueShort":"ICSE SEIP","tags":[],"abstract":"\n    In this paper, we propose a semi-automated approach that leverages spreadsheets’ contexts (e.g., attached emails) and contents to identify evolved spreadsheets and recover the embedded version information. We apply it to the released email archive of the Enron Corporation and build an industrial-scale, versioned spreadsheet corpus VEnron. Our approach first clusters spreadsheets that likely evolved from one to another into evolution groups based on various fragmented information, such as spreadsheet filenames, spreadsheet contents, and spreadsheet-attached emails. Then, it recovers the version information of the spreadsheets in each evolution group. VEnron enables us to identify interesting issues that can arise from spreadsheet evolution. For example, the versioned spreadsheets popularly exist in the Enron email archive; changes in formulas are common; and some groups (16.9%) can introduce new errors during evolution.\nAccording to our knowledge, VEnron is the first spreadsheet corpus with version information. It provides a valuable resource to understand issues arising from spreadsheet evolution.\n    ","paperUrl":"http://delivery.acm.org/10.1145/2890000/2889238/p162-dou.pdf?ip=175.159.126.8&id=2889238&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=836117825&CFTOKEN=34377724&__acm__=1473671848_9a79ceac0a81a74ac3ee0d6561cb8330","projectUrl":"http://sccpu2.cse.ust.hk/venron/","bibtex":"@inproceedings{Dou_ICSE2016,\n  author    = {Wensheng Dou and\n               Liang Xu and\n               Shing{-}Chi Cheung and\n               Chushu Gao and\n               Jun Wei and\n               Tao Huang},\n  title     = {VEnron: a versioned spreadsheet corpus and related evolution analysis},\n  booktitle = {Proceedings of the 38th International Conference on Software Engineering,\n               {ICSE} 2016, Austin, TX, USA, May 14-22, 2016 - Companion Volume},\n  pages     = {162--171},\n  year      = {2016},\n  crossref  = {DBLP:conf/icse/2016c},\n  url       = {http://doi.acm.org/10.1145/2889160.2889238},\n  doi       = {10.1145/2889160.2889238},\n  timestamp = {Sun, 15 May 2016 12:23:10 +0200},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icse/DouXCGWH16},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"CACheck: Detecting and Repairing Cell Arrays in Spreadsheets","date":"2017","authors":["Wensheng Dou","Chang Xu","Shing-Chi Cheung","Jun Wei"],"venue":"IEEE Transactions on Software Engineering (TSE)","venueShort":"TSE","tags":[],"abstract":"\n    Spreadsheets are widely used by end users for numerical computation in their business. Spreadsheet cells whose computation is subject to the same semantics are often clustered in a row or column as a cell array. When a spreadsheet evolves, the cells in a cell array can degenerate due to ad hoc modifications. Such degenerated cell arrays no longer keep cells prescribing the same computational semantics, and are said to exhibit ambiguous computation smells. We propose CACheck, a novel technique that automatically detects and repairs smelly cell arrays by recovering their intended computational semantics. Our empirical study on the EUSES and Enron corpora finds that such smelly cell arrays are common. Our study also suggests that CACheck is useful for detecting and repairing real spreadsheet problems caused by smelly cell arrays. Compared with our previous work AmCheck, CACheck detects smelly cell arrays with higher precision and recall rate.\n    ","paperUrl":"https://doi.org/10.1109/TSE.2016.2584059","bibtex":"@article{Dou_TSE17,\n\tauthor    = {Wensheng Dou, Chang Xu, Shing-Chi Cheung and Jun Wei},\n\ttitle     = {CACheck: Detecting and Repairing Cell Arrays in Spreadsheets},\n\tjournal = {IEEE Transactions on Software Engineering (TSE)},\n\tyear      = {2017}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"GreenDroid: Automated Diagnosis of Energy Inefficiency for Smartphone Applications","date":"2014","authors":["Yepang Liu","Chang Xu","Shing-Chi Cheung","Jian Lv"],"venue":"IEEE Transactions on Software Engineering 40(9), September 2014","venueShort":"TSE","tags":[],"abstract":"\n    Smartphone applications’ energy efficiency is vital, but many Android applications suffer from serious energy inefficiency problems. Locating these problems is labor-intensive and automated diagnosis is highly desirable. However, a key challenge is the lack of a decidable criterion that facilitates automated judgment of such energy problems. Our work aims to address this challenge. We conducted an in-depth study of 173 open-source and 229 commercial Android applications, and observed two common causes of energy problems: missing deactivation of sensors or wake locks, and cost-ineffective use of sensory data. With these findings, we\npropose an automated approach to diagnosing energy problems in Android applications. Our approach explores an application’s state space by systematically executing the application using Java PathFinder (JPF). It monitors sensor and wake lock operations to detect missing deactivation of sensors and wake locks. It also tracks the transformation and usage of sensory data and judges whether they are effectively utilized by the application using our state-sensitive data utilization metric. In this way, our approach can generate detailed reports with actionable information to assist developers in validating detected energy problems. We built our approach as a tool, GreenDroid, on top of JPF. Technically, we addressed the challenges of generating user interaction events and scheduling event han- dlers in extending JPF for analyzing Android applications. We evaluated GreenDroid using 13 real-world popular Android applications. GreenDroid completed energy efficiency diagnosis for these applications in a few minutes. It successfully located real energy problems in these applications, and additionally found new unreported energy problems that were later confirmed by developers.\n    ","paperUrl":"http://sccpu2.cse.ust.hk/andrewust/files/TSE2014.pdf","projectUrl":"http://sccpu2.cse.ust.hk/greendroid/","bibtex":"@ARTICLE{Liu:TSE2014, \n  author = {Liu, Yepang and Xu, Chang and Cheung, Shing-Chi and Lu, Jian}, \n  journal = {IEEE Transactions on Software Engineering}, \n  title = {GreenDroid: Automated Diagnosis of Energy Inefficiency for Smartphone Applications}, \n  year = {2014}, \n  volume = {40}, \n  number = {9}, \n  pages = {911-940}, \n  doi = {10.1109/TSE.2014.2323982}, \n  month = {Sept},\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"CHECKERDROID: Automated Quality Assurance for Smartphone Applications","date":"2014","authors":["Yepang Liu","Chang Xu","Shing-Chi Cheung","Wenhua Yang"],"venue":"International Journal of Software and Informatics (IJSI)","venueShort":"IJSI","tags":[],"abstract":"\n    Smartphone applications’ quality is vital. However, many smartphone applications on market suffer from various bugs. One major reason is that developers lack viable techniques to help expose potential bugs in their applications. This paper presents a practical dynamic analysis tool, CheckerDroid, to help developers automatically detect both functional and non-functional bugs in their Android applications. CheckerDroid currently supports the detection of the following three types of bugs: null pointer exception, resource leak and sensor listener misusage. We built CheckerDroid by extending Java PathFinder (JPF), a widely-used model checker for general Java programs. Our extension addresses two technical challenges. First, Android applications are event-driven and lack explicit control flow information between event handlers. Second, Android applications closely hinge on native framework libraries, whose implementations are platform-dependent. To address these challenges, we derive event handler scheduling policies from Android documentations, and encode them to guide CheckerDroid to realistically execute Android applications. Besides, we modeled the side effects for a critical set of Android APIs such that CheckerDroid can conduct bug detection precisely. To evaluate CheckerDroid, we conducted experiments with seven popular real-world Android applications. CheckerDroid analyzed these applications in a few minutes, and successfully located real bugs in them.\n    ","paperUrl":"http://sccpu2.cse.ust.hk/andrewust/files/IJSI2014.pdf","bibtex":"@article{DBLP:journals/ijsi/LiuXCY14,\n  author    = {Yepang Liu and\n               Chang Xu and\n               S. C. Cheung and\n               Wenhua Yang},\n  title     = {{CHECKERDROID} : Automated Quality Assurance for Smartphone Applications},\n  journal   = {Int. J. Software and Informatics},\n  volume    = {8},\n  number    = {1},\n  pages     = {21--41},\n  year      = {2014},\n  url       = {http://www.ijsi.org/ch/reader/view_abstract.aspx?file_no=i181},\n  timestamp = {Sun, 14 Aug 2016 14:06:59 +0200},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/ijsi/LiuXCY14},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Characterizing and Detecting Performance Bugs for Smartphone Applications","date":"2014","authors":["Yepang Liu","Chang Xu","Shing-Chi Cheung"],"venue":"36th International Conference on Software Engineering (ICSE 2014), Hyderabad, India, May-Jun 2014","venueShort":"ICSE","tags":["Android","Empirical Study"],"awards":["Distinguished Paper"],"abstract":"\n    Smartphone applications’ performance has a vital impact on user experience. However, many smartphone applications suffer from bugs that cause significant performance degradation, thereby losing their competitive edge. Unfortunately, people have little understanding of these performance bugs. They also lack effective techniques to fight with such bugs. To bridge this gap, we conducted a study of 70 real-world performance bugs collected from eight large-scale and popular Android applications. We studied the characteristics (e.g., bug types and how they manifested) of these bugs and identified their common patterns. These findings can support follow-up research on performance bug avoidance, testing, debugging and analysis for smartphone applications. To demonstrate the usefulness of our findings, we implemented a static code analyzer, PerfChecker, to detect our identified performance bug patterns. We experimentally evaluated PerfChecker by applying it to 29 popular Android applications, which comprise 1.1 million lines of Java code. PerfChecker successfully detected 126 matching instances of our performance bug patterns. Among them, 68 were quickly confirmed by developers as previouslynunknown issues that affect application performance, and 20 were fixed soon afterwards by following our optimization suggestions.\n    ","paperUrl":"http://sccpu2.cse.ust.hk/andrewust/files/ICSE2014.pdf","projectUrl":"http://sccpu2.cse.ust.hk/perfchecker","bibtex":"@inproceedings{DBLP:conf/icse/LiuXC14,\n  author    = {Yepang Liu and\n               Chang Xu and\n               Shing{-}Chi Cheung},\n  title     = {Characterizing and detecting performance bugs for smartphone applications},\n  booktitle = {36th International Conference on Software Engineering, {ICSE} '14,\n               Hyderabad, India - May 31 - June 07, 2014},\n  pages     = {1013--1024},\n  year      = {2014},\n  crossref  = {DBLP:conf/icse/2014},\n  url       = {http://doi.acm.org/10.1145/2568225.2568229},\n  doi       = {10.1145/2568225.2568229},\n  timestamp = {Sun, 18 May 2014 16:12:57 +0200},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icse/LiuXC14},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"slidesUrl":null},{"title":"Diagnosing Energy Efficiency and Performance for Mobile Internetware Applications: Challenges and Opportunities","date":"2015","authors":["Yepang Liu","Chang Xu","Shing-Chi Cheung"],"venue":"IEEE Software 32(1), Jan/Feb 2015","venueShort":"IEEE SOFTWARE","tags":[],"abstract":"\n    Many smartphone applications' smart services are realized in a way that wastes energy or degrades performance, seriously affecting the user experience. What's worse, developers lack powerful tools to combat such problems, curbing the growth of Internet-based mobile computing. Research communities and industries have issued a strong call for effective techniques to diagnose energy and performance bugs in smartphone applications. This article describes bug characteristics, discusses diagnostic challenges, and reviews state-of-the-art diagnostic techniques. A case study shows how a representative tool analyzed commercial Android applications and the Samsung Mobile Software Developer's Kit, providing useful diagnostic information.\n    ","paperUrl":"http://sccpu2.cse.ust.hk/andrewust/files/ieeesoft15.pdf","bibtex":"@article{DBLP:journals/software/LiuXC15,\n  author    = {Yepang Liu and\n               Chang Xu and\n               Shing{-}Chi Cheung},\n  title     = {Diagnosing Energy Efficiency and Performance for Mobile Internetware\n               Applications},\n  journal   = {{IEEE} Software},\n  volume    = {32},\n  number    = {1},\n  pages     = {67--75},\n  year      = {2015},\n  url       = {http://dx.doi.org/10.1109/MS.2015.4},\n  doi       = {10.1109/MS.2015.4},\n  timestamp = {Tue, 12 Jan 2016 12:01:52 +0100},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/software/LiuXC15},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Understanding and Detecting Wake Lock Misuses for Android Applications","date":"2016","authors":["Yepang Liu","Chang Xu","Shing-Chi Cheung","Valerio Terrangi"],"venue":"24th ACM SIGSOFT International Symposium on the Foundations of Software Engineering (FSE 2016), Seattle, WA, USA, Nov 2016","venueShort":"FSE ","tags":[],"abstract":"\n    Wake locks are widely used in Android apps to protect critical computations from being disrupted by device sleeping. Inappropriate use of wake locks often seriously impacts user experience. However, little is known on how wake locks are used in real-world Android apps and the impact of their misuses. To bridge the gap, we conducted a large-scale empirical study on 44,736 commercial and 31 open-source Android apps. By automated program analysis and manual investigation, we observed (1) common program points where wake locks are acquired and released, (2) 13 types of critical computational tasks that are often protected by wake locks, and (3) eight patterns of wake lock misuses that commonly cause functional and non-functional issues, only three of which had been studied by existing work. Based on our findings, we designed a static analysis technique, Elite, to detect two most common patterns of wake lock misuses. Our experiments on real-world subjects showed that Elite is effective and can outperform two state-of-the-art techniques.\n    ","paperUrl":"http://sccpu2.cse.ust.hk/andrewust/files/FSE2016.pdf","slidesUrl":"http://sccpu2.cse.ust.hk/castle/materials/ELITE-FSE2016-V3.pdf","bibtex":"@inproceedings{Liu_FSE16,\n\tauthor    = {Yepang Liu and Chang Xu and\n\t\t    \t Shing{-}Chi Cheung and Valerio Terragni},\n\ttitle     = {Understanding and Detecting Wake Lock Misuses for Android Applications},\n\tbooktitle = {Proceedings of the 2016 International Symposium on the Foundations of Software Engineering, {FSE} 2016},\n\tyear      = {2016}\n}","arxivUrl":null,"projectUrl":null,"awards":[]},{"title":"DroidLeaks: a comprehensive database of resource leaks in Android apps","date":"2019","authors":["Yepang Liu","Jue Wang","Lili Wei","Chang Xu","Shing-Chi Cheung","Tianyong Wu","Jun Yan","Jian Zhang"],"venue":"Empirical Software Engineering 2019","venueShort":"EmSE","tags":[],"abstract":"\n    Resource leaks in Android apps are pervasive. They can cause serious performance degradation and system crashes. In recent years, many resource leak detection techniques have been proposed to help Android developers correctly manage system resources. Yet, there exist no common databases of real-world bugs for effectively comparing such techniques to understand their strengths and limitations. This paper describes our effort towards constructing such a bug database named DROIDLEAKS. To extract real resource leak bugs, we mined 124,215 code revisions of 34 popular open-source Android apps. After automated filtering and manual validation, we successfully found 292 fixed resource leak bugs, which cover a diverse set of resource classes, from 32 analyzed apps. To understand these bugs, we conducted an empirical study, which revealed the characteristics of resource leaks in Android apps and common patterns of resource management mistakes made by developers. To further demonstrate the usefulness of our work, we evaluated eight resource leak detectors from both academia and industry on DROIDLEAKS and performed a detailed analysis of their performance. We release DROIDLEAKS for public access to support future research.\n    ","paperUrl":"https://link.springer.com/article/10.1007/s10664-019-09715-8","projectUrl":"https://zenodo.org/record/2589909#.XfxlvZP7TOR","bibtex":"@article{DBLP:journals/ese/LiuWWXCWYZ19,\n  author    = {Yepang Liu and\n               Jue Wang and\n               Lili Wei and\n               Chang Xu and\n               Shing{-}Chi Cheung and\n               Tianyong Wu and\n               Jun Yan and\n               Jian Zhang},\n  title     = {DroidLeaks: a comprehensive database of resource leaks in Android\n               apps},\n  journal   = {Empirical Software Engineering},\n  volume    = {24},\n  number    = {6},\n  pages     = {3435--3483},\n  year      = {2019},\n  url       = {https://doi.org/10.1007/s10664-019-09715-8},\n  doi       = {10.1007/s10664-019-09715-8},\n  timestamp = {Thu, 19 Dec 2019 09:26:48 +0100},\n  biburl    = {https://dblp.org/rec/bib/journals/ese/LiuWWXCWYZ19},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Automatic Software Refactoring via Weighted Clustering in Method-level Networks","date":"2018","authors":["Ying Wang","Hai Yu","Zhiliang Zhu","Wei Zhang","Yuli Zhao"],"venue":"IEEE Transactions on Software Engineering (TSE)","venueShort":"TSE","tags":[],"abstract":"\n    In this study, we describe a system-level multiple refactoring algorithm, which can identify the move method, move field, and extract class refactoring opportunities automatically according to the principle of “high cohesion and low coupling.” The algorithm works by merging and splitting related classes to obtain the optimal functionality distribution from the system-level. Furthermore, we present a weighted clustering algorithm for regrouping the entities in a system based on merged method-level networks. Using a series of preprocessing steps and preconditions, the “bad smells” introduced by cohesion and coupling problems can be removed from both the non-inheritance and inheritance hierarchies without changing the code behaviors. We rank the refactoring suggestions based on the anticipated benefits that they bring to the system. Based on comparisons with related research and assessing the refactoring results using quality metrics and empirical evaluation, we show that the proposed approach performs well in different systems and is beneficial from the perspective of the original developers. Finally, an open source tool is implemented to support the proposed approach.\n    ","paperUrl":"materials/TSE18-ying.pdf","projectUrl":"https://github.com/wangying8052/REsolution_runnable-JAR-File","bibtex":"@article{wang2018automatic,\n  title={Automatic Software Refactoring via Weighted Clustering in Method-Level Networks},\n  author={Ying, Wang and Hai, Yu and Zhiliang, Zhu and Wei, Zhang and Yuli, Zhao},\n  journal={IEEE Transactions on Software Engineering},\n  volume={44},\n  number={3},\n  pages={202--236},\n  year={2018},\n  publisher={IEEE}\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Risk Analysis on Multi-granular Network for Software Integration Testing","date":"2018","authors":["Ying Wang","Zhiliang Zhu","Hai Yu"],"venue":"IEEE Transactions on Circuits and Systems II: Express Briefs (TCAS2)","venueShort":"TCAS2","tags":[],"abstract":"\n    This brief presents a model, a methodology, and an application scheme of risk assessment for information exchange system. The multi-granular flow network (MGFN) model serves as a basis for measuring the vulnerabilities and threats of components, and the failure consequences they bring to the system when a failure occurs. The risk factors of components are then quantified, assisted by a probabilistic risk analysis model. Furthermore, we apply the MGFN model and the risk assessment scheme in ordering class integration testing for object-oriented software system. By comparing our approach with the state-of-the-art integration test order algorithms from the perspectives of detection efficiency of severe faults and stubbing efforts, we show that classes with higher risk indexes can be tested in earlier integration steps, and that the total complexity of the established test stubs is minimized.\n    ","paperUrl":"materials/TCAS218-ying.pdf","bibtex":"@article{wang2018risk,\n  title={Risk Analysis on Multi-Granular Flow Network for Software Integration Testing},\n  author={Ying, Wang and Zhiliang, Zhu and Hai, Yu and Bo, Yang},\n  journal={IEEE Transactions on Circuits and Systems II: Express Briefs},\n  volume={65},\n  number={8},\n  pages={1059--1063},\n  year={2018},\n  publisher={IEEE}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Do the Dependency Conflicts in My Project Matter?","date":"2018","authors":["Ying Wang","Ming Wen","Zhenwei Liu","Rongxin Wu","Rui Wang","Bo Yang","Hai Yu","Zhiliang Zhu","Shing-Chi Cheung"],"venue":" The ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Technical Research Paper, Lake Buena Vista, Florida, 4 Nov - 9 Nov 2018","venueShort":"ESEC/FSE","tags":[],"abstract":"\n    Intensive dependencies of a Java project on third-party libraries can easily lead to the presence of multiple library or class versions on its classpath. When this happens, JVM will load one version and shadows the others. Dependency conflict (DC) issues occur when the loaded version fails to cover a required feature (e.g., method) referenced by the project, thus causing runtime exceptions. However, the warnings of duplicate classes or libraries detected by existing build tools such as Maven can be benign since not all instances of duplication will induce runtime exceptions, and hence are often ignored by developers. In this paper, we conducted an empirical study on real-world DC issues collected from large open source projects. We studied the manifestation and fixing patterns of DC issues. Based on our findings, we designed Decca, an automated detection tool that assesses DC issues' severity and filters out the benign ones. Our evaluation results on 30 projects show that Decca achieves a precision of 0.923 and recall of 0.766 in detecting high-severity DC issues. Decca also detected new DC issues in these projects. Subsequently, 20 DC bug reports were filed, and 11 of them were confirmed by developers. Issues in 6 reports were fixed with our suggested patches.\n    ","paperUrl":"materials/fse18-ying.pdf","projectUrl":"https://deccadc.github.io/fse18/","slidesUrl":"materials/fse18-ying-slides.pdf","bibtex":"@inproceedings{wang2018conflict,\n title={Do the Dependency Conflicts in My Project Matter?},\n author={Wang, Ying and Wen, Ming and Liu, Zhenwei and Wu, Rongxin and Wang, Rui and Yang, Bo and Yu, Hai and Zhu, Zhiliang and Cheung, Shing-Chi},\n booktitle={Proceedings of the 2018 26th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2018)},\n pages={1--12},\n year={2018},\n organization={ACM}\n}","arxivUrl":null,"awards":[]},{"title":"Using Risk Analysis to Prioritize Test Cases","date":"2018","authors":["Ying Wang","Hai Yu","Zhiliang Zhu"],"venue":"Journal of Systems and Software (JSS)","venueShort":"JSS","tags":[],"abstract":"\n    In this paper, we present a risk-based test case prioritization (Ri-TCP) algorithm based on the transmission of information flows among software components. Most of the existing approaches rely on the historical code changes or test case execution data, few of them effectively use the system topology information covered by test cases when scheduling the execution of test cases. From the perspective of code structure, the proposed algorithm firstly maps software into an information flow-based directed network model. Then, functional paths covered by each test case are represented by a set of barbell motifs. Finally, combining with probabilistic risk analysis (PRA) and fault tree model, we assign a priority to each test case by calculating the sum of risk indexes of all the barbells covered by it. Experimental results demonstrate that Ri-TCP technique has a higher detection rate of faults with serious risk indicators and performs stably in different systems, compared with the other state-of-the-art algorithms.\n    ","paperUrl":"materials/JSS18-ying.pdf","bibtex":"@article{wang2018using,\n  title={Using reliability risk analysis to prioritize test cases},\n  author={Ying, Wang and Zhiliang, Zhu and Bo,Yang and Fangda, Guo and Hai,Yu},\n  journal={Journal of Systems and Software},\n  volume={139},\n  pages={14--31},\n  year={2018},\n  publisher={Elsevier}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Could I Have a Stack Trace to Examine the Dependency Conflict Issue?","date":"2019","authors":["Ying Wang","Ming Wen","Rongxin Wu","Zhenwei Liu","Shin Hwei Tan","Zhiliang Zhu","Hai Yu","Shing-Chi Cheung"],"venue":"International Conference on Software Engineering 2019, Technical Research Paper, Montréal, QC, Canada, 25 May - 31 May","venueShort":"ICSE","tags":[],"abstract":"\n    Intensive use of libraries in Java projects brings potential risk of dependency conflicts, which occur when a project directly or indirectly depends on multiple versions of the same library or class. When this happens, JVM loads one version and shadows the others. Runtime exceptions can occur when methods in the shadowed versions are referenced. Although project management tools such as Maven are able to give warnings of potential dependency conflicts when a project is built, developers often ask for crashing stack traces before examining these warnings. It motivates us to develop RIDDLE, an automated approach that generates tests and collects crashing stack traces for projects subject to risk of dependency conflicts. RIDDLE, built on top of ASM and EVOSUITE, combines condition mutation, search strategies and condition restoration. We applied RIDDLE on 19 real-world Java projects with duplicate libraries or classes. We reported 20 identified dependency conflicts including their induced crashing stack traces and the details of generated tests. Among them, 15 conflicts were confirmed by developers as real issues, and 10 were readily fixed. The evaluation results demonstrate the effectiveness and usefulness of RIDDLE.\n    ","paperUrl":"materials/ICSE19-ying.pdf","projectUrl":"https://skillwind.github.io/RiddleDC/index.html","bibtex":"@inproceedings {WANG2019STACK,\n  title = {{Could I Have a Stack Trace to Examine the Dependency Conflict Issue?}},\n  author = {Ying, Wang and Ming, Wen and Rongxin, Wu and Zhenwei, Liu and Shin Hwei, Tan and Zhiliang, Zhu and Hai, Yu and Shing-Chi, Cheung},\n  booktitle = {{Proceedings of the 41th International Conference on Software Engineering}},\n  series = {ICSE 2019},\n  year = {2019},\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Scaling Up Symbolic Analysis by Removing Z-Equivalent States","date":"2014","authors":["Yueqi Li","Shing-Chi Cheung","Xiangyu Zhang","Yepang Liu"],"venue":"ACM Transactions on Software Engineering and Methodology 23(4), August 2014","venueShort":"TOSEM","tags":[],"abstract":"\n    Path explosion is a major issue in applying path-sensitive symbolic analysis to large programs. We ob- serve that many symbolic states generated by the symbolic analysis of a procedure are indistinguishable to its callers. It is, therefore, possible to keep only one state from each set of equivalent symbolic states without affecting the analysis result. Based on this observation, we propose an equivalence relation called z-equivalence, which is weaker than logical equivalence, to relate a large number of z-equivalent states. We prove that z-equivalence is strong enough to guarantee that paths to be traversed by the symbolic analysis of two z-equivalent states are identical, giving the same solutions to satisfiability and validity queries. We propose a sound linear algorithm to detect z-equivalence. Our experiments show that the symbolic analysis that leverages z-equivalence is able to achieve more than ten orders of magnitude reduction in terms of search space. The reduction significantly alleviates the path explosion problem, enabling us to apply symbolic analysis in large programs such as Hadoop and Linux Kernel.\n    ","paperUrl":"http://sccpu2.cse.ust.hk/andrewust/files/tosem14.pdf","bibtex":"@article{Li:TOSEM2014,\n  author = {Li, Yueqi and Cheung, Shing-Chi and Zhang, Xiangyu and Liu, Yepang},\n  title = {Scaling Up Symbolic Analysis by Removing Z-Equivalent States},\n  journal = {ACM Trans. Softw. Eng. Methodol.},\n  issue_date = {August 2014},\n  volume = {23},\n  number = {4},\n  month = sep,\n  year = {2014},\n  pages = {34:1--34:32},\n  articleno = {34},\n  url = {http://doi.acm.org/10.1145/2652484},\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Symbolic State Validation through Runtime Data","date":"2014","authors":["Yueqi Li","Shing-Chi Cheung"],"venue":"29th IEEE/ACM International Conference on Automated Software Engineering (ASE 2014), Vasteras, Sweden, September 2014","venueShort":"ASE","tags":[],"abstract":"\n    Real world programs are typically built on top of many library functions. Symbolic analysis of these programs generally requires precise models of these functions? Application Programming Interfaces (APIs), which are mostly unavailable because these models are costly to construct. A variant approach of symbolic analysis is to over-approximate the return values of those APIs that have not been modeled. However, such approximation can induce many unreachable symbolic states, which are expensive to validate manually. In this paper, we propose a static approach to automatically validating the reported anomalous symbolic states. The validation makes use of the available runtime data of the un-modeled APIs collected from previous program executions. We show that the symbolic state validation problem can be cast as a MAX-SAT problem and solved by existing constraint solvers.\n\nOur approach is motivated by two observations. We may bind the symbolic parameters in un-modeled APIs based on observations made in former executions by other programs. The binding enables us to use the corresponding observed concrete return values of APIs to validate the symbolic states arising from the over-approximated return values of the un-modeled APIs. Second, some symbolic constraints can be accurately evaluated despite the imprecision of the over-approximated symbolic values.\n\nOur technique found 80 unreported bugs when it was applied to 10 popular programs with a total of 1.5 million lines of code. All of them can be confirmed by test cases. Our technique presents a promising way to apply the big data paradigm to software engineering. It provides a mechanism to validate the symbolic states of a project by leveraging the many concrete input-output values of APIs collected from other projects.\n    ","paperUrl":"http://dl.acm.org/citation.cfm?doid=2642937.2642973","bibtex":"@inproceedings{DBLP:conf/kbse/LiC14,\n  author    = {Yueqi Li and\n               Shing{-}Chi Cheung},\n  title     = {Symbolic state validation through runtime data},\n  booktitle = {{ACM/IEEE} International Conference on Automated Software Engineering,\n               {ASE} '14, Vasteras, Sweden - September 15 - 19, 2014},\n  pages     = {187--198},\n  year      = {2014},\n  crossref  = {DBLP:conf/kbse/2014},\n  url       = {http://doi.acm.org/10.1145/2642937.2642973},\n  doi       = {10.1145/2642937.2642973},\n  timestamp = {Fri, 07 Nov 2014 12:44:47 +0100},\n  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/kbse/LiC14},\n  bibsource = {dblp computer science bibliography, http://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"An Empirical Study on TensorFlow Program Bugs","date":"2018","authors":["Yuhao Zhang","Yifan Chen","Shing-Chi Cheung","Yingfei Xiong","Lu Zhang"],"venue":"International Symposium on Software Testing and Analysis, Amsterdam Netherlands, July 2018","venueShort":"ISSTA","tags":[],"abstract":"\n    Deep learning applications become increasingly popular in important domains such as self-driving systems and facial identity systems. Defective deep learning applications may lead to catastrophic consequences. Although recent research efforts were made on testing and debugging deep learning applications, the characteristics of deep learning defects have never been studied. To fill this gap, we studied deep learning applications built on top of TensorFlow and collected program bugs related to TensorFlow from StackOverflow QA pages and Github projects. We extracted information from QA pages, commit messages, pull request messages, and issue discussions to examine the root causes and symptoms of these bugs. We also studied the strategies deployed by TensorFlow users for bug detection and localization. These findings help researchers and TensorFlow users to gain a better understanding of coding defects in TensorFlow programs and point out a new direction for future research.\n    ","paperUrl":"materials/issta18main-p98-p.pdf","bibtex":"@inproceedings {ISSTA18,\n  title = {{An Empirical Study on TensorFlow Program Bugs}},\n  author = {Yuhao Zhang, Yifan Chen, Shing-Chi Cheung, Yingfei Xiong, Lu Zhang},\n  booktitle = {{Proceedings of The ACM SIGSOFT International Symposium on Software Testing and Analysis}},\n  year = {2018},\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"ReScue: Crafting Regular Expression DoS Attacks","date":"2018","authors":["Yuju Shen","Yanyan Jiang","Chang Xu","Ping Yu","Xiaoxing Ma","Jian Lu"],"venue":"2018 33rd ACM/IEEE International Conference on Automated Software Engineering (ASE '18), September 2018, Montpellier, France","venueShort":"ASE","tags":[],"abstract":"\n    Regular expression (regex) with modern extensions is one of the most popular string processing tools. However, poorly-designed regexes can yield exponentially many matching steps, and lead to regex Denial-of-Service (ReDoS) attacks under well-conceived string inputs. This paper presents ReScue, a three-phase gray-box analytical technique, to automatically generate ReDoS strings to highlight vulnerabilities of given regexes. ReScue systematically seeds (by a genetic search), incubates (by another genetic search), and finally pumps (by a regex-dedicated algorithm) for generat- ing strings with maximized search time. We implemenmted the ReScue tool and evaluated it against 29,088 practical regexes in real-world projects. The evaluation results show that ReScue found 49% more attack strings compared with the best existing technique, and applying ReScue to popular GitHub projects discovered ten previously unknown ReDoS vulnerabilities.\n    ","paperUrl":"https://cs.nju.edu.cn/changxu/1_publications/ASE18.pdf","projectUrl":"http://2bdenny.github.io/ReScue/","bibtex":"@inproceedings{shen_rescue_2018,\n  author    = {Yuju Shen and Yanyan Jiang and Chang Xu and Ping Yu and Xiaoxing Ma and Jian Lu},\n  title     = {ReScue: Crafting regular expression DoS attacks},\n  pages     = {to appear},\n  year      = {2018},\n  booktitle = {Proceedings of the 33rd International Conference on Automated Software Engineering (ASE)},\n  pdf       = {/spar/publication/shen_rescue_2018.pdf},\n  code      = {http://2bdenny.github.io/ReScue/},\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Analyzing and Disentangling Interleaved Interrupt-Driven IoT Programs","date":"2019","authors":["Yuxia Sun","Song Guo","Shing-Chi Cheung","Yong Tang"],"venue":"IEEE Internet of Things Journal 2019","venueShort":"IoT-J","tags":[],"abstract":"\n    In the Internet of Things (IoT) community, wireless sensor network (WSN) is a key technique to enable ubiquitous sensing of environments and provide reliable services to applications. WSN programs, typically interrupt-driven, implement the functionalities via the collaboration of interrupt procedure instances (IPIs, namely executions of interrupt processing logic). However, due to the complicated concurrency model of WSN programs, the IPIs are interleaved intricately and the program behaviors are hard to predicate from the source codes. Thus, to improve the software quality of WSN programs, it is significant to disentangle the interleaved executions and develop various IPI-based program analysis techniques, including offline and online ones. As the common foundation of those techniques, a generic efficient and real-time algorithm to identify IPIs is urgently desired. However, the existing instance-identification approach cannot satisfy the desires. In this paper, we first formally define the concept of IPI. Next, we propose a generic IPI-identification algorithm, and prove its correctness, real-time, and efficiency. We also conduct comparison experiments to illustrate that our algorithm is more efficient than the existing one in terms of both time and space. As the theoretical analyses and empirical studies exhibit, our algorithm provides the groundwork for IPI-based analyses of WSN programs in IoT environment.\n    ","paperUrl":"https://ieeexplore.ieee.org/document/8648188","bibtex":"@article{DBLP:journals/iotj/SunGCT19,\n  author    = {Yuxia Sun and\n               Song Guo and\n               Shing{-}Chi Cheung and\n               Yong Tang},\n  title     = {Analyzing and Disentangling Interleaved Interrupt-Driven IoT Programs},\n  journal   = {{IEEE} Internet of Things Journal},\n  volume    = {6},\n  number    = {3},\n  pages     = {5376--5386},\n  year      = {2019},\n  url       = {https://doi.org/10.1109/JIOT.2019.2900769},\n  doi       = {10.1109/JIOT.2019.2900769},\n  timestamp = {Fri, 05 Jul 2019 09:39:40 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/iotj/SunGCT19},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Disclosing and Locating Concurrency Bugs of Interrupt-Driven IoT Programs","date":"2019","authors":["Yuxia Sun","Shing-Chi Cheung","Song Guo","Ming Cheng"],"venue":"IEEE Internet of Things Journal 2019","venueShort":"IoT-J","tags":[],"abstract":"\n    The Internet of Things (IoT) is envisioned as a distributed network formed by many end devices, e.g., the motes of wireless sensor network (WSN). These important IoT end devices enable ubiquitous sensing of environments and provide reliable services for mission-critical applications. However, programs running on WSN devices are typically interrupt-driven and prone to interrupt-induced concurrency bugs, which are primarily caused by erroneous interleavings among interrupt procedure instances (IPIs) (namely, executions of interrupt processing logic). In this paper, we use a set of dynamic bug patterns to characterize the concurrency bugs due to buggy access-interleavings among IPIs to shared resources, including shared memory locations and shared communication channels. By matching the above bug patterns, a dynamic analysis approach called disclosing and locating concurrency bugs of interrupt-driven IoT programs based on dynamic bug patterns (Daemon) is proposed to automatically detect and locate concurrency bugs in WSN programs. A GUI tool of Daemon is developed. As the empirical studies exhibit, the tool can discover concurrency bugs effectively and locate the buggy source lines visually.\n    ","paperUrl":"https://ieeexplore.ieee.org/document/8746139","bibtex":"@article{DBLP:journals/iotj/SunCGC19,\n  author    = {Yuxia Sun and\n               Shing{-}Chi Cheung and\n               Song Guo and\n               Ming Cheng},\n  title     = {Disclosing and Locating Concurrency Bugs of Interrupt-Driven IoT Programs},\n  journal   = {{IEEE} Internet of Things Journal},\n  volume    = {6},\n  number    = {5},\n  pages     = {8945--8957},\n  year      = {2019},\n  url       = {https://doi.org/10.1109/JIOT.2019.2925291},\n  doi       = {10.1109/JIOT.2019.2925291},\n  timestamp = {Thu, 07 Nov 2019 09:19:37 +0100},\n  biburl    = {https://dblp.org/rec/bib/journals/iotj/SunCGC19},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Fuzzing Deep Learning Compilers with HirGen","date":"2023","authors":["Haoyang Ma","Qingchao Shen","Yongqiang Tian","Junjie Chen","Shing-Chi Cheung"],"venue":"ACM SIGSOFT International Symposium on Software Testing and Analysis","venueShort":"ISSTA","tags":["Deep Learning compiler testing"],"projectUrl":"https://zenodo.org/record/7905120#.ZKptii9ByJ8","paperUrl":null,"arxivUrl":null,"abstract":null,"bibtex":null,"slidesUrl":null,"awards":[]},{"title":"StubCoder: Automated Generation and Repair of Stub Code for Mock Objects","date":"2023","authors":["Hengcheng Zhu","Lili Wei","Valerio Terragni","Yepang Liu","Shing-Chi Cheung","Jiarong Wu","Qin Sheng","Bing Zhang","Lihong Song"],"venue":"ACM Transactions on Software Engineering and Methodology","venueShort":"TOSEM","tags":["Mocking","Unit Test"],"abstract":"Mocking is an essential unit testing technique for isolating the class under test (CUT) from its dependencies. Developers often leverage mocking frameworks to develop stub code that specifies the behaviors of mock objects. However, developing and maintaining stub code is labor-intensive and error-prone. In this paper, we present StubCoder to automatically generate and repair stub code for regression testing. StubCoder implements a novel evolutionary algorithm that synthesizes test-passing stub code guided by the runtime behavior of test cases. We evaluated our proposed approach on 59 test cases from 13 open-source projects. Our evaluation results show that StubCoder can effectively generate stub code for incomplete test cases without stub code and repair obsolete test cases with broken stub code.","paperUrl":"https://doi.org/10.1145/3617171","projectUrl":"https://github.com/henryhchchc","bibtex":"@article{10.1145/3617171,\n        author = {Zhu, Hengcheng and Wei, Lili and Terragni, Valerio and Liu, Yepang and Cheung, Shing-Chi and Wu, Jiarong and Sheng, Qin and Zhang, Bing and Song, Lihong},\n        title = {StubCoder: Automated Generation and Repair of Stub Code for Mock Objects},\n        year = {2023},\n        publisher = {Association for Computing Machinery},\n        address = {New York, NY, USA},\n        issn = {1049-331X},\n        url = {https://doi.org/10.1145/3617171},\n        doi = {10.1145/3617171},\n        abstract = {Mocking is an essential unit testing technique for isolating the class under test (CUT) from its dependencies. Developers often leverage mocking frameworks to develop stub code that specifies the behaviors of mock objects. However, developing and maintaining stub code is labor-intensive and error-prone. In this paper, we present StubCoder to automatically generate and repair stub code for regression testing. StubCoder implements a novel evolutionary algorithm that synthesizes test-passing stub code guided by the runtime behavior of test cases. We evaluated our proposed approach on 59 test cases from 13 open-source projects. Our evaluation results show that StubCoder can effectively generate stub code for incomplete test cases without stub code and repair obsolete test cases with broken stub code.},\n        note = {Just Accepted},\n        journal = {ACM Trans. Softw. Eng. Methodol.},\n        month = {aug},\n        keywords = {Test Generation and Repair, Genetic Programming, Software Testing, Mocking, Evolutionary Computation, Program Analysis}\n        }","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"MockSniffer: Characterizing and Recommending Mocking Decisions for Unit Tests","date":"2020","authors":["Hengcheng Zhu","Lili Wei","Ming Wen","Yepang Liu","Shing-Chi Cheung","Qin Sheng","Cui Zhou"],"venue":"IEEE/ACM International Conference on Automated Software Engineering","venueShort":"ASE","tags":["Mocking","Unit Test"],"abstract":"In unit testing, mocking is popularly used to ease test effort, reduce test flakiness, and increase test coverage by replacing the actual dependencies with simple implementations. However, there are no clear criteria to determine which dependencies in a unit test should be mocked. Inappropriate mocking can have undesirable consequences: under-mocking could result in the inability to isolate the class under test (CUT) from its dependencies while over-mocking increases the developers' burden on maintaining the mocked objects and may lead to spurious test failures. According to existing work, various factors can determine whether a dependency should be mocked. As a result, mocking decisions are often difficult to make in practice. Studies on the evolution of mocked objects also showed that developers tend to change their mocking decisions: 17% of the studied mocked objects were introduced sometime after the test scripts were created and another 13% of the originally mocked objects eventually became unmocked. In this work, we are motivated to develop an automated technique to make mocking recommendations to facilitate unit testing. We studied 10,846 test scripts in four actively maintained open-source projects that use mocked objects, aiming to characterize the dependencies that are mocked in unit testing. Based on our observations on mocking practices, we designed and implemented a tool, MockSniffer, to identify and recommend mocks for unit tests. The tool is fully automated and requires only the CUT and its dependencies as input. It leverages machine learning techniques to make mocking recommendations by holistically considering multiple factors that can affect developers' mocking decisions. Our evaluation of MockSniffer on ten open-source projects showed that it outperformed three baseline approaches, and achieved good performance in two potential application scenarios.","paperUrl":"https://doi.org/10.1145/3324884.3416539","projectUrl":"https://github.com/henryhchchc/MockSniffer","bibtex":"@inproceedings{10.1145/3324884.3416539,\n            author = {Zhu, Hengcheng and Wei, Lili and Wen, Ming and Liu, Yepang and Cheung, Shing-Chi and Sheng, Qin and Zhou, Cui},\n            title = {MockSniffer: Characterizing and Recommending Mocking Decisions for Unit Tests},\n            year = {2020},\n            isbn = {9781450367684},\n            publisher = {Association for Computing Machinery},\n            address = {New York, NY, USA},\n            url = {https://doi.org/10.1145/3324884.3416539},\n            doi = {10.1145/3324884.3416539},\n            abstract = {In unit testing, mocking is popularly used to ease test effort, reduce test flakiness, and increase test coverage by replacing the actual dependencies with simple implementations. However, there are no clear criteria to determine which dependencies in a unit test should be mocked. Inappropriate mocking can have undesirable consequences: under-mocking could result in the inability to isolate the class under test (CUT) from its dependencies while over-mocking increases the developers' burden on maintaining the mocked objects and may lead to spurious test failures. According to existing work, various factors can determine whether a dependency should be mocked. As a result, mocking decisions are often difficult to make in practice. Studies on the evolution of mocked objects also showed that developers tend to change their mocking decisions: 17% of the studied mocked objects were introduced sometime after the test scripts were created and another 13% of the originally mocked objects eventually became unmocked. In this work, we are motivated to develop an automated technique to make mocking recommendations to facilitate unit testing. We studied 10,846 test scripts in four actively maintained open-source projects that use mocked objects, aiming to characterize the dependencies that are mocked in unit testing. Based on our observations on mocking practices, we designed and implemented a tool, MockSniffer, to identify and recommend mocks for unit tests. The tool is fully automated and requires only the CUT and its dependencies as input. It leverages machine learning techniques to make mocking recommendations by holistically considering multiple factors that can affect developers' mocking decisions. Our evaluation of MockSniffer on ten open-source projects showed that it outperformed three baseline approaches, and achieved good performance in two potential application scenarios.},\n            booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},\n            pages = {436–447},\n            numpages = {12},\n            keywords = {unit testing, dependencies, recommendation system, mocking},\n            location = {Virtual Event, Australia},\n            series = {ASE '20}\n        }","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"How Do Python Framework APIs Evolve? An Exploratory Study","date":"2020","authors":["Zhaoxu Zhang","Hengcheng Zhu","Ming Wen","Yida Tao","Yepang Liu","Yingfei Xiong"],"venue":"International Conference on Software Analysis, Evolution and Reengineering","venueShort":"SANER","tags":["Python","API Evolution"],"abstract":"Python is a popular dynamic programming language. In recent years, many frameworks implemented in Python have been widely used for data science and web development. Similar to frameworks in other languages, the APIs provided by Python frameworks often evolve, which would inevitably induce compatibility issues in client applications. While existing work has studied the evolution of frameworks in static programming languages such as Java, little is known on how Python framework APIs evolve and the characteristics of the compatibility issues induced by such evolution. To bridge this gap, we take a first look at the evolution of Python framework APIs and the resulting compatibility issues in client applications. We analyzed 288 releases of six popular Python frameworks from three different domains and 5,538 open-source projects built on these frameworks. We investigated the evolution patterns of Python framework APIs and found that they largely differ from those of Java framework APIs. We also investigated the compatibility issues in client applications and identified common strategies that developers adopt to fix these issues. Based on the empirical findings, we designed and implemented a tool, PYCOMPAT , to automatically detect compatibility issues caused by misusing evolved framework APIs in Python applications. Experiments on 10 real-world projects show that our tool can effectively detect compatibility issues of developers' concern.","paperUrl":"https://doi.org/10.1109/SANER48275.2020.9054800","projectUrl":"https://github.com/sqlab-sustech/PyCompat","bibtex":"@INPROCEEDINGS{9054800,\n            author={Zhang, Zhaoxu and Zhu, Hengcheng and Wen, Ming and Tao, Yida and Liu, Yepang and Xiong, Yingfei},\n            booktitle={2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)},\n            title={How Do Python Framework APIs Evolve? An Exploratory Study},\n            year={2020},\n            volume={},\n            number={},\n            pages={81-92},\n            doi={10.1109/SANER48275.2020.9054800}\n        }","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Characterizing and Detecting Configuration Compatibility Issues in Android Apps","date":"2021-08-26","authors":["Huaxun Huang","Ming Wen","Lili Wei","Yepang Liu","Shing-Chi Cheung"],"venue":"Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering (ASE '21)","venueShort":"ASE","tags":["Android","Compatibility Issues","XML Configurations"],"abstract":"\nXML configuration files are widely used in Android to define an app's user interface and essential runtime information such as system permissions. As Android evolves, it might introduce functional changes in the configuration environment, thus causing compatibility issues that manifest as inconsistent app behaviors at different API levels. Such issues can often induce software crashes and inconsistent look-and-feel when running at specific Android versions. Existing works incur plenty of false positive and false negative issue-detection rules by conducting trivial data-flow analysis while failing to model the XML tree hierarchies of the Android configuration files. Besides, little is known about how the changes in an Android framework can induce such compatibility issues. To bridge such gaps, we conducted a systematic study by analyzing 196 real-world issues collected from 43 popular apps. We identified common patterns of Android framework code changes that induce such configuration compatibility issues. Based on the findings, we propose ConfDroid that can automatically extract rules for detecting configuration compatibility issues. The intuition is to perform symbolic execution based on a model learned from the common code change patterns. Experiment results show that ConfDroid can successfully extract 282 valid issue-detection rules with a precision of 91.9%. Among them, 65 extracted rules can manifest issues that cannot be detected by the rules of state-of-the-art baselines. More importantly, 11 out of them have led to the detection of 107 reproducible configuration compatibility issues that the baselines cannot detect in 30 out of 316 real-world Android apps.\n    ","projectUrl":"https://sites.google.com/view/confdroid","paperUrl":"https:/castlelab.github.io/selected-publications/assets/ConfDroid-ASE21.pdf","arxivUrl":null,"bibtex":null,"slidesUrl":null,"awards":[]},{"title":"FlashSchema: Achieving High Quality XML Schemas with Powerful Inference Algorithms and Large-scale Schema Data.","date":"2020","authors":["Yeting LI"," Jialun CAO"," Haiming CHEN"," Tingjian GE"," Zhiwu XU"," Qiancheng PENG"],"venue":"International Conference on Data Engineering","venueShort":"ICDE","tags":["XML Schemas","Schemas Inference"],"abstract":"Getting high quality XML schemas to avoid or reduce application risks is an important problem in practice, for which some important aspects have yet to be addressed satisfactorily in existing work. In this paper, we propose a tool FlashSchema for high quality XML schema design, which supports both one-pass and interactive schema design and schema recommendation. To the best of our knowledge, no other existing tools support interactive schema design and schema recommendation. One salient feature of our work is the design of algorithms to infer k-occurrence interleaving regular expressions, which are not only more powerful in model capacity, but also more efficient. Additionally, such algorithms form the basis of our interactive schema design. The other feature is that, starting from largescale schema data that we have harvested from the Web, we devise a new solution for type inference, as well as propose schema recommendation for schema design. Finally, we conduct a series of experiments on two XML datasets, comparing with 9 state-of-the-art algorithms and open-source tools in terms of running time, preciseness, and conciseness. Experimental results show that our work achieves the highest level of preciseness and conciseness within only a few seconds. Experimental results and examples also demonstrate the effectiveness of our type inference and schema recommendation methods.","paperUrl":"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9101818","arxivUrl":null,"bibtex":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"FlashRegex: Deducing Anti-ReDoS Regexes from Examples.","date":"2020","authors":["Yeting LI"," Zhiwu XU"," Jialun CAO"," Haiming CHEN"," Tingjian GE"," Shing-Chi CHEUNG","Haoren ZHAO"],"venue":"International Conference on Automated Software Engineering","venueShort":"ASE","tags":["regular expression","Anti-ReDoS","program synthesis","program repair"],"abstract":"Regular expressions (regexes) are widely used in different fields of computer science such as programming languages, string processing and databases. However, existing tools for synthesizing or repairing regexes were not designed to be resilient to Regex Denial of Service (ReDoS) attacks. Specifically, if a regex has super-linear (SL) worst-case complexity, an attacker could provide carefully-crafted inputs to launch ReDoS attacks. Therefore, in this paper, we propose a programming-by-example framework, FlashRegex, for generating anti-ReDoS regexes by either synthesizing or repairing from given examples. It is the first framework that integrates regex synthesis and repair with the awareness of ReDoS-vulnerabilities. We present novel algorithms to deduce anti-ReDoS regexes by reducing the ambiguity of these regexes and by using Boolean Satisfiability (SAT) or Neighborhood Search (NS) techniques. We evaluate FlashRegex with five related state-of-the-art tools. The evaluation results show that our work can effectively and efficiently generate anti-ReDoS regexes from given examples, and also reveal that existing synthesis and repair tools have neglected ReDoS-vulnerabilities of regexes. Specifically, the existing synthesis and repair tools generated up to 394 ReDoS-vulnerable regex within few seconds to more than one hour, while FlashRegex generated no SL regex within around five seconds. Furthermore, the evaluation results on ReDoS-vulnerable regex repair also show that FlashRegex has better capability than existing repair tools and even human experts, achieving 4 more ReDoS-invulnerable regex after repair without trimming and resorting, highlighting the usefulness of FlashRegex in terms of the generality, automation and user-friendliness","paperUrl":"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9286092","arxivUrl":null,"bibtex":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"TransRegex: Multi-modal Regular Expression Synthesis by Generate-and-Repair.","date":"2021","authors":["Yeting LI"," Shuaimin LI"," Zhiwu XU"," Jialun CAO"," Zixuan CHEN"," Yun HU"," Haiming CHEN","Shing-Chi CHEUNG"],"venue":"International Conference on Software Engineering","venueShort":"ICSE","tags":["regular expression","regular expression synthesis","regex synthesis","regex repair","programming by example","programming by natural language"],"abstract":"Since regular expressions (abbrev. regexes) are difficult to understand and compose, automatically generating regexes has been an important research problem. This paper introduces Tr ansRegex , lor automatically constructing regexes from both natural language descriptions and examples. To the best of our knowledge, Tr ansRegex is the first to treat the Nl.P-and-example-based regex synthesis problem as the problem of NLP-based synthesis with regex repair. For this purpose, we present novel algorithms for both NLP-based synthesis and regex repair. We evaluate Tr ansRegex with ten relevant state-of-theart tools on three publicly available datasets. The evaluation results demonstrate that the accuracy of our Tr ansRegex is 17.4%, 35.8% and 38.9% higher than that of NLP-hased approaches on the three datasets, respectively. Furthermore, T r ansRegex can achieve higher accuracy than the stateof-the-art multi-modal techniques with 10% to 30% higher accuracy on all three datasets. The evaluation results also indicate Tr ansRegex utilizing natural language and examples in a more effective way.","paperUrl":"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9401951","arxivUrl":null,"bibtex":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"ReDoSHunter: A Combined Static and Dynamic Approach for Regular Expression DoS Detection.","date":"2021","authors":["Yeting Li"," Zixuan Chen"," Jialun Cao"," Zhiwu Xu"," Qiancheng Peng"," Haiming Chen"," Liyuan Chen"," Shing-Chi Cheung"],"venue":"USENIX Security Symposium","venueShort":"USENIX Security","tags":["regular expression","Anti-ReDoS","ReDoS detection"],"abstract":"Regular expression Denial of Service (ReDoS) is a class of algorithmic complexity attacks where there exist inputs causing the typical backtracking-based matching algorithms to run super-linear time. Considering the widespread use of regular expressions (regexes), ReDoS is a pervasive and serious threat. Thus, early detection of ReDoS-vulnerable regexes in software projects is vital. Existing detection approaches mainly fall into two categories: static and dynamic analysis. However, the static approaches detect more candidate vulnerabilities at the cost of low precision, while dynamic approaches guarantee the precision of detection yet compromise the recall. Detecting ReDos at both high precision and high recall remains unsolved. Furthermore, we observed that a ReDoSvulnerable regex often contains more than one vulnerability in practice. However, existing tools are incapable of detecting multiple vulnerabilities in one regex. To bridge the gaps, we proposes ReDoSHunter, a ReDoSvulnerable regex detection framework that can effectively pinpoint the multiple root causes of a vulnerable regex and generate the associated attack-triggering strings. Driven by our concluded ﬁve vulnerability patterns, ReDoSHunter can not only pinpoint the multiple vulnerabilities in one regex, but also assess the degree (i.e., exponential or polynomial) of vulnerabilities it detects. The experiment results show that ReDoSHunter is able to achieve 100% precision and 100% recall on three large-scale datasets with 37,651 regexes. Furthermore, apart from being able to detect 100% the conﬁrmed ReDoS CVEs (compared with 14.29%-60.00% achieved by existing works), ReDoSHunter also exposed 28 new ReDoSvulnerabilities in intensively-tested projects, resulting in 26 assigned CVEs and 2 ﬁxed by developers.","paperUrl":null,"arxivUrl":null,"bibtex":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Programming by Example Made Easy","date":"2023","authors":["Jiarong Wu","Lili Wei","Yanyan Jiang","Shing-Chi Cheung","Luyao Ren","Chang Xu"],"venue":"ACM Transactions on Software Engineering and Methodology","venueShort":"TOSEM","tags":["Programming Synthesis","Programming by Example"],"abstract":"Programming by example (PBE) is an emerging programming paradigm that automatically synthesizes programs specified by user-provided input-output examples. Despite the convenience for end-users, implementing PBE tools often requires strong expertise in programming language and synthesis algorithms. Such a level of knowledge is uncommon among software developers. It greatly limits the broad adoption of PBE by the industry. To facilitate the adoption of PBE techniques, we propose a PBE framework called Bee, which leverages an “entity-action” model based on relational tables to ease PBE development for a wide but restrained range of domains. Implementing PBE tools with Bee only requires adapting domain-specific data entities and user actions to tables, with no need to design a domain-specific language or an efficient synthesis algorithm. The synthesis algorithm of Bee exploits bidirectional searching and constraint-solving techniques to address the challenge of value computation nested in table transformation. We evaluated Bee’s effectiveness on 64 PBE tasks from three different domains and usability with a human study of 12 participants. Evaluation results show that Bee is easier to learn and use than the state-of-the-art PBE framework, and the bidirectional algorithm achieves comparable performance to domain-specifically optimized synthesizers.","paperUrl":"https://dl.acm.org/doi/10.1145/3607185","projectUrl":"https://github.com/Sissel-Wu/Bee","bibtex":"@article{10.1145/3607185,\nauthor = {Wu, Jiarong and Wei, Lili and Jiang, Yanyan and Cheung, Shing-Chi and Ren, Luyao and Xu, Chang},\ntitle = {Programming by Example Made Easy},\nyear = {2023},\nissue_date = {January 2024},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {33},\nnumber = {1},\nissn = {1049-331X},\nurl = {https://doi.org/10.1145/3607185},\ndoi = {10.1145/3607185},\nabstract = {Programming by example (PBE) is an emerging programming paradigm that automatically synthesizes programs specified by user-provided input-output examples. Despite the convenience for end-users, implementing PBE tools often requires strong expertise in programming language and synthesis algorithms. Such a level of knowledge is uncommon among software developers. It greatly limits the broad adoption of PBE by the industry. To facilitate the adoption of PBE techniques, we propose a PBE framework called Bee, which leverages an “entity-action” model based on relational tables to ease PBE development for a wide but restrained range of domains. Implementing PBE tools with Bee only requires adapting domain-specific data entities and user actions to tables, with no need to design a domain-specific language or an efficient synthesis algorithm. The synthesis algorithm of Bee exploits bidirectional searching and constraint-solving techniques to address the challenge of value computation nested in table transformation. We evaluated Bee’s effectiveness on 64 PBE tasks from three different domains and usability with a human study of 12 participants. Evaluation results show that Bee is easier to learn and use than the state-of-the-art PBE framework, and the bidirectional algorithm achieves comparable performance to domain-specifically optimized synthesizers.},\njournal = {ACM Trans. Softw. Eng. Methodol.},\nmonth = {nov},\narticleno = {4},\nnumpages = {36},\nkeywords = {programming by example, Program synthesis}\n}","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"Can Systems Explain Permissions Better? Understanding Users' Misperceptions under Smartphone Runtime Permission Model","date":"2021-08-11","authors":["Bingyu Shen","Lili Wei","Chengcheng Xiang","Yudong Wu","Mingyao Shen","Yuanyuan Zhou","Xinxin Jin"],"venue":"the 30th USENIX Security Symposium, Vancouver, BC, Canada, Aug 11-13 2021","venueShort":"USENIX Security","tags":["Android","User study","Security"],"abstract":"\n            Current smartphone operating systems enable users to manage permissions according to their personal preferences with a runtime permission model. Nonetheless, the systems provide very limited information when requesting permissions, making it difficult for users to understand permissions’ capabilities and potentially induced risks.\n            In this paper, we first investigated to what extent current system-provided information can help users understand the scope of permissions and their potential risks. We took a mixed-methods approach by collecting real permission settings from 4,636 Android users, an interview study of 20 participants, and large-scale Internet surveys of 1559 users. Our study identified several common misunderstandings on the runtime permission model among users. We found that only a very small percentage (6.1%) of users can infer the scope of permission groups accurately from the system-provided information. This indicates that the information provided by current systems is far from sufficient.\n            We thereby explored what extra information that systems can provide to help users make more informed permission decisions. By surveying users’ common concerns on apps’ permission requests, we identified five types of information (i.e., decision factors) that are helpful for users’ decisions. We further studied the impact and helpfulness of the factors to users’ permission decisions with both positive and negative messages. Our study shows that the background access factor helps most while the grant rate helps the least. Based on the findings, we provide suggestions for system designers to enhance future systems with more permission information.\n        ","projectUrl":"https://ucsdopera.github.io/PermissionStudyUsenix21/dataset/","paperUrl":"http://cseweb.ucsd.edu/~byshen/files/sec21-shen.pdf","arxivUrl":null,"bibtex":null,"slidesUrl":null,"awards":[]},{"title":"Logging Practices with Mobile Analytics: An Empirical Study on Firebase","date":"2021-05-17","authors":["Julian Harty","Haonan Zhang","Lili Wei","Luca Pascarella","Maurício Aniche","Weiyi Shang"],"venue":"the 8th IEEE/ACM International Conference on Mobile Software Engineering and Systems, Madrid, Spain, May 17-19 2021","venueShort":"MOBILESoft","tags":["Android","Empirical study"],"abstract":"\n            Software logs are of great value in both industrial and open-source projects. Mobile analytics logging enables developers to collect logs remotely from their apps running on end user devices at the cost of recording and transmitting logs across the Internet to a centralised infrastructure.\n            This paper makes a first step in characterising logging practices with a widely adopted mobile analytics logging library, namely Firebase Analytics. We provide an empirical evaluation of the use of Firebase Analytics in 57 open-source Android applications by studying the evolution of code-bases to understand: a) the needs-in-common that push practitioners to adopt logging practices on mobile devices, and b) the differences in the ways developers use local and remote logging.\n            Our results indicate mobile analytics logs are less pervasive and less maintained than traditional logging code. Based on our analysis, we believe logging using mobile analytics is more user centered compared to traditional logging, where the latter is mainly used to record information for debugging purposes.\n        ","paperUrl":"https://arxiv.org/abs/2104.02513","arxivUrl":null,"bibtex":null,"projectUrl":null,"slidesUrl":null,"awards":[]},{"title":"Characterizing Transaction-Reverting Statements inEthereum Smart Contracts","date":"2021-11-15","authors":["Lu Liu","Lili Wei","Wuqi Zhang","Ming Wen","Yepang Liu","Shing-Chi Cheung"],"venue":"The 36th IEEE/ACM International Conference on Automated Software Engineering","venueShort":"ASE","tags":["Blockchain","Smart Contracts","Empirical Study"],"awards":[],"abstract":"\nSmart contracts are programs stored on blockchains to execute transactions. \nWhen input constraints or security properties are violated at runtime, the transaction being executed by a smart contract needs to be reverted to avoid undesirable consequences.\nOn Ethereum, the most popular blockchain that supports smart contracts, developers can choose among three transaction-reverting statements (i.e., require, if...revert, and if...throw) to handle anomalous transactions.\nWhile these transaction-reverting statements are vital for preventing smart contracts from exhibiting abnormal behaviors or suffering malicious attacks, there is limited understanding of how they are used in practice. \nIn this work, we perform the first empirical study to characterize transaction-reverting statements in Ethereum smart contracts. \nWe measured the prevalence of these statements in 3,866 verified smart contracts from popular dapps and built a taxonomy of their purposes via manually analyzing 557 transaction-reverting statements.\nWe also compared template contracts and their corresponding custom contracts to understand how developers customize the use of transaction-reverting statements.\nFinally, we analyzed the security impact of transaction-reverting statements by removing them from smart contracts and comparing the mutated contracts against the original ones. \nOur study led to important findings.\nFor example, we found that transaction-reverting statements are commonly used to perform seven types of authority verifications or validity checks, and missing such statements may compromise the security of smart contracts.\nWe also found that current smart contract security analyzers cannot effectively handle transaction-reverting statements when detecting security vulnerabilities.\nOur findings can shed light on further research in the broad area of smart contract quality assurance and provide practical guidance to smart contract developers on the appropriate use of transaction-reverting statements. \n        ","projectUrl":"https://github.com/transaction-reverting-statements/Characterizing-require-statement-in-Ethereum-Smart-Contract","arxivUrl":"https://arxiv.org/abs/2108.10799","paperUrl":"https:/castlelab.github.io/selected-publications/assets/Characterizing_Transaction_Reverting_Statements-ASE21.pdf","slidesUrl":null,"bibtex":""},{"title":"LspFuzz: Hunting Bugs in Language Servers.","date":"2025","authors":["Hengcheng Zhu","Songqiang Chen","Valerio Terragni","Lili Wei","Yepang Liu","Jiarong Wu","Shing-Chi Cheung"],"venue":"40th IEEE/ACM International Conference on Automated Software Engineering","venueShort":"ASE","tags":[],"awards":[],"abstract":"The Language Server Protocol (LSP) has revolutionized the integration of code intelligence in modern software development. There are approximately 300 LSP server implementations for various languages and 50 editors offering LSP integration. However, the reliability of LSP servers is a growing concern, as crashes can disable all code intelligence features and significantly impact productivity, while vulnerabilities can put developers at risk even when editing untrusted source code. Despite the widespread adoption of LSP, no existing techniques specifically target LSP server testing. To bridge this gap, we present LspFuzz, a grey-box hybrid fuzzer for systematic LSP server testing. Our key insight is that effective LSP server testing requires holistic mutation of source code and editor operations, as bugs often manifest from their combinations. To satisfy the sophisticated constraints of LSP and effectively explore the input space, we employ a two-stage mutation pipeline: syntax-aware mutations to source code, followed by context-aware dispatching of editor operations. We evaluated LspFuzz on four widely used LSP servers. LspFuzz demonstrated superior performance compared to baseline fuzzers, and uncovered previously unknown bugs in real-world LSP servers. Of the 51 bugs we reported, 42 have been confirmed, 26 have been fixed by developers, and two have been assigned CVE numbers. Our work advances the quality assurance of LSP servers, providing both a practical tool and foundational insights for future research in this domain.","arxivUrl":null,"paperUrl":"https://doi.org/10.1109/ASE63991.2025.00183","bibtex":"@inproceedings{DBLP:conf/kbse/ZhuCTWLWC25,\n  author       = {Hengcheng Zhu and\n                  Songqiang Chen and\n                  Valerio Terragni and\n                  Lili Wei and\n                  Yepang Liu and\n                  Jiarong Wu and\n                  Shing{-}Chi Cheung},\n  title        = {LspFuzz: Hunting Bugs in Language Servers},\n  booktitle    = {40th {IEEE/ACM} International Conference on Automated Software Engineering,\n                  {ASE} 2025, Seoul, Korea, Republic of, November 16-20, 2025},\n  pages        = {2209--2221},\n  publisher    = {{IEEE}},\n  year         = {2025},\n  url          = {https://doi.org/10.1109/ASE63991.2025.00183},\n  doi          = {10.1109/ASE63991.2025.00183},\n  timestamp    = {Sun, 08 Feb 2026 15:06:01 +0100},\n  biburl       = {https://dblp.org/rec/conf/kbse/ZhuCTWLWC25.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Word Closure-Based Metamorphic Testing for Machine Translation.","date":"2024","authors":["Xiaoyuan Xie","Shuo Jin","Songqiang Chen","Shing-Chi Cheung"],"venue":"ACM Transactions on Software Engineering and Methodology","venueShort":"ACM","tags":[],"awards":[],"abstract":null,"arxivUrl":null,"paperUrl":"https://doi.org/10.1145/3675396","bibtex":"@article{DBLP:journals/tosem/XieJCC24,\n  author       = {Xiaoyuan Xie and\n                  Shuo Jin and\n                  Songqiang Chen and\n                  Shing{-}Chi Cheung},\n  title        = {Word Closure-Based Metamorphic Testing for Machine Translation},\n  journal      = {{ACM} Trans. Softw. Eng. Methodol.},\n  volume       = {33},\n  number       = {8},\n  pages        = {203:1--203:46},\n  year         = {2024},\n  url          = {https://doi.org/10.1145/3675396},\n  doi          = {10.1145/3675396},\n  timestamp    = {Sun, 02 Nov 2025 21:28:35 +0100},\n  biburl       = {https://dblp.org/rec/journals/tosem/XieJCC24.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"SURE: A Visualized Failure Indexing Approach Using Program Memory Spectrum.","date":"2024","authors":["Yi Song","Xihao Zhang","Xiaoyuan Xie","Songqiang Chen","Quanming Liu","Ruizhi Gao"],"venue":"ACM Transactions on Software Engineering and Methodology","venueShort":"ACM","tags":["Failure proximity","program memory","siamese learning","failure indexing","parallel debugging"],"awards":[],"abstract":"Failure indexing is a longstanding crux in software debugging, the goal of which is to automatically divide failures (e.g., failed test cases) into distinct groups according to the culprit root causes, as such multiple faults residing in a faulty program can be handled independently and simultaneously. The community of failure indexing has long been plagued by two challenges: (1) The effectiveness of division is still far from promising. Specifically, existing failure indexing techniques only employ a limited source of software runtime data, for example, code coverage, to be failure proximity and further divide them, which typically delivers unsatisfactory results. (2) The outcome can be hardly comprehensible. Specifically, a developer who receives the division result is just aware of how all failures are divided, without knowing why they should be divided the way they are. This leads to difficulties for developers to be convinced by the division result, which in turn affects the adoption of the results. To tackle these two problems, in this article, we propose SURE , a vi SU alized failu R e ind E xing approach using the program memory spectrum (PMS). We first collect the runtime memory information (i.e., variables’ names and values, as well as the depth of the stack frame) at several preset breakpoints during the execution of a failed test case, and transform the gathered memory information into a human-friendly image (called PMS). Then, any pair of PMS images that serve as proxies for two failures is fed to a trained Siamese convolutional neural network, to predict the likelihood of them being triggered by the same fault. Last, a clustering algorithm is adopted to divide all failures based on the mentioned likelihood. In the experiments, we use 30% of the simulated faults to train the neural network, and use 70% of the simulated faults as well as real-world faults to test. Results demonstrate the effectiveness of SURE: It achieves 101.20% and 41.38% improvements in faults number estimation, as well as 105.20% and 35.53% improvements in clustering, compared with the state-of-the-art technique in this field, in simulated and real-world environments, respectively. Moreover, we carry out a human study to quantitatively evaluate the comprehensibility of PMS, revealing that this novel type of representation can help developers better comprehend failure indexing results.","arxivUrl":null,"paperUrl":"https://doi.org/10.1145/3676958","bibtex":"@article{DBLP:journals/tosem/SongZXCLG24,\n  author       = {Yi Song and\n                  Xihao Zhang and\n                  Xiaoyuan Xie and\n                  Songqiang Chen and\n                  Quanming Liu and\n                  Ruizhi Gao},\n  title        = {{SURE:} {A} Visualized Failure Indexing Approach Using Program Memory\n                  Spectrum},\n  journal      = {{ACM} Trans. Softw. Eng. Methodol.},\n  volume       = {33},\n  number       = {8},\n  pages        = {210:1--210:43},\n  year         = {2024},\n  url          = {https://doi.org/10.1145/3676958},\n  doi          = {10.1145/3676958},\n  timestamp    = {Sun, 02 Nov 2025 21:28:35 +0100},\n  biburl       = {https://dblp.org/rec/journals/tosem/SongZXCLG24.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Metamorphic Testing of Image Captioning Systems via Image-Level Reduction.","date":"2024","authors":["Xiaoyuan Xie","Xingpeng Li","Songqiang Chen"],"venue":"IEEE Transactions on Software Engineering","venueShort":"IEEE","tags":[],"awards":[],"abstract":"The Image Captioning (IC) technique is widely used to describe images in natural language. However, even state-of-the-art IC systems can still produce incorrect captions and lead to misunderstandings. Recently, some IC system testing methods have been proposed. However, these methods still rely on pre-annotated information and hence cannot really alleviate the difficulty in identifying the test oracle. Furthermore, their methods artificially manipulate objects, which may generate unreal images as test cases and thus lead to less meaningful testing results. Thirdly, existing methods have various requirements on the eligibility of source test cases, and hence cannot fully utilize the given images to perform testing. To tackle these issues, in this paper, we propose <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">ReIC</small> to perform metamorphic testing for the IC systems with some image-level reduction transformations like image cropping and stretching. Instead of relying on the pre-annotated information, <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">ReIC</small> uses a localization method to align objects in the caption with corresponding objects in the image, and checks whether each object is correctly described or deleted in the caption after transformation. With the image-level reduction transformations, <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">ReIC</small> does not artificially manipulate any objects and hence can avoid generating unreal follow-up images. Additionally, it eliminates the requirement on the eligibility of source test cases during the metamorphic transformation process, as well as decreases the ambiguity and boosts the diversity among the follow-up test cases, which consequently enables testing to be performed on any test image and reveals more distinct valid violations. We employ <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">ReIC</small> to test five popular IC systems. The results demonstrate that <sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">ReIC</small> can sufficiently leverage the provided test images to generate follow-up cases of good realism, and effectively detect a great number of distinct violations, without the need for any pre-annotated information.","arxivUrl":null,"paperUrl":"https://doi.org/10.1109/TSE.2024.3463747","bibtex":"@article{DBLP:journals/tse/XieLC24,\n  author       = {Xiaoyuan Xie and\n                  Xingpeng Li and\n                  Songqiang Chen},\n  title        = {Metamorphic Testing of Image Captioning Systems via Image-Level Reduction},\n  journal      = {{IEEE} Trans. Software Eng.},\n  volume       = {50},\n  number       = {11},\n  pages        = {2962--2982},\n  year         = {2024},\n  url          = {https://doi.org/10.1109/TSE.2024.3463747},\n  doi          = {10.1109/TSE.2024.3463747},\n  timestamp    = {Sun, 22 Dec 2024 15:49:15 +0100},\n  biburl       = {https://dblp.org/rec/journals/tse/XieLC24.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"FastLog: An End-to-End Method to Efficiently Generate and Insert Logging Statements.","date":"2024","authors":["Xiaoyuan Xie","Zhipeng Cai","Songqiang Chen","Jifeng Xuan"],"venue":"the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis","venueShort":"ISSTA","tags":[],"awards":[],"abstract":null,"arxivUrl":null,"paperUrl":"https://doi.org/10.1145/3650212.3652107","bibtex":"@inproceedings{DBLP:conf/issta/XieCCX24,\n  author       = {Xiaoyuan Xie and\n                  Zhipeng Cai and\n                  Songqiang Chen and\n                  Jifeng Xuan},\n  editor       = {Maria Christakis and\n                  Michael Pradel},\n  title        = {FastLog: An End-to-End Method to Efficiently Generate and Insert Logging\n                  Statements},\n  booktitle    = {Proceedings of the 33rd {ACM} {SIGSOFT} International Symposium on\n                  Software Testing and Analysis, {ISSTA} 2024, Vienna, Austria, September\n                  16-20, 2024},\n  pages        = {26--37},\n  publisher    = {{ACM}},\n  year         = {2024},\n  url          = {https://doi.org/10.1145/3650212.3652107},\n  doi          = {10.1145/3650212.3652107},\n  timestamp    = {Thu, 03 Oct 2024 00:44:59 +0200},\n  biburl       = {https://dblp.org/rec/conf/issta/XieCCX24.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing.","date":"2024","authors":["Congying Xu","Songqiang Chen","Jiarong Wu","Shing-Chi Cheung","Valerio Terragni","Hengcheng Zhu","Jialun Cao"],"venue":"the 39th IEEE/ACM International Conference on Automated Software Engineering","venueShort":"ASE","tags":[],"awards":[],"abstract":null,"arxivUrl":null,"paperUrl":"https://doi.org/10.1145/3691620.3696020","bibtex":"@inproceedings{DBLP:conf/kbse/XuCWCT0C24,\n  author       = {Congying Xu and\n                  Songqiang Chen and\n                  Jiarong Wu and\n                  Shing{-}Chi Cheung and\n                  Valerio Terragni and\n                  Hengcheng Zhu and\n                  Jialun Cao},\n  editor       = {Vladimir Filkov and\n                  Baishakhi Ray and\n                  Minghui Zhou},\n  title        = {MR-Adopt: Automatic Deduction of Input Transformation Function for\n                  Metamorphic Testing},\n  booktitle    = {Proceedings of the 39th {IEEE/ACM} International Conference on Automated\n                  Software Engineering, {ASE} 2024, Sacramento, CA, USA, October 27\n                  - November 1, 2024},\n  pages        = {557--569},\n  publisher    = {{ACM}},\n  year         = {2024},\n  url          = {https://doi.org/10.1145/3691620.3696020},\n  doi          = {10.1145/3691620.3696020},\n  timestamp    = {Mon, 03 Mar 2025 21:16:52 +0100},\n  biburl       = {https://dblp.org/rec/conf/kbse/XuCWCT0C24.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"qaAskeR+: a novel testing method for question answering software via asking recursive questions.","date":"2023","authors":["Xiaoyuan Xie","Shuo Jin","Songqiang Chen"],"venue":"Automated Software Engineering","venueShort":"Autom. Softw. Eng.","tags":[],"awards":[],"abstract":"Question Answering (QA) is an attractive and challenging area in NLP community. With the development of QA technique, plenty of QA software has been applied in daily human life to provide convenient access of information retrieval. To investigate the performance of QA software, many benchmark datasets have been constructed to provide various test cases. However, current QA software is mainly tested in a reference-based paradigm, in which the expected outputs (labels) of test cases are mandatory to be annotated with much human effort before testing. As a result, neither the just-in-time test during usage nor the extensible test on massive unlabeled real-life data is feasible, which keeps the current testing of QA software from being flexible and sufficient. In this work, we propose a novel testing method, qaAskeR $$^+$$ + , with five new Metamorphic Relations for QA software. qaAskeR $$^+$$ + does not refer to the annotated labels of test cases. Instead, based on the idea that a correct answer should imply a piece of reliable knowledge that always conforms with any other correct answer, qaAskeR $$^+$$ + tests QA software by inspecting its behaviors on multiple recursively asked questions that are relevant to the same or some further enriched knowledge. Experimental results show that qaAskeR $$^+$$ + can reveal quite a few violations that indicate actual answering issues on various mainstream QA software without using any pre-annotated labels.","arxivUrl":null,"paperUrl":"https://doi.org/10.1007/s10515-023-00380-2","bibtex":"@article{DBLP:journals/ase/XieJC23,\n  author       = {Xiaoyuan Xie and\n                  Shuo Jin and\n                  Songqiang Chen},\n  title        = {qaAskeR\\({}^{\\mbox{+}}\\): a novel testing method for question answering\n                  software via asking recursive questions},\n  journal      = {Autom. Softw. Eng.},\n  volume       = {30},\n  number       = {1},\n  pages        = {14},\n  year         = {2023},\n  url          = {https://doi.org/10.1007/s10515-023-00380-2},\n  doi          = {10.1007/S10515-023-00380-2},\n  timestamp    = {Mon, 05 Feb 2024 20:24:13 +0100},\n  biburl       = {https://dblp.org/rec/journals/ase/XieJC23.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Properly Offer Options to Improve the Practicality of Software Document Completion Tools.","date":"2023","authors":["Zhipeng Cai","Songqiang Chen","Xiaoyuan Xie"],"venue":"31st IEEE/ACM International Conference on Program Comprehension","venueShort":"ICPC","tags":[],"awards":[],"abstract":"With the great progress in deep learning and natural language processing, many completion tools are proposed to help practitioners efficiently fill in various fields in software document. However, most of these tools offer their users only one option and this option generally requires much revision to meet a satisfactory quality, which hurts much practicality of the completion tools. By finding that the beam search model of such tools often generates a much better output at relatively high confidence and considering the interactive use of such tools, we advise such tools to offer multiple high-confidence model outputs for more chances of offering a good option. And we further suggest these tools offer dissimilar outputs to expand the chance of including a better output in a few options. To evaluate our whole idea, we design a clustering-based initial method to help these tools properly offer some dissimilar model outputs as options. We adopt this method to improve nine completion tools for three software document fields. Results show it can help all the nine tools offer an option that needs less revision from users and thus effectively improve the practicality of tools.","arxivUrl":null,"paperUrl":"https://doi.org/10.1109/ICPC58990.2023.00038","bibtex":"@inproceedings{DBLP:conf/iwpc/CaiCX23,\n  author       = {Zhipeng Cai and\n                  Songqiang Chen and\n                  Xiaoyuan Xie},\n  title        = {Properly Offer Options to Improve the Practicality of Software Document\n                  Completion Tools},\n  booktitle    = {31st {IEEE/ACM} International Conference on Program Comprehension,\n                  {ICPC} 2023, Melbourne, Australia, May 15-16, 2023},\n  pages        = {237--241},\n  publisher    = {{IEEE}},\n  year         = {2023},\n  url          = {https://doi.org/10.1109/ICPC58990.2023.00038},\n  doi          = {10.1109/ICPC58990.2023.00038},\n  timestamp    = {Mon, 05 Feb 2024 20:33:14 +0100},\n  biburl       = {https://dblp.org/rec/conf/iwpc/CaiCX23.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"MULA: A Just-In-Time Multi-labeling System for Issue Reports.","date":"2022","authors":["Xiaoyuan Xie","Yuhui Su","Songqiang Chen","Lin Chen","Jifeng Xuan","Baowen Xu"],"venue":"IEEE Transactions on Reliability","venueShort":"IEEE","tags":[],"awards":[],"abstract":"A very important function of an issue tracking system is to assign labels to issue reports, such as bug, feature, enhancement, etc., in order to categorize issues to facilitate various development activities. In practice, it is very common that an issue has multiple labels. However, current works are mainly based on single-label prediction, which are not suitable for just-in-time multi-labeling services, due to the low efficiency. Therefore, in this paper, we propose MULA, a just-in-time MUlti-LAbeling system, which learns and automatically assigns multiple labels to issue reports. We have built a dataset with 81,601 entries and 11 labels, as the first benchmark for this task, and implemented a GitHub app. To the best of our knowledge, this is the first work and tool for online multi-labeling GitHub issues based on their categories. We conduct a comprehensive empirical study, including comparisons with five commonly adopted labeling models that show the superiority of MULA, as well as an evaluation that shows high consistency between MULA’s suggestions and developers’ opinions.","arxivUrl":null,"paperUrl":"https://doi.org/10.1109/TR.2021.3074512","bibtex":"@article{DBLP:journals/tr/XieSCCXX22,\n  author       = {Xiaoyuan Xie and\n                  Yuhui Su and\n                  Songqiang Chen and\n                  Lin Chen and\n                  Jifeng Xuan and\n                  Baowen Xu},\n  title        = {{MULA:} {A} Just-In-Time Multi-labeling System for Issue Reports},\n  journal      = {{IEEE} Trans. Reliab.},\n  volume       = {71},\n  number       = {1},\n  pages        = {250--263},\n  year         = {2022},\n  url          = {https://doi.org/10.1109/TR.2021.3074512},\n  doi          = {10.1109/TR.2021.3074512},\n  timestamp    = {Fri, 01 Apr 2022 11:23:38 +0200},\n  biburl       = {https://dblp.org/rec/journals/tr/XieSCCXX22.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Towards the Robustness of Multiple Object Tracking Systems.","date":"2022","authors":["Xiaoyuan Xie","Ying Duan","Songqiang Chen","Jifeng Xuan"],"venue":"IEEE 33rd International Symposium on Software Reliability Engineering","venueShort":"ISSRE","tags":[],"awards":[],"abstract":"Due to the wide use of visual perception techniques in safety-critical fields, existing studies have tested the robustness of the essential object detection systems in scenarios with different image content. However, the applications that perceive one video with multiple image frames, such as autonomous driving, usually further require the trajectories of objects. This is mainly realized by combining detecting objects and associating detected objects in frames using multiple object tracking (MOT) systems. Thus, it is also essential to test the robustness of MOT systems, particularly in their exclusive scenarios that involve variety beyond the static image content. In this paper, we propose a novel testing method with five new Metamorphic Relations to realize the robustness test for MOT systems in two typical categories of scenarios, i.e., the speed variety of tracked objects and temporary camera failures. Our method also properly addresses the oracle problem and the lack of test cases for some rare scenarios to make the test efficient and diverse. Finally, we use our method to test three typical MOT systems and effectively reveal numerous and diverse MOT errors. We also extensively discuss the performance of tested systems and summarize two typical scenes where they often misbehave.","arxivUrl":null,"paperUrl":"https://doi.org/10.1109/ISSRE55969.2022.00046","bibtex":"@inproceedings{DBLP:conf/issre/XieDCX22,\n  author       = {Xiaoyuan Xie and\n                  Ying Duan and\n                  Songqiang Chen and\n                  Jifeng Xuan},\n  title        = {Towards the Robustness of Multiple Object Tracking Systems},\n  booktitle    = {{IEEE} 33rd International Symposium on Software Reliability Engineering,\n                  {ISSRE} 2022, Charlotte, NC, USA, October 31 - Nov. 3, 2022},\n  pages        = {402--413},\n  publisher    = {{IEEE}},\n  year         = {2022},\n  url          = {https://doi.org/10.1109/ISSRE55969.2022.00046},\n  doi          = {10.1109/ISSRE55969.2022.00046},\n  timestamp    = {Tue, 21 Mar 2023 21:00:30 +0100},\n  biburl       = {https://dblp.org/rec/conf/issre/XieDCX22.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Boosting the Revealing of Detected Violations in Deep Learning Testing: A Diversity-Guided Method.","date":"2022","authors":["Xiaoyuan Xie","Pengbo Yin","Songqiang Chen"],"venue":"37th IEEE/ACM International Conference on Automated Software Engineering","venueShort":"ASE","tags":[],"awards":[],"abstract":null,"arxivUrl":null,"paperUrl":"https://doi.org/10.1145/3551349.3556919","bibtex":"@inproceedings{DBLP:conf/kbse/XieYC22,\n  author       = {Xiaoyuan Xie and\n                  Pengbo Yin and\n                  Songqiang Chen},\n  title        = {Boosting the Revealing of Detected Violations in Deep Learning Testing:\n                  {A} Diversity-Guided Method},\n  booktitle    = {37th {IEEE/ACM} International Conference on Automated Software Engineering,\n                  {ASE} 2022, Rochester, MI, USA, October 10-14, 2022},\n  pages        = {17:1--17:13},\n  publisher    = {{ACM}},\n  year         = {2022},\n  url          = {https://doi.org/10.1145/3551349.3556919},\n  doi          = {10.1145/3551349.3556919},\n  timestamp    = {Sun, 15 Jan 2023 18:32:12 +0100},\n  biburl       = {https://dblp.org/rec/conf/kbse/XieYC22.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"SMAPGAN: Generative Adversarial Network-Based Semisupervised Styled Map Tile Generation Method.","date":"2021","authors":["Xu Chen","Songqiang Chen","Tian Xu","Bangguo Yin","Jian Peng","Xiaoming Mei","Haifeng Li"],"venue":"IEEE Transactions on Geoscience and Remote Sensing","venueShort":"IEEE","tags":[],"awards":[],"abstract":"Traditional online map tiles, which are widely used on the Internet, such as by Google Maps and Baidu Maps, are rendered from vector data. The timely updating of online map tiles from vector data, for which generation is time-consuming, is a difficult mission. Generating map tiles over time from remote sensing images is relatively simple and can be performed quickly without vector data. However, this approach used to be challenging or even impossible. Inspired by image-to-image translation (img2img) techniques based on generative adversarial networks (GANs), we proposed a semisupervised generation of styled map tiles based on the GANs (SMAPGAN) model to generate styled map tiles directly from remote sensing images. In this model, we designed a semisupervised learning strategy to pretrain SMAPGAN on rich unpaired samples and fine-tune it on limited paired samples in reality. We also designed the image gradient L1 loss and the image gradient structure loss to generate a styled map tile with global topological relationships and detailed edge curves for objects, which are important in cartography. Moreover, we proposed the edge structural similarity index (ESSI) as a metric to evaluate the quality of the topological consistency between the generated map tiles and ground truth. The experimental results show that SMAPGAN outperforms state-of-the-art (SOTA) works according to the mean squared error, the structural similarity index, and the ESSI. Also, SMAPGAN gained higher approval than SOTA in a human perceptual test on the visual realism of cartography. Our work shows that SMAPGAN is a new tool with excellent potential for producing styled map tiles. Our implementation of SMAPGAN is available at https://github.com/imcsq/SMAPGAN.","arxivUrl":null,"paperUrl":"https://doi.org/10.1109/TGRS.2020.3021819","bibtex":"@article{DBLP:journals/tgrs/ChenCXYPML21,\n  author       = {Xu Chen and\n                  Songqiang Chen and\n                  Tian Xu and\n                  Bangguo Yin and\n                  Jian Peng and\n                  Xiaoming Mei and\n                  Haifeng Li},\n  title        = {{SMAPGAN:} Generative Adversarial Network-Based Semisupervised Styled\n                  Map Tile Generation Method},\n  journal      = {{IEEE} Trans. Geosci. Remote. Sens.},\n  volume       = {59},\n  number       = {5},\n  pages        = {4388--4406},\n  year         = {2021},\n  url          = {https://doi.org/10.1109/TGRS.2020.3021819},\n  doi          = {10.1109/TGRS.2020.3021819},\n  timestamp    = {Thu, 18 Sep 2025 11:23:21 +0200},\n  biburl       = {https://dblp.org/rec/journals/tgrs/ChenCXYPML21.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Where to Handle an Exception? Recommending Exception Handling Locations from a Global Perspective.","date":"2021","authors":["Xiangyang Jia","Songqiang Chen","Xingqi Zhou","Xintong Li","Run Yu","Xu Chen","Jifeng Xuan"],"venue":"29th IEEE/ACM International Conference on Program Comprehension","venueShort":"ICPC","tags":[],"awards":[],"abstract":"Exception handling is an effective mechanism to guarantee software reliability in modern programming languages. An exception interrupts the program execution and propagates backwards along the call chain until the exception is caught by an exception handler. In software development practices, developers may be confused in determining where to place the exception handler in the call chain. The reason is that exception handling requires a developer to take a comprehensive consideration from a global perspective of the software project. In this paper, we propose an automatic approach EHAdvisor, which recommends exception handling locations from the global perspective of the project. EHAdvisor first trains a binary classification model based on four types of features, including architectural features, project features, functional features, and exception features. Then, for a new code snippet with exceptions, EHAdvisor predicts the exception catching probability for each method in the call chain based on the classification model and recommends Top-K exception handling locations based on the probability ranking. We conducted experiments on a dataset from 29 high-quality open source projects. Experimental results show that EHAdvisor achieves an average Top-1 recommendation success rate of 70.83% for across-project location recommendation and an average Top-1 accuracy of 86.21% for intra-project recommendation. Experiments on the importance scores show that global features, such as project features and architectural features, are evidently important to the recommendation of exception handling locations.","arxivUrl":null,"paperUrl":"https://doi.org/10.1109/ICPC52881.2021.00042","bibtex":"@inproceedings{DBLP:conf/iwpc/JiaCZLYCX21,\n  author       = {Xiangyang Jia and\n                  Songqiang Chen and\n                  Xingqi Zhou and\n                  Xintong Li and\n                  Run Yu and\n                  Xu Chen and\n                  Jifeng Xuan},\n  title        = {Where to Handle an Exception? Recommending Exception Handling Locations\n                  from a Global Perspective},\n  booktitle    = {29th {IEEE/ACM} International Conference on Program Comprehension,\n                  {ICPC} 2021, Madrid, Spain, May 20-21, 2021},\n  pages        = {369--380},\n  publisher    = {{IEEE}},\n  year         = {2021},\n  url          = {https://doi.org/10.1109/ICPC52881.2021.00042},\n  doi          = {10.1109/ICPC52881.2021.00042},\n  timestamp    = {Fri, 19 Sep 2025 07:19:01 +0200},\n  biburl       = {https://dblp.org/rec/conf/iwpc/JiaCZLYCX21.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Testing Your Question Answering Software via Asking Recursively.","date":"2021","authors":["Songqiang Chen","Shuo Jin","Xiaoyuan Xie"],"venue":"36th IEEE/ACM International Conference on Automated Software Engineering","venueShort":"ASE","tags":[],"awards":[],"abstract":"Question Answering (QA) is an attractive and challenging area in NLP community. There are diverse algorithms being proposed and various benchmark datasets with different topics and task formats being constructed. QA software has also been widely used in daily human life now. However, current QA software is mainly tested in a reference-based paradigm, in which the expected outputs (labels) of test cases need to be annotated with much human effort before testing. As a result, neither the just-in-time test during usage nor the extensible test on massive unlabeled real-life data is feasible, which keeps the current testing of QA software from being flexible and sufficient. In this paper, we propose a method, qaAskeR, with three novel Metamorphic Relations for testing QA software. qaAskeR does not require the annotated labels but tests QA software by checking its behaviors on multiple recursively asked questions that are related to the same knowledge. Experimental results show that qaAskeR can reveal violations at over 80% of valid cases without using any preannotated labels. Diverse answering issues, especially the limited generalization on question types across datasets, are revealed on a state-of-the-art QA algorithm.","arxivUrl":null,"paperUrl":"https://doi.org/10.1109/ASE51524.2021.9678670","bibtex":"@inproceedings{DBLP:conf/kbse/ChenJX21,\n  author       = {Songqiang Chen and\n                  Shuo Jin and\n                  Xiaoyuan Xie},\n  title        = {Testing Your Question Answering Software via Asking Recursively},\n  booktitle    = {36th {IEEE/ACM} International Conference on Automated Software Engineering,\n                  {ASE} 2021, Melbourne, Australia, November 15-19, 2021},\n  pages        = {104--116},\n  publisher    = {{IEEE}},\n  year         = {2021},\n  url          = {https://doi.org/10.1109/ASE51524.2021.9678670},\n  doi          = {10.1109/ASE51524.2021.9678670},\n  timestamp    = {Sun, 19 Jan 2025 13:19:05 +0100},\n  biburl       = {https://dblp.org/rec/conf/kbse/ChenJX21.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Property-based Test for Part-of-Speech Tagging Tool.","date":"2021","authors":["Shuo Jin","Songqiang Chen","Xiaoyuan Xie"],"venue":"36th IEEE/ACM International Conference on Automated Software Engineering","venueShort":"ASE","tags":[],"awards":[],"abstract":"Part-of-Speech (POS) tagging for sentences is a basic and widely-used Natural Language Processing (NLP) technique. People rely heavily on it to predict POS tags that serve as the base for many advanced NLP tasks, such as sentiment analysis, word sense disambiguation, and information retrieval. However, POS tagging tools could make wrong predictions, which bring consequent error propagation to the advanced tasks and even cause serious threats in critical application domains. In this paper, we propose to test POS tagging tools with Metamorphic Testing against some properties that they should follow. The preliminary exploration with two groups of Metamorphic Relations shows that our method can effectively reveal defects of three common POS tagging tools (i.e., spaCy, NLTK, and Flair) on handling fairly simple intra- and inter-sentence transformation regarding adverbial clause and sentence appending. This demonstrates the great potential of our method to deliver a systematic test and reveal the unaware issues, which may benefit the validation, repair, and improvement, for POS tagging tools.","arxivUrl":null,"paperUrl":"https://doi.org/10.1109/ASE51524.2021.9678807","bibtex":"@inproceedings{DBLP:conf/kbse/JinCX21,\n  author       = {Shuo Jin and\n                  Songqiang Chen and\n                  Xiaoyuan Xie},\n  title        = {Property-based Test for Part-of-Speech Tagging Tool},\n  booktitle    = {36th {IEEE/ACM} International Conference on Automated Software Engineering,\n                  {ASE} 2021, Melbourne, Australia, November 15-19, 2021},\n  pages        = {1306--1311},\n  publisher    = {{IEEE}},\n  year         = {2021},\n  url          = {https://doi.org/10.1109/ASE51524.2021.9678807},\n  doi          = {10.1109/ASE51524.2021.9678807},\n  timestamp    = {Sun, 02 Oct 2022 16:10:53 +0200},\n  biburl       = {https://dblp.org/rec/conf/kbse/JinCX21.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Validation on machine reading comprehension software without annotated labels: a property-based method.","date":"2021","authors":["Songqiang Chen","Shuo Jin","Xiaoyuan Xie"],"venue":"ESEC/FSE '21: 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering","venueShort":"ESEC/FSE","tags":[],"awards":[],"abstract":null,"arxivUrl":null,"paperUrl":"https://doi.org/10.1145/3468264.3468569","bibtex":"@inproceedings{DBLP:conf/sigsoft/ChenJX21,\n  author       = {Songqiang Chen and\n                  Shuo Jin and\n                  Xiaoyuan Xie},\n  editor       = {Diomidis Spinellis and\n                  Georgios Gousios and\n                  Marsha Chechik and\n                  Massimiliano Di Penta},\n  title        = {Validation on machine reading comprehension software without annotated\n                  labels: a property-based method},\n  booktitle    = {{ESEC/FSE} '21: 29th {ACM} Joint European Software Engineering Conference\n                  and Symposium on the Foundations of Software Engineering, Athens,\n                  Greece, August 23-28, 2021},\n  pages        = {590--602},\n  publisher    = {{ACM}},\n  year         = {2021},\n  url          = {https://doi.org/10.1145/3468264.3468569},\n  doi          = {10.1145/3468264.3468569},\n  timestamp    = {Sat, 08 Jan 2022 02:24:43 +0100},\n  biburl       = {https://dblp.org/rec/conf/sigsoft/ChenJX21.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Stay Professional and Efficient: Automatically Generate Titles for Your Bug Reports.","date":"2020","authors":["Songqiang Chen","Xiaoyuan Xie","Bangguo Yin","Yuanxiang Ji","Lin Chen","Baowen Xu"],"venue":"35th IEEE/ACM International Conference on Automated Software Engineering","venueShort":"ASE","tags":[],"awards":[],"abstract":null,"arxivUrl":null,"paperUrl":"https://doi.org/10.1145/3324884.3416538","bibtex":"@inproceedings{DBLP:conf/kbse/ChenXYJCX20,\n  author       = {Songqiang Chen and\n                  Xiaoyuan Xie and\n                  Bangguo Yin and\n                  Yuanxiang Ji and\n                  Lin Chen and\n                  Baowen Xu},\n  title        = {Stay Professional and Efficient: Automatically Generate Titles for\n                  Your Bug Reports},\n  booktitle    = {35th {IEEE/ACM} International Conference on Automated Software Engineering,\n                  {ASE} 2020, Melbourne, Australia, September 21-25, 2020},\n  pages        = {385--397},\n  publisher    = {{IEEE}},\n  year         = {2020},\n  url          = {https://doi.org/10.1145/3324884.3416538},\n  doi          = {10.1145/3324884.3416538},\n  timestamp    = {Wed, 19 May 2021 08:32:10 +0200},\n  biburl       = {https://dblp.org/rec/conf/kbse/ChenXYJCX20.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"abcdefghijklmnopqrstuvwxyz","date":"2026","authors":["Albert"],"venue":"Expert Systems with Applications","venueShort":"Expert Syst. Appl.","tags":[],"awards":[],"abstract":null,"arxivUrl":null,"paperUrl":"https://doi.org/10.1016/j.eswa.2025.130793","bibtex":"@article{DBLP:journals/eswa/LiuJ26,\n  author       = {Dongcan Liu and\n                  Linfeng Jiang},\n  title        = {Occluded person re-identification via feature enhancement and contextual\n                  refinement},\n  journal      = {Expert Syst. Appl.},\n  volume       = {304},\n  pages        = {130793},\n  year         = {2026},\n  url          = {https://doi.org/10.1016/j.eswa.2025.130793},\n  doi          = {10.1016/J.ESWA.2025.130793},\n  timestamp    = {Sun, 01 Feb 2026 13:38:19 +0100},\n  biburl       = {https://dblp.org/rec/journals/eswa/LiuJ26.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}","projectUrl":null,"slidesUrl":null},{"title":"Nyx: Detecting Exploitable Front-Running Vulnerabilities in Smart Contracts","date":"2024-05-20","authors":["Wuqi Zhang","Zhuo Zhang","Qingkai Shi","Lu Liu","Lili Wei","Yepang Liu","Xiangyu Zhang","Shing-Chi Cheung"],"venue":"The 45th IEEE Symposium on Security and Privacy","venueShort":"S&P","tags":["Blockchain","Front-running","Vulnerability","MEV","Program Analysis"],"abstract":"Smart contracts are susceptible to front-running attacks, in which malicious users leverage prior knowledge of upcoming transactions to execute attack transactions in advance and benefit their own portfolios. Existing contract analysis techniques raise a number of false positives and false negatives in that they simplistically treat data races in a contract as front-running vulnerabilities and can only analyze contracts in isolation. In this work, we formalize the definition of exploitable front-running vulnerabilities based on previous empirical studies on historical attacks, and present Nyx, a novel static analyzer to detect them. Nyx features a Datalog-based preprocessing procedure that efficiently and soundly prunes a large part of the search space, followed by a symbolic validation engine that precisely locates vulnerabilities with an SMT solver. We evaluate Nyx using a large dataset that comprises 513 real-world front-running attacks in smart contracts. Compared to six state-of-the-art techniques, Nyx surpasses them by 32.64%-90.19% in terms of recall and 2.89%-70.89% in terms of precision. Nyx has also identified four zero-days in real-world smart contracts.","projectUrl":null,"arxivUrl":null,"paperUrl":"https:/castlelab.github.io/selected-publications/assets/Nyx-SP24.pdf","bibtex":null,"slidesUrl":null,"awards":[]},{"title":"Combatting Front-Running in Smart Contracts: Attack Mining, Benchmark Construction and Vulnerability Detector Evaluation","date":"2023-04-15","authors":["Wuqi Zhang","Lili Wei","Shing-Chi Cheung","Yepang Liu","Shuqing Li","Lu Liu","Michael R. Lyu"],"venue":"Transactions on Software Engineering","venueShort":"TSE","tags":["Blockchain","Front-running","Vulnerability","MEV","Benchmark"],"abstract":"\n    Front-running attacks have been a major concern on the blockchain. Attackers launch front-running attacks by inserting additional transactions before upcoming victim transactions to manipulate victim transaction executions and make profits. Recent studies have shown that front-running attacks are prevalent on the Ethereum blockchain and have caused millions of US dollars loss. Vulnerable smart contracts, blockchain programs invoked by transactions, are held responsible for front-running attacks. Although techniques to detect front-running vulnerabilities have been proposed, their performance on real-world vulnerable contracts is unclear. There is no large-scale benchmark based on real attacks to evaluate their capabilities. This motivates us to build a benchmark consisting of 513 real-world attacks with vulnerable code labeled in 235 distinct smart contracts. We propose automated techniques to effectively collect real-world attacks and localize the corresponding vulnerable code at scale. Our experiments show that our approaches are effective, achieving higher recall in finding real attacks and higher precision in pinpointing vulnerabilities compared to the existing techniques. The evaluation of seven state-of-the-art vulnerability detection techniques on the benchmark reveals their inadequacy in detecting front-running vulnerabilities, with a low recall of at most 6.04%. Our further analysis identifies four common limitations in existing techniques: lack of support for inter-contract analysis, inefficient constraint solving for cryptographic operations, improper vulnerability patterns, and lack of token support.\n  ","projectUrl":"https://github.com/Troublor/erebus-redgiant","arxivUrl":null,"paperUrl":"https://ieeexplore.ieee.org/document/10108045","bibtex":null,"slidesUrl":null,"awards":[]},{"title":"ÐArcher: Detecting On-Chain-Off-Chain Synchronization Bugs in Decentralized Applications","date":"2021-08-23","authors":["Wuqi Zhang","Lili Wei","Shuqing Li","Yepang Liu","Shing-Chi Cheung"],"venue":"Proceedings of the 29th ACM Joint European SoftwareEngineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE ’21)","venueShort":"ESEC/FSE","tags":["Decentralized Applications","Testing","Blockchain"],"abstract":"\n    Since the emergence of Ethereum, blockchain-based decentralized applications (DApps) have become increasingly popular and important. To balance the security, performance, and costs, a DApp typically consists of two layers: an on-chain layer to execute transactions and store crucial data on blockchain, and an off-chain layer to interact with users. A DApp needs to proactively synchronize its off-chain layer with the on-chain layer, otherwise, the inconsistent data in the off-chain layer could mislead users and cause undesirable consequences, e.g., loss of transaction fees. However, transactions sent to blockchain are not guaranteed to be executed and could even be reversed after execution due to chain reorganization. Such non-determinism in the transaction execution is unique to blockchain and DApp developers may fail to perform the on-chain-off-chain synchronization accurately due to their unfamiliarity of the complex transaction lifecycle.\n    In this work, we investigate the challenges of synchronizing on-chain and off-chain data in Ethereum-based DApps. We present two types of bugs that could result in inconsistencies between the on-chain and off-chain layers. To help detect such on-chain-off-chain synchronization bugs, we introduce a state transition model to guide the testing of DApps, and propose two effective oracles to facilitate the automatic identification of bugs. We build the first testing framework, ÐArcher, to detect on-chain-off-chain synchronization bugs in DApps. We have evaluated ÐArcher on 11 popular real-world DApps. ÐArcher achieves high precision (99.3%), recall (87.6%), and accuracy (89.4%) in bug detection and significantly outperforms the baseline methods. It has found 15 real bugs in the 11 DApps. So far, six of the 15 bugs have been confirmed by the developers and three have been fixed. These promising results demonstrate the usefulness of ÐArcher.\n    ","projectUrl":"https://github.com/Troublor/darcher","arxivUrl":"https://arxiv.org/pdf/2106.09440.pdf","paperUrl":"https:/castlelab.github.io/selected-publications/assets/DArcher-FSE21.pdf","bibtex":"@inproceedings{10.1145/3468264.3468546,\n      author = {Zhang, Wuqi and Wei, Lili and Li, Shuqing and Liu, Yepang and Cheung, Shing-Chi},\n      title = {DH{}Archer: Detecting on-Chain-off-Chain Synchronization Bugs in Decentralized Applications},\n      year = {2021},\n      isbn = {9781450385626},\n      publisher = {Association for Computing Machinery},\n      address = {New York, NY, USA},\n      url = {https://doi.org/10.1145/3468264.3468546},\n      doi = {10.1145/3468264.3468546},\n      abstract = {Since the emergence of Ethereum, blockchain-based decentralized applications (DApps)\n      have become increasingly popular and important. To balance the security, performance,\n      and costs, a DApp typically consists of two layers: an on-chain layer to execute transactions\n      and store crucial data on the blockchain and an off-chain layer to interact with users.\n      A DApp needs to synchronize its off-chain layer with the on-chain layer proactively.\n      Otherwise, the inconsistent data in the off-chain layer could mislead users and cause\n      undesirable consequences, e.g., loss of transaction fees. However, transactions sent\n      to the blockchain are not guaranteed to be executed and could even be reversed after\n      execution due to chain reorganization. Such non-determinism in the transaction execution\n      is unique to blockchain. DApp developers may fail to perform the on-chain-off-chain\n      synchronization accurately due to their lack of familiarity with the complex transaction\n      lifecycle. In this work, we investigate the challenges of synchronizing on-chain and\n      off-chain data in Ethereum-based DApps. We present two types of bugs that could result\n      in inconsistencies between the on-chain and off-chain layers. To help detect such\n      on-chain-off-chain synchronization bugs, we introduce a state transition model to\n      guide the testing of DApps and propose two effective oracles to facilitate the automatic\n      identification of bugs. We build the first testing framework, DH{}Archer, to detect on-chain-off-chain\n      synchronization bugs in DApps. We have evaluated DH{}Archer on 11 popular real-world\n      DApps. DH{}Archer achieves high precision (99.3%), recall (87.6%), and accuracy (89.4%)\n      in bug detection and significantly outperforms the baseline methods. It has found\n      15 real bugs in the 11 DApps. So far, six of the 15 bugs have been confirmed by the\n      developers, and three have been fixed. These promising results demonstrate the usefulness\n      of DH{}Archer.},\n      booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},\n      pages = {553–565},\n      numpages = {13},\n      keywords = {Software testing, DApps, Decentralized applications, Blockchain},\n      location = {Athens, Greece},\n      series = {ESEC/FSE 2021}\n    }","slidesUrl":null,"awards":[]},{"title":"Will Dependency Conflicts Affect My Program's Semantics?","date":"2021","authors":["Ying Wang","Rongxin Wu","Chao Wang","Ming Wen","Yepang Liu","Shing-Chi Cheung","Hai Yu","Chang Xu","Zhiliang Zhu"],"venue":"IEEE Transactions on Software Engineering","venueShort":"TSE","tags":["Third-Party Libraries","Java","Dependency Management"],"abstract":"\n        Java projects are often built on top of various third-party libraries. If multiple versions of a library exist on the classpath, JVM will only load one version and shadow the others, which we refer to as dependency conflicts. This would give rise to semantic conflict (SC) issues, if the library APIs referenced by a project have identical method signatures but inconsistent semantics across the loaded and shadowed versions of libraries. SC issues are difficult for developers to diagnose in practice, since understanding them typically requires domain knowledge. Although adapting the existing test generation technique for dependency conflict issues, Riddle, to detect SC issues is feasible, its effectiveness is greatly compromised. This is mainly because Riddle randomly generates test inputs, while the SC issues typically require specific arguments in the tests to be exposed. To address that, we conducted an empirical study of 316 real SC issues to understand the characteristics of such specific arguments in the test cases that can capture the SC issues. Inspired by our empirical findings, we propose an automated testing technique Sensor, which synthesizes test cases using ingredients from the project under test to trigger inconsistent behaviors of the APIs with the same signatures in conflicting library versions. Our evaluation results show that Sensor is effective and useful: it achieved a Precision of 0.898 and a Recall of 0.725 on open-source projects and a Precision of 0.821 on industrial projects; it detected 306 semantic conflict issues in 50 projects, 70.4% of which had been confirmed as real bugs, and 84.2% of the confirmed issues have been fixed quickly.\n        ","projectUrl":"https://sensordc.github.io/","paperUrl":"https://ieeexplore.ieee.org/document/9350237","slidesUrl":null,"bibtex":"@article{YingSensor,\n  author    = {Ying Wang and\n               Rongxin Wu and\n               Chao Wang and\n               Ming Wen and\n               Yepang Liu and\n               Shing{-}Chi Cheung\n               Hai Yu and\n               Chang Xu\n               and Zhiliang Zhu},\n  title     = {Will Dependency Conflicts Affect My Program's Semantics?},\n  journal   = {{IEEE} Transactions on Software Engineering},\n  volume    = {99},\n  number    = {1},\n  pages     = {1--22},\n  year      = {2021},\n  url       = {https://ieeexplore.ieee.org/document/9350237},\n  doi       = {10.1109/TSE.2021.3057767},\n  timestamp = {Fri, 08 February 2021 21:56:08 +0200},\n  biburl    = {https://dblp.org/rec/journals/tsc/WangHXZC20.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n            }","arxivUrl":null,"awards":[]},{"title":"Hero: On the Chaos When PATH Meets Modules","date":"2021","authors":["Ying Wang","Liang Qiao","Chang Xu","Yepang Liu","Shing-Chi Cheung","Na Meng","Hai Yu","Zhiliang Zhu"],"venue":"Proceedings of the 43rd International Conference on Software Engineering (ICSE ’21)","venueShort":"ICSE","tags":["Third-Party Libraries","Golang","Dependency Management"],"awards":["Distinguished Paper"],"abstract":"\n        Ever since its first release in 2009, the Go programming language (Golang) has been well received by software communities. A major reason for its success is the powerful support of library-based development, where a Golang project can be conveniently built on top of other projects by referencing them as libraries. As Golang evolves, it recommends the use of a new library-referencing mode to overcome the limitations of the original one. While these two library modes are incompatible, both are supported by the Golang ecosystem. The heterogeneous use of library-referencing modes across Golang projects has caused numerous dependency management (DM) issues, incurring reference inconsistencies and even build failures. Motivated by the problem, we conducted an empirical study to characterize the DM issues, understand their root causes, and examine their fixing solutions. Based on our findings, we developed Hero, an automated technique to detect DM issues and suggest proper fixing solutions. We applied Hero to 19,000 popular Golang projects. The results showed that Hero achieved a high detection rate of 98.5% on a DM issue benchmark and found 2,422 new DM issues in 2,356 popular Golang projects. We reported 280 issues, among which 181 (64.6%) issues have been confirmed, and 160 of them (88.4%) have been fixed or are under fixing. Almost all the fixes have adopted our fixing suggestions.\n        ","projectUrl":"http://www.hero-go.com/","paperUrl":"https://conf.researchr.org/details/icse-2021/icse-2021-papers/16/Hero-On-the-Chaos-When-PATH-Meets-Modules","slidesUrl":null,"bibtex":"@inproceedings{YingHero,\n  author    = {Ying Wang and\n               Liang Qiao and\n               Chang Xu and\n               Yepang Liu and\n               Shing{-}Chi Cheung and\n               Na Meng and\n               Hai Yu and \n               Zhiliang Zhu},\n  title     = {Hero: On the Chaos When PATH Meets Modules},\n  booktitle = {{ICSE} '21: 43rd International Conference on Software Engineering, Virtual\n               Event, Spain, May 23-29, 2021},\n  pages     = {99--111},\n  publisher = {{IEEE}},\n  year      = {2021},\n  url       = {https://ieeexplore.ieee.org/document/9401974},\n  doi       = {10.1109/ICSE43902.2021.00022},\n  timestamp = {22-30 May 2021 10:58:23 +0100},\n  biburl    = {https://dblp.org/rec/conf/sigsoft/ZhangRC0C020.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null},{"title":"Watchman: Monitoring Dependency Conflicts for Python Library Ecosystem","date":"2020","authors":["Ying Wang","Ming Wen","Yepang Liu","Yibo Wang","Zhenming Li","Chao Wang","Shing-Chi Cheung","Hai Yu","Chang Xu","Zhiliang Zhu"],"venue":"Proceedings of the 42rd International Conference on Software Engineering (ICSE ’20)","venueShort":"ICSE","tags":["Third-Party Libraries","Python","Dependency Management"],"abstract":"\n        The PyPI ecosystem has indexed millions of Python libraries to allow developers to automatically download and install dependencies of their projects based on the specified version constraints. Despite the convenience brought by automation, version constraints in Python projects can easily conflict, resulting in build failures. We refer to such conflicts as Dependency Conflict (DC) issues. Although DC issues are common in Python projects, developers lack tool support to gain a comprehensive knowledge for diagnosing the root causes of these issues. In this paper, we conducted an empirical study on 235 real-world DC issues. We studied the manifestation patterns and fixing strategies of these issues and found several key factors that can lead to DC issues and their regressions. Based on our findings, we designed and implemented Watchman, a technique to continuously monitor dependency conflicts for the PyPI ecosystem. In our evaluation, Watchman analyzed PyPI snapshots between 11 Jul 2019 and 16 Aug 2019, and found 117 potential DC issues. We reported these issues to the developers of the corresponding projects. So far, 63 issues have been confirmed, 38 of which have been quickly fixed by applying our suggested patches.\n        ","projectUrl":"http://www.watchman-pypi.com/","paperUrl":"https://dl.acm.org/doi/abs/10.1145/3377811.3380426","slidesUrl":"https://blog.acolyer.org/2020/09/21/watchman/","bibtex":"@inproceedings{YingWatchman,\n  author    = {Ying Wang and\n               Ming Wen and\n               Yepang Liu and\n               Yibo Wang and\n               Zhenming Li and\n               Chao Wang and\n               Shing{-}Chi Cheung and\n               Hai Yu and\n               Chang Xu and\n               Zhiliang Zhu\n            },\n  title     = {Watchman: Monitoring Dependency Conflicts for Python Library Ecosystem},\n  booktitle = {{ICSE} '20: 42nd International Conference on Software Engineering, Virtual\n                Event, Spain, July 6-11, 2020},\n  pages     = {125--135},\n  publisher = {{ACM}},\n  year      = {2020},\n  url       = {https://dl.acm.org/doi/abs/10.1145/3377811.3380426},\n  doi       = {10.1145/3377811.3380426},\n  timestamp = {Mon, 27 July 2020 16:42:27 +0200},\n  biburl    = {https://dblp.uni-trier.de/db/conf/icse/icse2020.html},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","arxivUrl":null,"awards":[]},{"title":"To What Extent Do DNN-based Image Classification Models Make Unreliable Inferences?","date":"2021","authors":["Yongqiang Tian","Shiqing Ma","Ming Wen","Yepang Liu","Shing-Chi Cheung","Xiangyu Zhang"],"venue":"Empirical Software Engineering","venueShort":"EMSE","tags":["Testing","DNN model","Metamorphic Testing"],"abstract":"Deep Neural Network (DNN) models are widely used for image classification. While they offer high performance in terms of accuracy, researchers are concerned about if these models inappropriately make inferences using features irrelevant to the target object in a given image. To address this concern, we propose a metamorphic testing approach that assesses if a given inference is made based on irrelevant features. Specifically, we propose two metamorphic relations (MRs) to detect such unreliable inferences. These relations expect (a) the classification results with different labels or the same labels but less certainty from models after corrupting the relevant features of images, and (b) expect the classification results with the same labels after corrupting irrelevant features. The inferences that violate the metamorphic relations are regarded as unreliable inferences.\nOur evaluation demonstrated that our approach can effectively identify unreliable inferences for single-label classification models with an average precision of 64.1% and 96.4% for the two MRs, respectively. As for multi-label classification models, the corresponding precision for MR-1 and MR-2 is 78.2% and 86.5%, respectively. Further, we conducted an empirical study to understand the problem of unreliable inferences in practice. Specifically, we applied our approach to 18 pre-trained single-label image classification models and 3 multi-label classification models, and then examined their inferences on the ImageNet and COCO datasets. We found that unreliable inferences are pervasive. Specifically, for each model, more than thousands of correct classifications are actually made using irrelevant features. Next, we investigated the effect of such pervasive unreliable inferences, and found that they can cause significant degradation of a model's overall accuracy. After including these unreliable inferences from the test set, the model's accuracy can be significantly changed. Therefore, we recommend that developers should pay more attention to these unreliable inferences during the model evaluations. We also explored the correlation between model accuracy and the size of unreliable inferences. We found the inferences of the input with smaller objects are easier to be unreliable. Lastly, we found that the current model training methodologies can guide the models to learn object-relevant features to certain extent, but may not necessarily prevent the model from making unreliable inferences. We encourage the community to propose more effective training methodologies to address this issue.\n","projectUrl":"https://github.com/yqtianust/PaperUnreliableInference","paperUrl":"https://doi.org/10.1007/s10664-021-09985-1","bibtex":"@Article{Tian2021,\n        author={Tian, Yongqiang\n        and Ma, Shiqing\n        and Wen, Ming\n        and Liu, Yepang\n        and Cheung, Shing-Chi\n        and Zhang, Xiangyu},\n        title={To what extent do DNN-based image classification models make unreliable inferences?},\n        journal={Empirical Software Engineering},\n        year={2021},\n        month={Jun},\n        day={18},\n        volume={26},\n        number={5},\n        pages={84},\n        abstract={Deep Neural Network (DNN) models are widely used for image classification. While they offer high performance in terms of accuracy, researchers are concerned about if these models inappropriately make inferences using features irrelevant to the target object in a given image. To address this concern, we propose a metamorphic testing approach that assesses if a given inference is made based on irrelevant features. Specifically, we propose two metamorphic relations (MRs) to detect such unreliable inferences. These relations expect (a) the classification results with different labels or the same labels but less certainty from models after corrupting the relevant features of images, and (b) the classification results with the same labels after corrupting irrelevant features. The inferences that violate the metamorphic relations are regarded as unreliable inferences. Our evaluation demonstrated that our approach can effectively identify unreliable inferences for single-label classification models with an average precision of 64.1{\\%} and 96.4{\\%} for the two MRs, respectively. As for multi-label classification models, the corresponding precision for MR-1 and MR-2 is 78.2{\\%} and 86.5{\\%}, respectively. Further, we conducted an empirical study to understand the problem of unreliable inferences in practice. Specifically, we applied our approach to 18 pre-trained single-label image classification models and 3 multi-label classification models, and then examined their inferences on the ImageNet and COCO datasets. We found that unreliable inferences are pervasive. Specifically, for each model, more than thousands of correct classifications are actually made using irrelevant features. Next, we investigated the effect of such pervasive unreliable inferences, and found that they can cause significant degradation of a model's overall accuracy. After including these unreliable inferences from the test set, the model's accuracy can be significantly changed. Therefore, we recommend that developers should pay more attention to these unreliable inferences during the model evaluations. We also explored the correlation between model accuracy and the size of unreliable inferences. We found the inferences of the input with smaller objects are easier to be unreliable. Lastly, we found that the current model training methodologies can guide the models to learn object-relevant features to certain extent, but may not necessarily prevent the model from making unreliable inferences. We encourage the community to propose more effective training methodologies to address this issue.},\n        issn={1573-7616},\n        doi={10.1007/s10664-021-09985-1},\n        url={https://doi.org/10.1007/s10664-021-09985-1}\n        }","arxivUrl":null,"slidesUrl":null,"awards":[]},{"title":"EvalDNN: a toolbox for evaluating deep neural network models","date":"2020","authors":["Yongqiang Tian","Zhihua Zeng","Ming Wen","Yepang Liu","Tzu-yang Kuo","Shing-Chi Cheung"],"venue":"42nd International Conference on Software Engineering, Demo","venueShort":"ICSE Demo","tags":["Testing","DNN model","Benchmark"],"projectUrl":"https://github.com/yqtianust/EvalDNN","paperUrl":"https://doi.org/10.1145/3377812.3382133","arxivUrl":null,"abstract":null,"bibtex":null,"slidesUrl":null,"awards":[]},{"title":"A Comprehensive Study of Deep Learning Compiler Bugs","date":"2021","authors":["Qingchao Shen","Haoyang Ma","Junjie Chen","Yongqiang Tian","Shing-Chi Cheung","Xiang Chen"],"venue":"Proceedings of the 29th ACM Joint European SoftwareEngineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE ’21)","venueShort":"ESEC/FSE","tags":["DL Compiler","Empirical Study"],"projectUrl":"https://github.com/ShenQingchao/DLCstudy","paperUrl":null,"arxivUrl":null,"abstract":null,"bibtex":null,"slidesUrl":null,"awards":[]},{"title":"AdvDoor: Adversarial Backdoor Attack of Deep Learning System","date":"2021","authors":["Quan Zhang","Yifeng Ding","Yongqiang Tian","Jianmin Guo","Min Yuan","Yu Jiang"],"venue":"ACM SIGSOFT International Symposium on Software Testing and Analysis","venueShort":"ISSTA","tags":["DNN model","Backdoor Attack"],"projectUrl":"https://github.com/AdvDoor/AdvDoor","paperUrl":null,"arxivUrl":null,"abstract":null,"bibtex":null,"slidesUrl":null,"awards":[]},{"title":"Finding Deviated Behaviors of the Compressed DNN Models for Image Classifications.","date":"2023","authors":["Yongqiang Tian","Wuqi Zhang","Ming Wen","Shing-Chi Cheung","Chengnian Sun","Shiqing Ma","Yu Jiang"],"venue":"ACM Transactions on Software Engineering and Methodology","venueShort":"TOSEM","tags":["DNN model"],"projectUrl":"https://dl.acm.org/doi/abs/10.1145/3583564","paperUrl":null,"arxivUrl":null,"abstract":null,"bibtex":null,"slidesUrl":null,"awards":[]},{"title":"Revisiting the Evaluation of Deep Learning-Based Compiler Testing.","date":"2023","authors":["Yongqiang Tian","Zhenyang Xu","Yiwen Dong","Chengnian Sun","Shing-Chi Cheung"],"venue":"The 32nd International Joint Conference on Artificial Intelligence","venueShort":"IJCAI","tags":["Compiler testing"],"projectUrl":null,"paperUrl":null,"arxivUrl":null,"abstract":null,"bibtex":null,"slidesUrl":null,"awards":[]},{"title":"On the Caching Schemes to Speed Up Program Reduction.","date":"2023","authors":["Yongqiang Tian","Xueyan Zhang","Yiwen Dong","Zhenyang Xu","Mengxiao Zhang","Yu Jiang","Shing-Chi Cheung","Chengnian Sun"],"venue":"ACM Transactions on Software Engineering and Methodology","venueShort":"TOSEM","tags":["Program Reduction"],"projectUrl":"https://github.com/uw-pluverse/perses/blob/master/doc/RCC.md","paperUrl":null,"arxivUrl":null,"abstract":null,"bibtex":null,"slidesUrl":null,"awards":[]}]